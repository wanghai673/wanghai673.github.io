<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>论文阅读 on Wanghai673 | 博客</title>
    <link>http://localhost:1313/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/</link>
    <description>Recent content in 论文阅读 on Wanghai673 | 博客</description>
    <image>
      <title>Wanghai673 | 博客</title>
      <url>http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- 0.148.2</generator>
    <language>en</language>
    <lastBuildDate>Sat, 06 Sep 2025 12:25:10 +0800</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>9.6 论文阅读</title>
      <link>http://localhost:1313/posts/9.6_%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/</link>
      <pubDate>Sat, 06 Sep 2025 12:25:10 +0800</pubDate>
      <guid>http://localhost:1313/posts/9.6_%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/</guid>
      <description>&lt;h3 id=&#34;eduagent-generative-student-agents-in-learning&#34;&gt;EduAgent: Generative Student Agents in Learning&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;本文是针对线上教育领域的学生模仿相关的研究，之前的模型多利用庞大的数据对学生学习行为进行预测，随着LLM的问世，LLM提供的前置知识能很好的针对不同场景不同内容线上教育的学生行为预测。&lt;/p&gt;
&lt;p&gt;学生行为预测受到多方面的影响，如性格、学生储备知识等，本文提供了一个数据集（350个sample），针对一段5分钟的幻灯片讲解，提供学生个人信息和每个小时间段的学生注意窗口、行为、认知状态信息等。&lt;/p&gt;
&lt;p&gt;作者结合LLM强大的推理功能，让LLM自主推理出不同信息间的关联，从而实现学生行为的预测和模仿，但这篇论文的实验没咋看懂&amp;hellip;&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;llm-mediated-domain-specific-voice-agents-the-case-of-textilebot&#34;&gt;LLM-mediated domain-specific voice agents: the case of TextileBot&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;粗粒度地看了下&amp;hellip;&lt;/p&gt;
&lt;p&gt;只看了摘要和引言和结论，讲的是如何原型化地设计一个垂直领域的对话agent，包含prompt模板，随后作者自己设计了一个宣传服装环保领域的一个agent（在购物的时候跟顾客交流的），并做了用户实验。&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;why-language-models-hallucinate&#34;&gt;Why language models hallucinate&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://openai.com/index/why-language-models-hallucinate/&#34;&gt;Why language models hallucinate | OpenAI&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;OpenAI 9月5号刚发布的文章，主要讲述了为什么大语言模型会产生幻觉。&lt;/p&gt;
&lt;p&gt;作者描述，LLM（大语言模型）之所以产生幻觉，是因为现在对模型后训练的奖励函数，往往将答错一道题和拒答一道题（承认不知道）的惩罚都是一致的，导致LLM更倾向于去猜题，这样还有概率猜对。&lt;/p&gt;
&lt;p&gt;那有人就会说了，让答错的惩罚提升一些不就行了。确实可以，但是作者回应到现如今大多数的benchmark，只有对/错两个选项，并没有考虑到幻觉的因素，从而导致大家更宁愿LLM猜题，增加一些benchmark的准确率，而不是拒答（大幅度降低幻觉，但准确率会略微降低）。&lt;/p&gt;
&lt;p&gt;作者呼吁所有benchmark的制作者们，将幻觉这个评价指标加入到benchmark的评测之中，从而抑制LLM的胡言乱语。但现在的benchmark对幻觉的评判往往是特定的一类，大多数benmark没有考虑幻觉因素。&lt;/p&gt;
&lt;p&gt;上面都是通过后训练降低LLM幻觉的途径，那能不能在预训练的时候降低大语言模型的幻觉呢？作者回答，现在的数据都是无监督的，导致LLM并没有办法对每段数据的真实性做判断，更好的办法还是在后训练的时候减少大模型的幻觉。&lt;/p&gt;
&lt;p&gt;下面文字是原文的提出的LLM幻觉的一些误解与澄清：&lt;/p&gt;
&lt;p&gt;我们希望论文中的统计视角能够澄清幻觉（hallucinations）的本质，并纠正一些常见的误解：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;主张：&lt;/strong&gt; 通过提高准确率可以消除幻觉，因为一个 100% 准确的模型永远不会产生幻觉。
&lt;strong&gt;发现：&lt;/strong&gt; 准确率永远无法达到 100%，因为无论模型规模、检索能力和推理能力如何，一些现实世界中的问题本质上是无法回答的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;主张：&lt;/strong&gt; 幻觉是不可避免的。
&lt;strong&gt;发现：&lt;/strong&gt; 不是的，因为语言模型在不确定时可以选择不作答。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;主张：&lt;/strong&gt; 避免幻觉需要一种只能通过更大模型才能实现的智能水平。
&lt;strong&gt;发现：&lt;/strong&gt; 小模型有时更容易知道自己的局限。例如，当被问到毛利语问题时，一个完全不懂毛利语的小模型可以直接说“我不知道”；而一个懂一些毛利语的模型则需要判断自己的置信度。正如论文中所讨论的，“校准”所需的计算量远小于“准确”。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;主张：&lt;/strong&gt; 幻觉是现代语言模型中的某种神秘故障。
&lt;strong&gt;发现：&lt;/strong&gt; 我们理解幻觉产生并在评估中被奖励的统计机制。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;主张：&lt;/strong&gt; 衡量幻觉，只需要一个好的幻觉评测。
&lt;strong&gt;发现：&lt;/strong&gt; 已经有幻觉评测被发表。然而，一个好的幻觉评测在数百个传统的基于准确率的评测面前几乎无效，因为后者会惩罚谦逊、奖励猜测。因此，所有主要的评测指标都需要重新设计，以奖励表达不确定性的能力。&lt;/p&gt;</description>
    </item>
    <item>
      <title>9.5 论文阅读</title>
      <link>http://localhost:1313/posts/9%E6%9C%885%E6%97%A5%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/</link>
      <pubDate>Fri, 05 Sep 2025 13:35:14 +0800</pubDate>
      <guid>http://localhost:1313/posts/9%E6%9C%885%E6%97%A5%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/</guid>
      <description>&lt;h3 id=&#34;llm-agents-for-education-advances-and-applications&#34;&gt;LLM Agents for Education: Advances and Applications&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这是一篇综述论文，讲述了现在LLM agents在领域的各种运用。作者将教育agent分为 教学agent 和 垂直领域agent。&lt;/p&gt;
&lt;p&gt;教学agent又分为面向学生和面向教师的，垂直领域的分为很多不同学科类的agent，不同学科agent也有不同的功能的agent，整体分类思维导图见下图。&lt;/p&gt;
&lt;p&gt;然后作者讲述了，现有教育agent所面临的困难，如道德、偏见方面的，也有幻觉、可靠性方面的。现有的agent大多数不具备结构化的形式（更多是对话类型），无法直接在现实教育场景中插入。&lt;/p&gt;
&lt;p&gt;最后整理介绍了现有测评教育agent各种benchmark，以供后来研究者使用。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&#34;image-20250905134524279&#34; loading=&#34;lazy&#34; src=&#34;http://localhost:1313/posts/9%E6%9C%885%E6%97%A5%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/image-20250905134524279.png&#34;&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;mathagent-leveraging-a-mixture-of-math-agent-framework-for-real-world-multimodal-mathematical-error-detection&#34;&gt;MATHAGENT: Leveraging a Mixture-of-Math-Agent Framework for Real-World Multimodal Mathematical Error Detection&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;背景&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;大语言模型在数学问题求解中已经非常厉害了，但是在数学错误发现上还很少涉足。传统的数学老师批改，耗时耗力，并且不具备可扩展性，如无法为学生指明学生具体错误（人工成本高），多模态大模型可以识别图片，并且为学生提供错误位置和错误分类，但是MLLM还在存在较多错误，对于有细微错误的地方无法很好识别。并且现在研究多聚焦纯文本数学题改错，对于带有图片信息的不能很好应对。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;方法&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;数据集合为下图，有文本问题描述，图片类信息，正确答案，学生的不正确答案，解题步骤。
任务分为  1：找到第一个错误步骤，2：错误分类，指标都是准确率。&lt;/p&gt;
&lt;img src=&#34;image-20250905153558820.png&#34; alt=&#34;image-20250905153558820&#34; style=&#34;zoom:67%;&#34; /&gt;
&lt;p&gt;作者引入了个多智能体框架，分为三个部分，流程如下图。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;文本-图像一致性检测：判断图片和文字是否高度一致，避免使用图片识别功能，从而增强题目解读能力&lt;/li&gt;
&lt;li&gt;公式-表格识别：用专门model将各种公式、表格等识别为文本形式&lt;/li&gt;
&lt;li&gt;融合找错：将文本和转文本的图片信息融合为一个完整题目，并且让LLM完成上面具体两个任务&lt;img src=&#34;image-20250905153953903.png&#34; alt=&#34;image-20250905153953903&#34; style=&#34;zoom:67%;&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;实验结果&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;将该方法运用到多个多模态大模型，大部分都能提升准确率，但相较于人工还有很大的差距。
&lt;img alt=&#34;image-20250905154103167&#34; loading=&#34;lazy&#34; src=&#34;http://localhost:1313/posts/9%E6%9C%885%E6%97%A5%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/image-20250905154103167.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;论文写的浅显易懂，结构也很清晰，可惜本论文并未公布数据集。。。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
