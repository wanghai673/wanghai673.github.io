<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>10.9 记录 | Wanghai673 | 博客</title><meta name=keywords content="记录"><meta name=description content="Transformer 架构学习
学习了 self-attention、multi-head attention 机制，位置编码等，并手动搭建了 Transformer 架构。并利用 Transfomer 框架实现了一个名字实体识别、问答生成的任务（模型参数没上去，表现不如 RNN）。

LLM 历史了解
1、GPT, GPT-2, GPT-3
GPT，GPT-2，GPT-3 论文精读【论文精读】_哔哩哔哩_bilibili

GPT：Transformer 的 Decoder Only 的模型始祖
GPT-2：加大参数量，并在 fewshot 领域实现进步，但较同时期 Bert 进步不明显
GPT-3：继续加大参数和数据量，模型能力在微调和 fewshot 后大大提升

2、Bert
BERT 论文逐段精读【论文精读】_哔哩哔哩_bilibili
Encoder Only 的模型始祖
3、Instruct GPT
InstructGPT 论文精读【论文精读·48】_哔哩哔哩_bilibili
RLHF 就是这里来的
4、GPT-4
GPT-4 论文精读【论文精读·53】_哔哩哔哩_bilibili
模型能力涌现
5、Llama 3.1
经典的开源大模型
Llama 3.1 论文精读 · 1. 导言【论文精读·54】_哔哩哔哩_bilibili
大模型 SFT
雷智凯同学总结的文档来学习大模型的 SFT 微调，一步步的教学 transformer 库的核心函数是怎么用的，如 tokenizer，AutoModelForCausalLM 等；手动搭建 Dataset。
练习：对病句改错数据集进行 SFT 微调
📘 Few-shot 示例

  
      
          用户输入 (user)
          模型输出 (assistant)
      
  
  
      
          全国光伏发电平均利用率达 98%，利用水平明显提高。
          全国光伏发电平均利用率达 98%，利用水平明显提高。
      
      
          #晚安.spuer#希望我们都能在山川尔尔里找到让自己感到快乐还有意义的事，并坚持下去。
          #晚安.spuer#希望我们都能在山川尔里找到让自己感到快乐还有意义的事，并坚持下去。
      
      
          按照定逾期未检验车辆不得上路行驶。
          按照规定逾期未检验车辆不得上路行驶。
      
      
          ✨ 你终回像星星那般发光发亮早安#早安#
          ✨ 你总会像星星那般发光发亮早安#早安#
      
  


🔬 LLM Finetune 实验结果表

  
      
          ID
          System Prompt
          Finetune
          Few-shot
          Avg. Acc (%)
          Pos. Acc (%)
          Neg. Acc (%)
      
  
  
      
          6
          ✅
          ✅
          ✅
          56.02
          82.4
          30.35
      
      
          4
          ✅
          ✅
          ❌
          53.55
          71.4
          36.19
      
      
          5
          ✅
          ❌
          ✅
          9.76
          16.4
          3.31
      
      
          2
          ✅
          ❌
          ❌
          7.30
          12.20
          2.53
      
      
          3
          ❌
          ✅
          ❌
          3.55
          5.2
          1.95
      
      
          1
          ❌
          ❌
          ❌
          0
          0
          0
      
  


💡 总结观察

System Prompt + Finetune + Few-shot (ID 6) 组合效果最佳，平均准确率最高（56.02%），正样本识别表现尤其突出（82.4%）。
仅使用 System Prompt + Finetune (ID 4) 也表现良好，但略低于全组合。
缺少 Finetune 或 Few-shot 时（如 ID 5、2），性能急剧下降。
无任何增强 (ID 1) 表现最差，验证了各增强手段的重要性。

ID 6 微调 checkpoint 下变化
"><meta name=author content="Wanghai673"><link rel=canonical href=http://localhost:1313/posts/10.9_%E8%AE%B0%E5%BD%95/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.e0ba3545db7c40d4a40a6600ba4c0ca0c92ea8e60a1c1f89a93f15fb7438773c.css integrity="sha256-4Lo1Rdt8QNSkCmYAukwMoMkuqOYKHB+JqT8V+3Q4dzw=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/images/dog.svg><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/images/dog.svg><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/images/dog.svg><link rel=apple-touch-icon href=http://localhost:1313/images/dog.svg><link rel=mask-icon href=http://localhost:1313/images/dog.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:1313/posts/10.9_%E8%AE%B0%E5%BD%95/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css integrity=sha384-wcIxkf4k558AjM3Yz3BBFQUbk/zgIYC2R0QpeeYb+TwlBVMrlgLqwRjRtGZiK7ww crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.js integrity=sha384-hIoBPJpTUs74ddyc4bFZSM1TVlQDA60VBbJS0oA934VSz82sBx1X7kSx2ATBDIyd crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/contrib/auto-render.min.js integrity=sha384-43gviWU0YVjaDtb/GhzOouOXtZMP/7XUzwPTstBeZFe/+rCMvRwr4yROQP43s0Xk crossorigin=anonymous onload='window.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})'></script><meta property="og:url" content="http://localhost:1313/posts/10.9_%E8%AE%B0%E5%BD%95/"><meta property="og:site_name" content="Wanghai673 | 博客"><meta property="og:title" content="10.9 记录"><meta property="og:description" content="Transformer 架构学习 学习了 self-attention、multi-head attention 机制，位置编码等，并手动搭建了 Transformer 架构。并利用 Transfomer 框架实现了一个名字实体识别、问答生成的任务（模型参数没上去，表现不如 RNN）。
LLM 历史了解 1、GPT, GPT-2, GPT-3
GPT，GPT-2，GPT-3 论文精读【论文精读】_哔哩哔哩_bilibili
GPT：Transformer 的 Decoder Only 的模型始祖 GPT-2：加大参数量，并在 fewshot 领域实现进步，但较同时期 Bert 进步不明显 GPT-3：继续加大参数和数据量，模型能力在微调和 fewshot 后大大提升 2、Bert
BERT 论文逐段精读【论文精读】_哔哩哔哩_bilibili
Encoder Only 的模型始祖
3、Instruct GPT
InstructGPT 论文精读【论文精读·48】_哔哩哔哩_bilibili
RLHF 就是这里来的
4、GPT-4
GPT-4 论文精读【论文精读·53】_哔哩哔哩_bilibili
模型能力涌现
5、Llama 3.1
经典的开源大模型
Llama 3.1 论文精读 · 1. 导言【论文精读·54】_哔哩哔哩_bilibili
大模型 SFT 雷智凯同学总结的文档来学习大模型的 SFT 微调，一步步的教学 transformer 库的核心函数是怎么用的，如 tokenizer，AutoModelForCausalLM 等；手动搭建 Dataset。
练习：对病句改错数据集进行 SFT 微调 📘 Few-shot 示例 用户输入 (user) 模型输出 (assistant) 全国光伏发电平均利用率达 98%，利用水平明显提高。 全国光伏发电平均利用率达 98%，利用水平明显提高。 #晚安.spuer#希望我们都能在山川尔尔里找到让自己感到快乐还有意义的事，并坚持下去。 #晚安.spuer#希望我们都能在山川尔里找到让自己感到快乐还有意义的事，并坚持下去。 按照定逾期未检验车辆不得上路行驶。 按照规定逾期未检验车辆不得上路行驶。 ✨ 你终回像星星那般发光发亮早安#早安# ✨ 你总会像星星那般发光发亮早安#早安# 🔬 LLM Finetune 实验结果表 ID System Prompt Finetune Few-shot Avg. Acc (%) Pos. Acc (%) Neg. Acc (%) 6 ✅ ✅ ✅ 56.02 82.4 30.35 4 ✅ ✅ ❌ 53.55 71.4 36.19 5 ✅ ❌ ✅ 9.76 16.4 3.31 2 ✅ ❌ ❌ 7.30 12.20 2.53 3 ❌ ✅ ❌ 3.55 5.2 1.95 1 ❌ ❌ ❌ 0 0 0 💡 总结观察 System Prompt + Finetune + Few-shot (ID 6) 组合效果最佳，平均准确率最高（56.02%），正样本识别表现尤其突出（82.4%）。 仅使用 System Prompt + Finetune (ID 4) 也表现良好，但略低于全组合。 缺少 Finetune 或 Few-shot 时（如 ID 5、2），性能急剧下降。 无任何增强 (ID 1) 表现最差，验证了各增强手段的重要性。 ID 6 微调 checkpoint 下变化 "><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-10-07T19:59:05+08:00"><meta property="article:modified_time" content="2025-10-07T19:59:05+08:00"><meta property="article:tag" content="记录"><meta property="og:image" content="http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="10.9 记录"><meta name=twitter:description content="Transformer 架构学习
学习了 self-attention、multi-head attention 机制，位置编码等，并手动搭建了 Transformer 架构。并利用 Transfomer 框架实现了一个名字实体识别、问答生成的任务（模型参数没上去，表现不如 RNN）。

LLM 历史了解
1、GPT, GPT-2, GPT-3
GPT，GPT-2，GPT-3 论文精读【论文精读】_哔哩哔哩_bilibili

GPT：Transformer 的 Decoder Only 的模型始祖
GPT-2：加大参数量，并在 fewshot 领域实现进步，但较同时期 Bert 进步不明显
GPT-3：继续加大参数和数据量，模型能力在微调和 fewshot 后大大提升

2、Bert
BERT 论文逐段精读【论文精读】_哔哩哔哩_bilibili
Encoder Only 的模型始祖
3、Instruct GPT
InstructGPT 论文精读【论文精读·48】_哔哩哔哩_bilibili
RLHF 就是这里来的
4、GPT-4
GPT-4 论文精读【论文精读·53】_哔哩哔哩_bilibili
模型能力涌现
5、Llama 3.1
经典的开源大模型
Llama 3.1 论文精读 · 1. 导言【论文精读·54】_哔哩哔哩_bilibili
大模型 SFT
雷智凯同学总结的文档来学习大模型的 SFT 微调，一步步的教学 transformer 库的核心函数是怎么用的，如 tokenizer，AutoModelForCausalLM 等；手动搭建 Dataset。
练习：对病句改错数据集进行 SFT 微调
📘 Few-shot 示例

  
      
          用户输入 (user)
          模型输出 (assistant)
      
  
  
      
          全国光伏发电平均利用率达 98%，利用水平明显提高。
          全国光伏发电平均利用率达 98%，利用水平明显提高。
      
      
          #晚安.spuer#希望我们都能在山川尔尔里找到让自己感到快乐还有意义的事，并坚持下去。
          #晚安.spuer#希望我们都能在山川尔里找到让自己感到快乐还有意义的事，并坚持下去。
      
      
          按照定逾期未检验车辆不得上路行驶。
          按照规定逾期未检验车辆不得上路行驶。
      
      
          ✨ 你终回像星星那般发光发亮早安#早安#
          ✨ 你总会像星星那般发光发亮早安#早安#
      
  


🔬 LLM Finetune 实验结果表

  
      
          ID
          System Prompt
          Finetune
          Few-shot
          Avg. Acc (%)
          Pos. Acc (%)
          Neg. Acc (%)
      
  
  
      
          6
          ✅
          ✅
          ✅
          56.02
          82.4
          30.35
      
      
          4
          ✅
          ✅
          ❌
          53.55
          71.4
          36.19
      
      
          5
          ✅
          ❌
          ✅
          9.76
          16.4
          3.31
      
      
          2
          ✅
          ❌
          ❌
          7.30
          12.20
          2.53
      
      
          3
          ❌
          ✅
          ❌
          3.55
          5.2
          1.95
      
      
          1
          ❌
          ❌
          ❌
          0
          0
          0
      
  


💡 总结观察

System Prompt + Finetune + Few-shot (ID 6) 组合效果最佳，平均准确率最高（56.02%），正样本识别表现尤其突出（82.4%）。
仅使用 System Prompt + Finetune (ID 4) 也表现良好，但略低于全组合。
缺少 Finetune 或 Few-shot 时（如 ID 5、2），性能急剧下降。
无任何增强 (ID 1) 表现最差，验证了各增强手段的重要性。

ID 6 微调 checkpoint 下变化
"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://localhost:1313/posts/"},{"@type":"ListItem","position":2,"name":"10.9 记录","item":"http://localhost:1313/posts/10.9_%E8%AE%B0%E5%BD%95/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"10.9 记录","name":"10.9 记录","description":"Transformer 架构学习 学习了 self-attention、multi-head attention 机制，位置编码等，并手动搭建了 Transformer 架构。并利用 Transfomer 框架实现了一个名字实体识别、问答生成的任务（模型参数没上去，表现不如 RNN）。\nLLM 历史了解 1、GPT, GPT-2, GPT-3\nGPT，GPT-2，GPT-3 论文精读【论文精读】_哔哩哔哩_bilibili\nGPT：Transformer 的 Decoder Only 的模型始祖 GPT-2：加大参数量，并在 fewshot 领域实现进步，但较同时期 Bert 进步不明显 GPT-3：继续加大参数和数据量，模型能力在微调和 fewshot 后大大提升 2、Bert\nBERT 论文逐段精读【论文精读】_哔哩哔哩_bilibili\nEncoder Only 的模型始祖\n3、Instruct GPT\nInstructGPT 论文精读【论文精读·48】_哔哩哔哩_bilibili\nRLHF 就是这里来的\n4、GPT-4\nGPT-4 论文精读【论文精读·53】_哔哩哔哩_bilibili\n模型能力涌现\n5、Llama 3.1\n经典的开源大模型\nLlama 3.1 论文精读 · 1. 导言【论文精读·54】_哔哩哔哩_bilibili\n大模型 SFT 雷智凯同学总结的文档来学习大模型的 SFT 微调，一步步的教学 transformer 库的核心函数是怎么用的，如 tokenizer，AutoModelForCausalLM 等；手动搭建 Dataset。\n练习：对病句改错数据集进行 SFT 微调 📘 Few-shot 示例 用户输入 (user) 模型输出 (assistant) 全国光伏发电平均利用率达 98%，利用水平明显提高。 全国光伏发电平均利用率达 98%，利用水平明显提高。 #晚安.spuer#希望我们都能在山川尔尔里找到让自己感到快乐还有意义的事，并坚持下去。 #晚安.spuer#希望我们都能在山川尔里找到让自己感到快乐还有意义的事，并坚持下去。 按照定逾期未检验车辆不得上路行驶。 按照规定逾期未检验车辆不得上路行驶。 ✨ 你终回像星星那般发光发亮早安#早安# ✨ 你总会像星星那般发光发亮早安#早安# 🔬 LLM Finetune 实验结果表 ID System Prompt Finetune Few-shot Avg. Acc (%) Pos. Acc (%) Neg. Acc (%) 6 ✅ ✅ ✅ 56.02 82.4 30.35 4 ✅ ✅ ❌ 53.55 71.4 36.19 5 ✅ ❌ ✅ 9.76 16.4 3.31 2 ✅ ❌ ❌ 7.30 12.20 2.53 3 ❌ ✅ ❌ 3.55 5.2 1.95 1 ❌ ❌ ❌ 0 0 0 💡 总结观察 System Prompt + Finetune + Few-shot (ID 6) 组合效果最佳，平均准确率最高（56.02%），正样本识别表现尤其突出（82.4%）。 仅使用 System Prompt + Finetune (ID 4) 也表现良好，但略低于全组合。 缺少 Finetune 或 Few-shot 时（如 ID 5、2），性能急剧下降。 无任何增强 (ID 1) 表现最差，验证了各增强手段的重要性。 ID 6 微调 checkpoint 下变化 ","keywords":["记录"],"articleBody":"Transformer 架构学习 学习了 self-attention、multi-head attention 机制，位置编码等，并手动搭建了 Transformer 架构。并利用 Transfomer 框架实现了一个名字实体识别、问答生成的任务（模型参数没上去，表现不如 RNN）。\nLLM 历史了解 1、GPT, GPT-2, GPT-3\nGPT，GPT-2，GPT-3 论文精读【论文精读】_哔哩哔哩_bilibili\nGPT：Transformer 的 Decoder Only 的模型始祖 GPT-2：加大参数量，并在 fewshot 领域实现进步，但较同时期 Bert 进步不明显 GPT-3：继续加大参数和数据量，模型能力在微调和 fewshot 后大大提升 2、Bert\nBERT 论文逐段精读【论文精读】_哔哩哔哩_bilibili\nEncoder Only 的模型始祖\n3、Instruct GPT\nInstructGPT 论文精读【论文精读·48】_哔哩哔哩_bilibili\nRLHF 就是这里来的\n4、GPT-4\nGPT-4 论文精读【论文精读·53】_哔哩哔哩_bilibili\n模型能力涌现\n5、Llama 3.1\n经典的开源大模型\nLlama 3.1 论文精读 · 1. 导言【论文精读·54】_哔哩哔哩_bilibili\n大模型 SFT 雷智凯同学总结的文档来学习大模型的 SFT 微调，一步步的教学 transformer 库的核心函数是怎么用的，如 tokenizer，AutoModelForCausalLM 等；手动搭建 Dataset。\n练习：对病句改错数据集进行 SFT 微调 📘 Few-shot 示例 用户输入 (user) 模型输出 (assistant) 全国光伏发电平均利用率达 98%，利用水平明显提高。 全国光伏发电平均利用率达 98%，利用水平明显提高。 #晚安.spuer#希望我们都能在山川尔尔里找到让自己感到快乐还有意义的事，并坚持下去。 #晚安.spuer#希望我们都能在山川尔里找到让自己感到快乐还有意义的事，并坚持下去。 按照定逾期未检验车辆不得上路行驶。 按照规定逾期未检验车辆不得上路行驶。 ✨ 你终回像星星那般发光发亮早安#早安# ✨ 你总会像星星那般发光发亮早安#早安# 🔬 LLM Finetune 实验结果表 ID System Prompt Finetune Few-shot Avg. Acc (%) Pos. Acc (%) Neg. Acc (%) 6 ✅ ✅ ✅ 56.02 82.4 30.35 4 ✅ ✅ ❌ 53.55 71.4 36.19 5 ✅ ❌ ✅ 9.76 16.4 3.31 2 ✅ ❌ ❌ 7.30 12.20 2.53 3 ❌ ✅ ❌ 3.55 5.2 1.95 1 ❌ ❌ ❌ 0 0 0 💡 总结观察 System Prompt + Finetune + Few-shot (ID 6) 组合效果最佳，平均准确率最高（56.02%），正样本识别表现尤其突出（82.4%）。 仅使用 System Prompt + Finetune (ID 4) 也表现良好，但略低于全组合。 缺少 Finetune 或 Few-shot 时（如 ID 5、2），性能急剧下降。 无任何增强 (ID 1) 表现最差，验证了各增强手段的重要性。 ID 6 微调 checkpoint 下变化 这张图展示了 短训练周期 下模型在不同 checkpoint 的正样本与负样本准确率变化趋势：\n橙线（Positive Accuracy）：随训练进行迅速上升，从约 17% 提升到接近 96%，并在后期保持稳定。 蓝线（Negative Accuracy）：增长缓慢，整体维持在 5%–10% 区间，说明模型早期主要学习了正样本特征，而对负样本区分能力仍较弱。 这张图展示了 长训练周期 下模型在不同 checkpoint 的正样本与负样本准确率变化趋势：\n正样本准确率（橙线）：从约 85% 提升至 94.8%，随后保持在高位，说明模型对正确样本的识别能力持续增强。 负样本准确率（蓝线）：从约 14% 稳步提升至 30% 左右，增长缓慢但持续，表明模型逐渐学会区分错误样本。 这张图展示了 不同 checkpoint 下模型的平均准确率变化趋势：\n长训练周期（橙线）：模型准确率从约 49% 稳步提升至接近 59%，在 120–210 checkpoint 区间达到高点并趋于稳定，说明模型已收敛。 短训练周期（蓝线）：准确率快速上升，在第 9–10 个 checkpoint 达到约 50% 后趋于平稳，说明早期学习效率高，但提升空间有限。 ","wordCount":"229","inLanguage":"en","image":"http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E","datePublished":"2025-10-07T19:59:05+08:00","dateModified":"2025-10-07T19:59:05+08:00","author":{"@type":"Person","name":"Wanghai673"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/posts/10.9_%E8%AE%B0%E5%BD%95/"},"publisher":{"@type":"Organization","name":"Wanghai673 | 博客","logo":{"@type":"ImageObject","url":"http://localhost:1313/images/dog.svg"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="Wanghai673 | 博客 (Alt + H)"><img src=http://localhost:1313/apple-touch-icon.png alt aria-label=logo height=35>Wanghai673 | 博客</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://localhost:1313/tags/ title="🏷️ 标签"><span>🏷️ 标签</span></a></li><li><a href=http://localhost:1313/search/ title="🔍 搜索 (Alt + /)" accesskey=/><span>🔍 搜索</span></a></li><li><a href=http://localhost:1313/about/ title="🙋 关于"><span>🙋 关于</span></a></li><li><a href=http://localhost:1313/archives/ title="📚 归档"><span>📚 归档</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://localhost:1313/>Home</a>&nbsp;»&nbsp;<a href=http://localhost:1313/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">10.9 记录</h1><div class=post-meta><span title='2025-10-07 19:59:05 +0800 CST'>2025年10月07日</span>&nbsp;|&nbsp;<a href=https://github.com/wanghai673/wanghai673.github.io/tree/main/content/posts/10.9_%e8%ae%b0%e5%bd%95/index.md rel="noopener noreferrer edit" target=_blank>Suggest Changes</a></div></header><div class=post-content><h3 id=transformer-架构学习>Transformer 架构学习<a hidden class=anchor aria-hidden=true href=#transformer-架构学习>#</a></h3><p>学习了 self-attention、multi-head attention 机制，位置编码等，并手动搭建了 Transformer 架构。并利用 Transfomer 框架实现了一个<a href=https://www.coursera.org/learn/nlp-sequence-models/ungradedLab/RdNV9/transformer-network-application-named-entity-recognition/lab>名字实体识别</a>、<a href="https://www.coursera.org/learn/nlp-sequence-models/ungradedLab/6iTj6/transformer-network-application-question-answering/lab?path=%2Fnotebooks%2FW4A3_UGL%2FQA_dataset.ipynb">问答生成</a>的任务（模型参数没上去，表现不如 RNN）。</p><p><img alt=3319e3d6922a2e7f2499a3130d3b5925 loading=lazy src=/posts/10.9_%E8%AE%B0%E5%BD%95/3319e3d6922a2e7f2499a3130d3b5925.png></p><h3 id=llm-历史了解>LLM 历史了解<a hidden class=anchor aria-hidden=true href=#llm-历史了解>#</a></h3><p><strong>1、GPT, GPT-2, GPT-3</strong></p><p><a href="https://www.bilibili.com/video/BV1AF411b7xQ/?spm_id_from=333.1387.search.video_card.click&amp;vd_source=cf35d5107dda9df709c41cc1ec25735f">GPT，GPT-2，GPT-3 论文精读【论文精读】_哔哩哔哩_bilibili</a></p><ul><li>GPT：Transformer 的 Decoder Only 的模型始祖</li><li>GPT-2：加大参数量，并在 fewshot 领域实现进步，但较同时期 Bert 进步不明显</li><li>GPT-3：继续加大参数和数据量，模型能力在微调和 fewshot 后大大提升</li></ul><p><strong>2、Bert</strong></p><p><a href="https://www.bilibili.com/video/BV1PL411M7eQ/?spm_id_from=333.1387.search.video_card.click&amp;vd_source=2205a224ef8d2cd2b3b9cb444289192a">BERT 论文逐段精读【论文精读】_哔哩哔哩_bilibili</a></p><p>Encoder Only 的模型始祖</p><p><strong>3、Instruct GPT</strong></p><p><a href="https://www.bilibili.com/video/BV1hd4y187CR/?spm_id_from=333.337.search-card.all.click&amp;vd_source=cf35d5107dda9df709c41cc1ec25735f">InstructGPT 论文精读【论文精读·48】_哔哩哔哩_bilibili</a></p><p>RLHF 就是这里来的</p><p><strong>4、GPT-4</strong></p><p><a href="https://www.bilibili.com/video/BV1vM4y1U7b5/?spm_id_from=333.1387.search.video_card.click&amp;vd_source=cf35d5107dda9df709c41cc1ec25735f">GPT-4 论文精读【论文精读·53】_哔哩哔哩_bilibili</a></p><p>模型能力涌现</p><p><strong>5、Llama 3.1</strong></p><p>经典的开源大模型</p><p><a href="https://www.bilibili.com/video/BV1WM4m1y7Uh/?spm_id_from=333.788.videopod.sections&amp;vd_source=cf35d5107dda9df709c41cc1ec25735f">Llama 3.1 论文精读 · 1. 导言【论文精读·54】_哔哩哔哩_bilibili</a></p><h3 id=大模型-sft>大模型 SFT<a hidden class=anchor aria-hidden=true href=#大模型-sft>#</a></h3><p>雷智凯同学总结的文档来学习大模型的 SFT 微调，一步步的教学 transformer 库的核心函数是怎么用的，如 tokenizer，AutoModelForCausalLM 等；手动搭建 Dataset。</p><h4 id=练习对病句改错数据集进行-sft-微调><strong>练习</strong>：对病句改错数据集进行 SFT 微调<a hidden class=anchor aria-hidden=true href=#练习对病句改错数据集进行-sft-微调>#</a></h4><h3 id=-few-shot-示例>📘 Few-shot 示例<a hidden class=anchor aria-hidden=true href=#-few-shot-示例>#</a></h3><table><thead><tr><th>用户输入 (user)</th><th>模型输出 (assistant)</th></tr></thead><tbody><tr><td>全国光伏发电平均利用率达 98%，利用水平明显提高。</td><td>全国光伏发电平均利用率达 98%，利用水平明显提高。</td></tr><tr><td>#晚安.spuer#希望我们都能在山川尔尔里找到让自己感到快乐还有意义的事，并坚持下去。</td><td>#晚安.spuer#希望我们都能在山川尔里找到让自己感到快乐还有意义的事，并坚持下去。</td></tr><tr><td>按照定逾期未检验车辆不得上路行驶。</td><td>按照规定逾期未检验车辆不得上路行驶。</td></tr><tr><td>✨ 你终回像星星那般发光发亮早安#早安#</td><td>✨ 你总会像星星那般发光发亮早安#早安#</td></tr></tbody></table><hr><h3 id=-llm-finetune-实验结果表>🔬 LLM Finetune 实验结果表<a hidden class=anchor aria-hidden=true href=#-llm-finetune-实验结果表>#</a></h3><table><thead><tr><th>ID</th><th>System Prompt</th><th>Finetune</th><th>Few-shot</th><th>Avg. Acc (%)</th><th>Pos. Acc (%)</th><th>Neg. Acc (%)</th></tr></thead><tbody><tr><td><strong>6</strong></td><td>✅</td><td>✅</td><td>✅</td><td><strong>56.02</strong></td><td><strong>82.4</strong></td><td><strong>30.35</strong></td></tr><tr><td><strong>4</strong></td><td>✅</td><td>✅</td><td>❌</td><td>53.55</td><td>71.4</td><td>36.19</td></tr><tr><td><strong>5</strong></td><td>✅</td><td>❌</td><td>✅</td><td>9.76</td><td>16.4</td><td>3.31</td></tr><tr><td><strong>2</strong></td><td>✅</td><td>❌</td><td>❌</td><td>7.30</td><td>12.20</td><td>2.53</td></tr><tr><td><strong>3</strong></td><td>❌</td><td>✅</td><td>❌</td><td>3.55</td><td>5.2</td><td>1.95</td></tr><tr><td><strong>1</strong></td><td>❌</td><td>❌</td><td>❌</td><td>0</td><td>0</td><td>0</td></tr></tbody></table><hr><h3 id=-总结观察>💡 总结观察<a hidden class=anchor aria-hidden=true href=#-总结观察>#</a></h3><ul><li><strong>System Prompt + Finetune + Few-shot (ID 6)</strong> 组合效果最佳，平均准确率最高（56.02%），正样本识别表现尤其突出（82.4%）。</li><li>仅使用 <strong>System Prompt + Finetune (ID 4)</strong> 也表现良好，但略低于全组合。</li><li>缺少 Finetune 或 Few-shot 时（如 ID 5、2），性能急剧下降。</li><li><strong>无任何增强 (ID 1)</strong> 表现最差，验证了各增强手段的重要性。</li></ul><h4 id=id-6-微调-checkpoint-下变化>ID 6 微调 checkpoint 下变化<a hidden class=anchor aria-hidden=true href=#id-6-微调-checkpoint-下变化>#</a></h4><p><img alt="output (4)" loading=lazy src=/posts/10.9_%E8%AE%B0%E5%BD%95/output_4.png></p><p>这张图展示了 <strong>短训练周期</strong> 下模型在不同 checkpoint 的正样本与负样本准确率变化趋势：</p><ul><li><strong>橙线（Positive Accuracy）</strong>：随训练进行迅速上升，从约 17% 提升到接近 <strong>96%</strong>，并在后期保持稳定。</li><li><strong>蓝线（Negative Accuracy）</strong>：增长缓慢，整体维持在 <strong>5%–10%</strong> 区间，说明模型早期主要学习了正样本特征，而对负样本区分能力仍较弱。</li></ul><hr><p><img alt="output (3)" loading=lazy src=/posts/10.9_%E8%AE%B0%E5%BD%95/output_3.png></p><p>这张图展示了 <strong>长训练周期</strong> 下模型在不同 checkpoint 的正样本与负样本准确率变化趋势：</p><ul><li><strong>正样本准确率（橙线）</strong>：从约 85% 提升至 <strong>94.8%</strong>，随后保持在高位，说明模型对正确样本的识别能力持续增强。</li><li><strong>负样本准确率（蓝线）</strong>：从约 14% 稳步提升至 <strong>30% 左右</strong>，增长缓慢但持续，表明模型逐渐学会区分错误样本。</li></ul><hr><p><img alt="output (2)" loading=lazy src=/posts/10.9_%E8%AE%B0%E5%BD%95/output_2.png></p><p>这张图展示了 <strong>不同 checkpoint 下模型的平均准确率变化趋势</strong>：</p><ul><li><strong>长训练周期（橙线）</strong>：模型准确率从约 49% 稳步提升至接近 <strong>59%</strong>，在 120–210 checkpoint 区间达到高点并趋于稳定，说明模型已收敛。</li><li><strong>短训练周期（蓝线）</strong>：准确率快速上升，在第 9–10 个 checkpoint 达到约 <strong>50%</strong> 后趋于平稳，说明早期学习效率高，但提升空间有限。</li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=http://localhost:1313/tags/%E8%AE%B0%E5%BD%95/>记录</a></li></ul><nav class=paginav><a class=next href=http://localhost:1313/posts/%E7%BB%84%E4%BC%9A%E5%B1%95%E7%A4%BA/><span class=title>Next »</span><br><span>组会展示</span></a></nav></footer><div class=comments-title id=tw-comment-title><p class=x-comments-title>欢迎来到评论区</p><p style=font-size:1rem>感谢您的耐心阅读！来选个表情，或者留个评论吧！</p></div><div id=tw-comment></div><script>const getStoredTheme=()=>localStorage.getItem("pref-theme")==="dark"?"dark":"light",setGiscusTheme=()=>{const e=e=>{const t=document.querySelector("iframe.giscus-frame");t&&t.contentWindow.postMessage({giscus:e},"https://giscus.app")};e({setConfig:{theme:getStoredTheme()}})};document.addEventListener("DOMContentLoaded",()=>{const s={src:"https://giscus.app/client.js","data-repo":"wanghai673/wanghai673.github.io","data-repo-id":"R_kgDOPfU1mg","data-category":"Announcements","data-category-id":"DIC_kwDOPfU1ms4CuRXc","data-mapping":"pathname","data-strict":"0","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"top","data-theme":getStoredTheme(),"data-lang":"zh-CN","data-loading":"lazy",crossorigin:"anonymous",async:""},e=document.createElement("script");Object.entries(s).forEach(([t,n])=>e.setAttribute(t,n)),document.querySelector("#tw-comment").appendChild(e);const t=document.querySelector("#theme-toggle");t&&t.addEventListener("click",setGiscusTheme);const n=document.querySelector("#theme-toggle-float");n&&n.addEventListener("click",setGiscusTheme)})</script></article></main><footer class=footer><span>&copy; 2025 <a href=http://localhost:1313/>Wanghai673 | 博客</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>