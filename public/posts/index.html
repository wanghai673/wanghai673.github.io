<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Posts | Wanghai673 | 博客</title><meta name=keywords content><meta name=description content="Posts - Wanghai673 | 博客"><meta name=author content="Wanghai673"><link rel=canonical href=http://localhost:1313/posts/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.e0ba3545db7c40d4a40a6600ba4c0ca0c92ea8e60a1c1f89a93f15fb7438773c.css integrity="sha256-4Lo1Rdt8QNSkCmYAukwMoMkuqOYKHB+JqT8V+3Q4dzw=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/images/dog.svg><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/images/dog.svg><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/images/dog.svg><link rel=apple-touch-icon href=http://localhost:1313/images/dog.svg><link rel=mask-icon href=http://localhost:1313/images/dog.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=http://localhost:1313/posts/index.xml><link rel=alternate hreflang=en href=http://localhost:1313/posts/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css integrity=sha384-wcIxkf4k558AjM3Yz3BBFQUbk/zgIYC2R0QpeeYb+TwlBVMrlgLqwRjRtGZiK7ww crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.js integrity=sha384-hIoBPJpTUs74ddyc4bFZSM1TVlQDA60VBbJS0oA934VSz82sBx1X7kSx2ATBDIyd crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/contrib/auto-render.min.js integrity=sha384-43gviWU0YVjaDtb/GhzOouOXtZMP/7XUzwPTstBeZFe/+rCMvRwr4yROQP43s0Xk crossorigin=anonymous onload='window.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})'></script><meta property="og:url" content="http://localhost:1313/posts/"><meta property="og:site_name" content="Wanghai673 | 博客"><meta property="og:title" content="Posts"><meta property="og:description" content="ExampleSite description"><meta property="og:locale" content="en"><meta property="og:type" content="website"><meta property="og:image" content="http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Posts"><meta name=twitter:description content="ExampleSite description"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://localhost:1313/posts/"}]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="Wanghai673 | 博客 (Alt + H)"><img src=http://localhost:1313/apple-touch-icon.png alt aria-label=logo height=35>Wanghai673 | 博客</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://localhost:1313/tags/ title="🏷️ 标签"><span>🏷️ 标签</span></a></li><li><a href=http://localhost:1313/search/ title="🔍 搜索 (Alt + /)" accesskey=/><span>🔍 搜索</span></a></li><li><a href=http://localhost:1313/about/ title="🙋 关于"><span>🙋 关于</span></a></li><li><a href=http://localhost:1313/archives/ title="📚 归档"><span>📚 归档</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=http://localhost:1313/>Home</a></div><h1>Posts</h1></header><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Verl 框架下 GRPO 调参：GSM8K 实验记录（Qwen3-0.6B）</h2></header><div class=entry-content><p>背景 初始Qwen3-0.6B在GSM8K的准确率不到20%，问题主要分为以下两种情况：
未能按照prompt的答案格式 输出 答案 未能计算出正确答案 经测试主要发现准确率低的原因是主要是前者导致，少部分是后者。本质上就是小模型的指令跟随和推理能力的不足。
如今LLM已经有大量不同的微调方式，如强化学习微调、SFT等方向，本实验为探索GRPO在LLM微调的效果上限与优势。
目标 通过 GRPO 微调 Qwen3-0.6B，寻找在 验证集上的最优超参数组合。 使用 Qwen32B 生成答案进行蒸馏 + LoRA 微调 Qwen3-0.6B，并与 GRPO 方案对比。 方法概览 框架：Verl 基座模型：Qwen3-0.6B 优化：GRPO 对比：Qwen32B 蒸馏 → LoRA on Qwen3-0.6B 调节的超参数 超参数 重要度 推荐范围 / 设定 当前值 影响 / 说明 学习率 (LoRA, actor.optim.lr) ⭐⭐⭐⭐⭐ 1e-5 ～ 5e-5 5e-5 直接影响收敛与最终性能，建议从小到大网格/二分搜。 响应数量 (rollout.n) ⭐⭐⭐⭐ 5 ～ 16 5 / 16 更多样本可提升 GRPO 信号质量，但显著增算力。 KL 系数 (kl_loss_coef) ⭐⭐⭐⭐ 1e-4 ～ 1e-2 1e-3 约束与参考模型偏离度；过大抑制探索、过小易漂移。 批次大小 ⭐⭐⭐⭐ train 64/128/256/512；mini 32/64/128；micro 4/8/16 128 / 64 / 16 更大批次更稳（受显存限制）。 采样温度 (temperature) ⭐⭐ 0.7 / 1.0 / 1.2 1.0 多样性与探索；高温度利探索但易噪声。 Top-p (top_p) ⭐⭐ 0.7 / 0.9 / 1.0 1.0 控制尾部截断；与温度配合调度探索强度。 实验计划 调整verl框架的GRPO的超参数，微调Qwen3-0.6B，探索最大验证集表现的超参数。 使用Qwen32B模型，蒸馏答案，Lora微调Qwen3-0.6B，并与上面方式对比。 实验过程 初始实验 首先在使用LLM生产了一组初始参数，并跑通。
...</p></div><footer class=entry-footer><span title='2025-10-18 13:17:15 +0800 CST'>2025年10月18日</span></footer><a class=entry-link aria-label="post link to Verl 框架下 GRPO 调参：GSM8K 实验记录（Qwen3-0.6B）" href=http://localhost:1313/posts/verl%E6%A1%86%E6%9E%B6gpro%E8%B0%83%E5%8F%82gsm8k/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>10.9 记录</h2></header><div class=entry-content><p>Transformer 架构学习 学习了 self-attention、multi-head attention 机制，位置编码等，并手动搭建了 Transformer 架构。并利用 Transfomer 框架实现了一个名字实体识别、问答生成的任务（模型参数没上去，表现不如 RNN）。
LLM 历史了解 1、GPT, GPT-2, GPT-3
GPT，GPT-2，GPT-3 论文精读【论文精读】_哔哩哔哩_bilibili
GPT：Transformer 的 Decoder Only 的模型始祖 GPT-2：加大参数量，并在 fewshot 领域实现进步，但较同时期 Bert 进步不明显 GPT-3：继续加大参数和数据量，模型能力在微调和 fewshot 后大大提升 2、Bert
BERT 论文逐段精读【论文精读】_哔哩哔哩_bilibili
Encoder Only 的模型始祖
3、Instruct GPT
InstructGPT 论文精读【论文精读·48】_哔哩哔哩_bilibili
RLHF 就是这里来的
4、GPT-4
GPT-4 论文精读【论文精读·53】_哔哩哔哩_bilibili
模型能力涌现
5、Llama 3.1
经典的开源大模型
Llama 3.1 论文精读 · 1. 导言【论文精读·54】_哔哩哔哩_bilibili
大模型 SFT 雷智凯同学总结的文档来学习大模型的 SFT 微调，一步步的教学 transformer 库的核心函数是怎么用的，如 tokenizer，AutoModelForCausalLM 等；手动搭建 Dataset。
练习：对病句改错数据集进行 SFT 微调 📘 Few-shot 示例 用户输入 (user) 模型输出 (assistant) 全国光伏发电平均利用率达 98%，利用水平明显提高。 全国光伏发电平均利用率达 98%，利用水平明显提高。 #晚安.spuer#希望我们都能在山川尔尔里找到让自己感到快乐还有意义的事，并坚持下去。 #晚安.spuer#希望我们都能在山川尔里找到让自己感到快乐还有意义的事，并坚持下去。 按照定逾期未检验车辆不得上路行驶。 按照规定逾期未检验车辆不得上路行驶。 ✨ 你终回像星星那般发光发亮早安#早安# ✨ 你总会像星星那般发光发亮早安#早安# 🔬 LLM Finetune 实验结果表 ID System Prompt Finetune Few-shot Avg. Acc (%) Pos. Acc (%) Neg. Acc (%) 6 ✅ ✅ ✅ 56.02 82.4 30.35 4 ✅ ✅ ❌ 53.55 71.4 36.19 5 ✅ ❌ ✅ 9.76 16.4 3.31 2 ✅ ❌ ❌ 7.30 12.20 2.53 3 ❌ ✅ ❌ 3.55 5.2 1.95 1 ❌ ❌ ❌ 0 0 0 💡 总结观察 System Prompt + Finetune + Few-shot (ID 6) 组合效果最佳，平均准确率最高（56.02%），正样本识别表现尤其突出（82.4%）。 仅使用 System Prompt + Finetune (ID 4) 也表现良好，但略低于全组合。 缺少 Finetune 或 Few-shot 时（如 ID 5、2），性能急剧下降。 无任何增强 (ID 1) 表现最差，验证了各增强手段的重要性。 ID 6 微调 checkpoint 下变化 ...</p></div><footer class=entry-footer><span title='2025-10-07 19:59:05 +0800 CST'>2025年10月07日</span></footer><a class=entry-link aria-label="post link to 10.9 记录" href=http://localhost:1313/posts/10.9_%E8%AE%B0%E5%BD%95/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>组会展示
<span class=entry-hint title=Draft><svg height="20" viewBox="0 -960 960 960" fill="currentColor"><path d="M160-410v-60h3e2v60H160zm0-165v-60h470v60H160zm0-165v-60h470v60H160zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22-4.5 22.5T862.09-380L643-160H520zm3e2-263-37-37 37 37zM580-220h38l121-122-18-19-19-18-122 121v38zm141-141-19-18 37 37-18-19z"/></svg></span></h2></header><div class=entry-content><p>Transformer 架构学习 学习了 self-attention、multi-head attention 机制，位置编码等，并手动搭建了 Transformer 架构。并利用 Transfomer 框架实现了一个名字实体识别、问答生成的任务（模型参数没上去，表现不如 RNN）。
LLM 历史了解 1、GPT, GPT-2, GPT-3
GPT，GPT-2，GPT-3 论文精读【论文精读】_哔哩哔哩_bilibili
GPT：Transformer 的 Decoder Only 的模型始祖 GPT-2：加大参数量，并在 fewshot 领域实现进步，但较同时期 Bert 进步不明显 GPT-3：继续加大参数和数据量，模型能力在微调和 fewshot 后大大提升 2、Bert
BERT 论文逐段精读【论文精读】_哔哩哔哩_bilibili
Encoder Only 的模型始祖
3、Instruct GPT
InstructGPT 论文精读【论文精读·48】_哔哩哔哩_bilibili
RLHF 就是这里来的
4、GPT-4
GPT-4 论文精读【论文精读·53】_哔哩哔哩_bilibili
模型能力涌现
5、Llama 3.1
经典的开源大模型
Llama 3.1 论文精读 · 1. 导言【论文精读·54】_哔哩哔哩_bilibili
大模型 SFT 雷智凯同学总结的文档来学习大模型的 SFT 微调，一步步的教学 transformer 库的核心函数是怎么用的，如 tokenizer，AutoModelForCausalLM 等；手动搭建 Dataset。
练习：对病句改错数据集进行 SFT 微调 📘 Few-shot 示例 用户输入 (user) 模型输出 (assistant) 全国光伏发电平均利用率达 98%，利用水平明显提高。 全国光伏发电平均利用率达 98%，利用水平明显提高。 #晚安.spuer#希望我们都能在山川尔尔里找到让自己感到快乐还有意义的事，并坚持下去。 #晚安.spuer#希望我们都能在山川尔里找到让自己感到快乐还有意义的事，并坚持下去。 按照定逾期未检验车辆不得上路行驶。 按照规定逾期未检验车辆不得上路行驶。 ✨ 你终回像星星那般发光发亮早安#早安# ✨ 你总会像星星那般发光发亮早安#早安# 🔬 LLM Finetune 实验结果表 ID System Prompt Finetune Few-shot Avg. Acc (%) Pos. Acc (%) Neg. Acc (%) 6 ✅ ✅ ✅ 56.02 82.4 30.35 4 ✅ ✅ ❌ 53.55 71.4 36.19 5 ✅ ❌ ✅ 9.76 16.4 3.31 2 ✅ ❌ ❌ 7.30 12.20 2.53 3 ❌ ✅ ❌ 3.55 5.2 1.95 1 ❌ ❌ ❌ 0 0 0 💡 总结观察 System Prompt + Finetune + Few-shot (ID 6) 组合效果最佳，平均准确率最高（56.02%），正样本识别表现尤其突出（82.4%）。 仅使用 System Prompt + Finetune (ID 4) 也表现良好，但略低于全组合。 缺少 Finetune 或 Few-shot 时（如 ID 5、2），性能急剧下降。 无任何增强 (ID 1) 表现最差，验证了各增强手段的重要性。 ID 6 微调 checkpoint 下变化 ![output (4)](output (4).png)
...</p></div><footer class=entry-footer><span title='2025-10-07 19:59:05 +0800 CST'>2025年10月07日</span></footer><a class=entry-link aria-label="post link to 组会展示" href=http://localhost:1313/posts/%E7%BB%84%E4%BC%9A%E5%B1%95%E7%A4%BA/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>9.24 记录</h2></header><div class=entry-content><p>Coursera上的深度学习课程算是完成了个大概，序列模型里还是学到很多实用的知识，如RNN、GRU、LSTM、Embedding、Attention机制、transformer模型。
下面是原始RNN的一些知识点和发展历史：
RNN的不同应用 语音识别 音乐生成 情感分类 DNA序列分析 机器翻译 视频活动识别 命名实体识别 RNN的架构类型 RNN的生成语言模型 和 采样 学习beamsearch算法对模型生产序列进行采样，本质上也是种贪心算法。
引入LSTM和GRU 传统RNN随着上下文一长，由于模型隐藏层变量大小限制，会丢失掉部分上下文信息。随后，引入了记忆门的装置，能够使得记忆信息直接传递给后续节点。
GRU结构：
LSTM结构：
对于特定问题，如完形填空等，需要不仅前文内容，还需要后文的内容随后，引入双向RNN。
一个全连接层可能，无法很好提取上下文信息，随后引入深度RNN
之后完成了JAZZ创造的生成式RNN的作业：https://www.coursera.org/learn/nlp-sequence-models/programming/ZS7X2/jazz-improvisation-with-lstm/lab
课程内容都浅显易懂，并且配有作业。在上面的学习，主要深刻意识到了DL是一个很厉害的工具，我们可以用他做很多有意义的事情，并服务人类。而且并没有什么应用难度，人人都可以学习DL这个工具，应用到自己生活中（虽然黑盒，也就因为黑盒，才能超越人类认知）…
后面主要继续深入LLM的学习中，多看一些LLM经典论文，先打好基础，再投入到前沿研究中。</p></div><footer class=entry-footer><span title='2025-09-24 16:10:02 +0800 CST'>2025年09月24日</span></footer><a class=entry-link aria-label="post link to 9.24 记录" href=http://localhost:1313/posts/9.24_%E8%AE%B0%E5%BD%95/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>9.16 论文阅读</h2></header><div class=entry-content><p>SIMULATING HUMAN-LIKE DAILY ACTIVITIES WITH DESIRE-DRIVEN AUTONOMY 总结
现在有许多使用大语言模型模拟人类行为的相关论文，使用强化学习训练等方法，但这些方法的大多数只限定为特定场景，无法拓展到人类日常生活中多样变化的场景中。
作者引入了欲望驱使的大预言模型agent，来预测模拟人们日常一天生活中的行为，分为了两个模块：环境模拟、欲望驱使agent。
环境模拟主要使用了Concordia论文的方法，做了一个日常生活的模拟器。
欲望驱使agent更为复杂，其中最重要的部分便是欲望上下文的生成：DESIRE GENERATION，VALUE SYSTEM FOR DESIRE EVALUATION。
DESIRE GENERATION：通过预设好的相关标准，将不同形容词的不同程度映射为一个值。
VALUE SYSTEM FOR DESIRE EVALUATION分为三部分：
Quantitative Value Deduction：做选择题，推理出形容词不同值 Qualitative Value Description：根据value做出总体描述 Value Update：更新值 实验没咋看，准备还是看些对模型参数层面修改的论文，如LLM微调、强化学习等的论文。</p></div><footer class=entry-footer><span title='2025-09-16 15:46:03 +0800 CST'>2025年09月16日</span></footer><a class=entry-link aria-label="post link to 9.16 论文阅读" href=http://localhost:1313/posts/9.16_%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/></a></article><footer class=page-footer><nav class=pagination><a class=next href=http://localhost:1313/posts/page/2/>Next&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2025 <a href=http://localhost:1313/>Wanghai673 | 博客</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>