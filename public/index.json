[{"content":"EduAgent: Generative Student Agents in Learning 总结\n本文是针对线上教育领域的学生模仿相关的研究，之前的模型多利用庞大的数据对学生学习行为进行预测，随着LLM的问世，LLM提供的前置知识能很好的针对不同场景不同内容线上教育的学生行为预测。\n学生行为预测受到多方面的影响，如性格、学生储备知识等，本文提供了一个数据集（350个sample），针对一段5分钟的幻灯片讲解，提供学生个人信息和每个小时间段的学生注意窗口、行为、认知状态信息等。\n作者结合LLM强大的推理功能，让LLM自主推理出不同信息间的关联，从而实现学生行为的预测和模仿，但这篇论文的实验没咋看懂\u0026hellip;\nLLM-mediated domain-specific voice agents: the case of TextileBot 总结\n粗粒度地看了下\u0026hellip;\n只看了摘要和引言和结论，讲的是如何原型化地设计一个垂直领域的对话agent，包含prompt模板，随后作者自己设计了一个宣传服装环保领域的一个agent（在购物的时候跟顾客交流的），并做了用户实验。\nWhy language models hallucinate 总结\nWhy language models hallucinate | OpenAI\nOpenAI 9月5号刚发布的文章，主要讲述了为什么大语言模型会产生幻觉。\n作者描述，LLM（大语言模型）之所以产生幻觉，是因为现在对模型后训练的奖励函数，往往将答错一道题和拒答一道题（承认不知道）的惩罚都是一致的，导致LLM更倾向于去猜题，这样还有概率猜对。\n那有人就会说了，让答错的惩罚提升一些不就行了。确实可以，但是作者回应到现如今大多数的benchmark，只有对/错两个选项，并没有考虑到幻觉的因素，从而导致大家更宁愿LLM猜题，增加一些benchmark的准确率，而不是拒答（大幅度降低幻觉，但准确率会略微降低）。\n作者呼吁所有benchmark的制作者们，将幻觉这个评价指标加入到benchmark的评测之中，从而抑制LLM的胡言乱语。但现在的benchmark对幻觉的评判往往是特定的一类，大多数benmark没有考虑幻觉因素。\n上面都是通过后训练降低LLM幻觉的途径，那能不能在预训练的时候降低大语言模型的幻觉呢？作者回答，现在的数据都是无监督的，导致LLM并没有办法对每段数据的真实性做判断，更好的办法还是在后训练的时候减少大模型的幻觉。\n下面文字是原文的提出的LLM幻觉的一些误解与澄清：\n我们希望论文中的统计视角能够澄清幻觉（hallucinations）的本质，并纠正一些常见的误解：\n主张： 通过提高准确率可以消除幻觉，因为一个 100% 准确的模型永远不会产生幻觉。 发现： 准确率永远无法达到 100%，因为无论模型规模、检索能力和推理能力如何，一些现实世界中的问题本质上是无法回答的。\n主张： 幻觉是不可避免的。 发现： 不是的，因为语言模型在不确定时可以选择不作答。\n主张： 避免幻觉需要一种只能通过更大模型才能实现的智能水平。 发现： 小模型有时更容易知道自己的局限。例如，当被问到毛利语问题时，一个完全不懂毛利语的小模型可以直接说“我不知道”；而一个懂一些毛利语的模型则需要判断自己的置信度。正如论文中所讨论的，“校准”所需的计算量远小于“准确”。\n主张： 幻觉是现代语言模型中的某种神秘故障。 发现： 我们理解幻觉产生并在评估中被奖励的统计机制。\n主张： 衡量幻觉，只需要一个好的幻觉评测。 发现： 已经有幻觉评测被发表。然而，一个好的幻觉评测在数百个传统的基于准确率的评测面前几乎无效，因为后者会惩罚谦逊、奖励猜测。因此，所有主要的评测指标都需要重新设计，以奖励表达不确定性的能力。\n","permalink":"http://localhost:1313/posts/9.6_%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/","summary":"\u003ch3 id=\"eduagent-generative-student-agents-in-learning\"\u003eEduAgent: Generative Student Agents in Learning\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e总结\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e本文是针对线上教育领域的学生模仿相关的研究，之前的模型多利用庞大的数据对学生学习行为进行预测，随着LLM的问世，LLM提供的前置知识能很好的针对不同场景不同内容线上教育的学生行为预测。\u003c/p\u003e\n\u003cp\u003e学生行为预测受到多方面的影响，如性格、学生储备知识等，本文提供了一个数据集（350个sample），针对一段5分钟的幻灯片讲解，提供学生个人信息和每个小时间段的学生注意窗口、行为、认知状态信息等。\u003c/p\u003e\n\u003cp\u003e作者结合LLM强大的推理功能，让LLM自主推理出不同信息间的关联，从而实现学生行为的预测和模仿，但这篇论文的实验没咋看懂\u0026hellip;\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"llm-mediated-domain-specific-voice-agents-the-case-of-textilebot\"\u003eLLM-mediated domain-specific voice agents: the case of TextileBot\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e总结\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e粗粒度地看了下\u0026hellip;\u003c/p\u003e\n\u003cp\u003e只看了摘要和引言和结论，讲的是如何原型化地设计一个垂直领域的对话agent，包含prompt模板，随后作者自己设计了一个宣传服装环保领域的一个agent（在购物的时候跟顾客交流的），并做了用户实验。\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"why-language-models-hallucinate\"\u003eWhy language models hallucinate\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e总结\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://openai.com/index/why-language-models-hallucinate/\"\u003eWhy language models hallucinate | OpenAI\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eOpenAI 9月5号刚发布的文章，主要讲述了为什么大语言模型会产生幻觉。\u003c/p\u003e\n\u003cp\u003e作者描述，LLM（大语言模型）之所以产生幻觉，是因为现在对模型后训练的奖励函数，往往将答错一道题和拒答一道题（承认不知道）的惩罚都是一致的，导致LLM更倾向于去猜题，这样还有概率猜对。\u003c/p\u003e\n\u003cp\u003e那有人就会说了，让答错的惩罚提升一些不就行了。确实可以，但是作者回应到现如今大多数的benchmark，只有对/错两个选项，并没有考虑到幻觉的因素，从而导致大家更宁愿LLM猜题，增加一些benchmark的准确率，而不是拒答（大幅度降低幻觉，但准确率会略微降低）。\u003c/p\u003e\n\u003cp\u003e作者呼吁所有benchmark的制作者们，将幻觉这个评价指标加入到benchmark的评测之中，从而抑制LLM的胡言乱语。但现在的benchmark对幻觉的评判往往是特定的一类，大多数benmark没有考虑幻觉因素。\u003c/p\u003e\n\u003cp\u003e上面都是通过后训练降低LLM幻觉的途径，那能不能在预训练的时候降低大语言模型的幻觉呢？作者回答，现在的数据都是无监督的，导致LLM并没有办法对每段数据的真实性做判断，更好的办法还是在后训练的时候减少大模型的幻觉。\u003c/p\u003e\n\u003cp\u003e下面文字是原文的提出的LLM幻觉的一些误解与澄清：\u003c/p\u003e\n\u003cp\u003e我们希望论文中的统计视角能够澄清幻觉（hallucinations）的本质，并纠正一些常见的误解：\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e主张：\u003c/strong\u003e 通过提高准确率可以消除幻觉，因为一个 100% 准确的模型永远不会产生幻觉。\n\u003cstrong\u003e发现：\u003c/strong\u003e 准确率永远无法达到 100%，因为无论模型规模、检索能力和推理能力如何，一些现实世界中的问题本质上是无法回答的。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e主张：\u003c/strong\u003e 幻觉是不可避免的。\n\u003cstrong\u003e发现：\u003c/strong\u003e 不是的，因为语言模型在不确定时可以选择不作答。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e主张：\u003c/strong\u003e 避免幻觉需要一种只能通过更大模型才能实现的智能水平。\n\u003cstrong\u003e发现：\u003c/strong\u003e 小模型有时更容易知道自己的局限。例如，当被问到毛利语问题时，一个完全不懂毛利语的小模型可以直接说“我不知道”；而一个懂一些毛利语的模型则需要判断自己的置信度。正如论文中所讨论的，“校准”所需的计算量远小于“准确”。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e主张：\u003c/strong\u003e 幻觉是现代语言模型中的某种神秘故障。\n\u003cstrong\u003e发现：\u003c/strong\u003e 我们理解幻觉产生并在评估中被奖励的统计机制。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e主张：\u003c/strong\u003e 衡量幻觉，只需要一个好的幻觉评测。\n\u003cstrong\u003e发现：\u003c/strong\u003e 已经有幻觉评测被发表。然而，一个好的幻觉评测在数百个传统的基于准确率的评测面前几乎无效，因为后者会惩罚谦逊、奖励猜测。因此，所有主要的评测指标都需要重新设计，以奖励表达不确定性的能力。\u003c/p\u003e","title":"9.6 论文阅读"},{"content":"LLM Agents for Education: Advances and Applications 总结\n这是一篇综述论文，讲述了现在LLM agents在领域的各种运用。作者将教育agent分为 教学agent 和 垂直领域agent。\n教学agent又分为面向学生和面向教师的，垂直领域的分为很多不同学科类的agent，不同学科agent也有不同的功能的agent，整体分类思维导图见下图。\n然后作者讲述了，现有教育agent所面临的困难，如道德、偏见方面的，也有幻觉、可靠性方面的。现有的agent大多数不具备结构化的形式（更多是对话类型），无法直接在现实教育场景中插入。\n最后整理介绍了现有测评教育agent各种benchmark，以供后来研究者使用。\nMATHAGENT: Leveraging a Mixture-of-Math-Agent Framework for Real-World Multimodal Mathematical Error Detection 背景\n大语言模型在数学问题求解中已经非常厉害了，但是在数学错误发现上还很少涉足。传统的数学老师批改，耗时耗力，并且不具备可扩展性，如无法为学生指明学生具体错误（人工成本高），多模态大模型可以识别图片，并且为学生提供错误位置和错误分类，但是MLLM还在存在较多错误，对于有细微错误的地方无法很好识别。并且现在研究多聚焦纯文本数学题改错，对于带有图片信息的不能很好应对。\n方法\n数据集合为下图，有文本问题描述，图片类信息，正确答案，学生的不正确答案，解题步骤。 任务分为 1：找到第一个错误步骤，2：错误分类，指标都是准确率。\n作者引入了个多智能体框架，分为三个部分，流程如下图。\n文本-图像一致性检测：判断图片和文字是否高度一致，避免使用图片识别功能，从而增强题目解读能力 公式-表格识别：用专门model将各种公式、表格等识别为文本形式 融合找错：将文本和转文本的图片信息融合为一个完整题目，并且让LLM完成上面具体两个任务 实验结果\n将该方法运用到多个多模态大模型，大部分都能提升准确率，但相较于人工还有很大的差距。 论文写的浅显易懂，结构也很清晰，可惜本论文并未公布数据集。。。\n","permalink":"http://localhost:1313/posts/9%E6%9C%885%E6%97%A5%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/","summary":"\u003ch3 id=\"llm-agents-for-education-advances-and-applications\"\u003eLLM Agents for Education: Advances and Applications\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e总结\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e这是一篇综述论文，讲述了现在LLM agents在领域的各种运用。作者将教育agent分为 教学agent 和 垂直领域agent。\u003c/p\u003e\n\u003cp\u003e教学agent又分为面向学生和面向教师的，垂直领域的分为很多不同学科类的agent，不同学科agent也有不同的功能的agent，整体分类思维导图见下图。\u003c/p\u003e\n\u003cp\u003e然后作者讲述了，现有教育agent所面临的困难，如道德、偏见方面的，也有幻觉、可靠性方面的。现有的agent大多数不具备结构化的形式（更多是对话类型），无法直接在现实教育场景中插入。\u003c/p\u003e\n\u003cp\u003e最后整理介绍了现有测评教育agent各种benchmark，以供后来研究者使用。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250905134524279\" loading=\"lazy\" src=\"/posts/9%E6%9C%885%E6%97%A5%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/image-20250905134524279.png\"\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"mathagent-leveraging-a-mixture-of-math-agent-framework-for-real-world-multimodal-mathematical-error-detection\"\u003eMATHAGENT: Leveraging a Mixture-of-Math-Agent Framework for Real-World Multimodal Mathematical Error Detection\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e背景\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e大语言模型在数学问题求解中已经非常厉害了，但是在数学错误发现上还很少涉足。传统的数学老师批改，耗时耗力，并且不具备可扩展性，如无法为学生指明学生具体错误（人工成本高），多模态大模型可以识别图片，并且为学生提供错误位置和错误分类，但是MLLM还在存在较多错误，对于有细微错误的地方无法很好识别。并且现在研究多聚焦纯文本数学题改错，对于带有图片信息的不能很好应对。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e方法\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e数据集合为下图，有文本问题描述，图片类信息，正确答案，学生的不正确答案，解题步骤。\n任务分为  1：找到第一个错误步骤，2：错误分类，指标都是准确率。\u003c/p\u003e\n\u003cimg src=\"image-20250905153558820.png\" alt=\"image-20250905153558820\" style=\"zoom:67%;\" /\u003e\n\u003cp\u003e作者引入了个多智能体框架，分为三个部分，流程如下图。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e文本-图像一致性检测：判断图片和文字是否高度一致，避免使用图片识别功能，从而增强题目解读能力\u003c/li\u003e\n\u003cli\u003e公式-表格识别：用专门model将各种公式、表格等识别为文本形式\u003c/li\u003e\n\u003cli\u003e融合找错：将文本和转文本的图片信息融合为一个完整题目，并且让LLM完成上面具体两个任务\u003cimg src=\"image-20250905153953903.png\" alt=\"image-20250905153953903\" style=\"zoom:67%;\" /\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e实验结果\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e将该方法运用到多个多模态大模型，大部分都能提升准确率，但相较于人工还有很大的差距。\n\u003cimg alt=\"image-20250905154103167\" loading=\"lazy\" src=\"/posts/9%E6%9C%885%E6%97%A5%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/image-20250905154103167.png\"\u003e\u003c/p\u003e\n\u003cp\u003e论文写的浅显易懂，结构也很清晰，可惜本论文并未公布数据集。。。\u003c/p\u003e","title":"9.5 论文阅读"},{"content":"最近闲着无聊随便做了一个windows的语音唤醒助手，主要是闲平常要出门，或者不方便的时候（比如运动、躺床上的时候），可以叫一声电脑就做我想让他做的内容（可以连接LLM/GUI agent/MCP等等）。\n再加上现在GUIAgent发展的很快，网上还没有语音唤醒形式的链接，也就自己搭了一个出来。\n下面是这个项目的readme。\nWinAssistant – Windows 本地语音唤醒与自动化执行 一个在 Windows 上运行的本地语音助手：\n说出唤醒词 → 识别你的语音 → 自动执行自定义动作（脚本、GUI Agent、MCP 等）。 全离线（唤醒+识别均可离线），即插即用，优先使用耳机麦克风。 演示视频 https://github.com/user-attachments/assets/a48b8e94-8b95-46eb-9aa5-a4085c2341c4\n✨ 核心特性 多唤醒词可选 / 可自定义 内置多种常见唤醒词，也可替换为你训练的 .ppn 文件。\n本地唤醒：Picovoice Porcupine 轻量、低延迟、可靠，离线运行。\n语音识别：fast-whisper 内置去噪、VAD 端点检测，自动判断“用户是否说完”，可按需调节模型大小（速度/准确度权衡）。\n自动音频设备选择 自动选择可用的输入/输出设备，优先耳机。\n可插拔“处理态” 识别到文本后进入你的“处理态”（可自定义），例如：\n调用 MCP / 工具调用 触发 GUI Agent 执行脚本、打开应用、查询信息等 🧠 工作流 / 状态机 stateDiagram-v2 [*] --\u0026gt; 空闲态 空闲态 --\u0026gt; 唤醒态: 语音唤醒 唤醒态 --\u0026gt; 处理态: 用户语音结束 处理态 --\u0026gt; 空闲态 唤醒态 --\u0026gt; 空闲态: 用户长时间无应答 空闲态 --\u0026gt; 空闲态: （持续监听） 说明：唤醒后进入实时听写；若检测到长时间静音则回退到空闲态。\n📦 目录结构 WINASSISTANT/ ├─ model/ │ ├─ 小智.ppn # 自定义/内置唤醒词（Porcupine） │ └─ porcupine_params_zh.pv # 中文参数 ├─ music/ # 系统提示音 │ ├─ ok.wav │ ├─ sorry.wav │ └─ zai.wav ├─ utils/ │ ├─ player.py # 播放器：播放提示音/反馈 │ ├─ reader.py # 识别器：fast-whisper + VAD │ ├─ rouser.py # 唤醒：Porcupine 推理 │ └─ UIoperator.py # 处理态模板（可自定义） ├─ .env # 环境变量（见下） ├─ main.py # 入口：python main.py └─ requirements.txt # 依赖 🚀 快速开始 1) 环境准备 Windows 10/11 Python 3.9+（建议 64-bit） 麦克风 \u0026amp; 扬声器/耳机 git clone https://github.com/wanghai673/WinAssistant cd WINASSISTANT # 建议：创建虚拟环境 python -m venv .venv .\\.venv\\Scripts\\activate pip install -r requirements.txt 2) 申请 Picovoice Access Key 前往 https://picovoice.ai/ 免费获取 ACCESS_KEY。\n3) 配置 .env 在项目根目录创建或修改 .env：\nACCESS_KEY=你的AccessKey # 唤醒词（可选：小智, hey google, grasshopper, computer, americano, # bumblebee, hey barista, ok google, pico clock, porcupine, # picovoice, jarvis, terminator, grapefruit, blueberry, alexa, hey siri） ROUSE_WORD=小智 想用自定义唤醒词？把训练好的 .ppn 文件放到 model/ 并在代码/ENV 中指向它即可。\n4) 运行 python main.py 说出唤醒词（默认 “小智”）→ 说出命令 → 听到提示音并执行。\n🧩 自定义“处理态” 识别结果会进入你的“处理态”模块（示例：utils/UIoperator.py）。 你可以在这里：\n串接 MCP 工具调用 通过 GUI Agent 操作桌面 执行脚本 / 打开应用 / 系统自动化 回放 music/ok.wav / sorry.wav 作为反馈 建议将业务逻辑与语音管线解耦：保留 player / reader / rouser 作为通用能力层，处理态专注于“要做什么”。\n⚙️ 常用调优点 VAD/静音阈值：在 reader.py 中调整 MAX_SILENCE_SECS 等参数，影响“说完就停”的敏感度。 模型大小：根据机器性能切换 fast-whisper 模型（小模型更快，大模型更准）。 提示音屏蔽：通过 realtime_zh(..., beep_guard=0.5) 吞掉前 0.5s 系统“滴”声，避免影响识别。 音频设备：默认自动选择，优先耳机；如需固定设备，可在 player/reader 中指定设备索引。 🔐 隐私与本地化 唤醒与识别均可离线完成；音频不会上传到云端。 仅在你显式配置联网服务时才会产生外部调用。 🧪 简单示例（伪代码） # 极简示例：监听唤醒 → 识别 from utils.player import Player from utils.reader import Reader from utils.rouser import Rouser from pvrecorder import PvRecorder from dotenv import load_dotenv import os load_dotenv() ACCESS_KEY = os.getenv(\u0026#34;ACCESS_KEY\u0026#34;) ROUSE_WORD = os.getenv(\u0026#34;ROUSE_WORD\u0026#34;, \u0026#34;小智\u0026#34;) DEVICE_INDEX = -1 # 使用系统默认输入设备 rouser = Rouser(access_key=ACCESS_KEY, device_index=DEVICE_INDEX, keyword=ROUSE_WORD) player = Player() reader = Reader(device_index=DEVICE_INDEX) recorder = PvRecorder(device_index=DEVICE_INDEX, frame_length=rouser.porcupine.frame_length) recorder.start() print(f\u0026#34;正在监听唤醒词：『{ROUSE_WORD}』 (Ctrl+C 退出)\u0026#34;) while True: pcm = recorder.read() if rouser.process(pcm) \u0026gt;= 0: # 检测到唤醒 player.play_voice(block=True) # 提示音 text = reader.realtime_zh(rec_shared=recorder, beep_guard=0.0) if text: print(\u0026#34;识别文本：\u0026#34;, text) player.play_voice(block=True, type=\u0026#34;ok\u0026#34;) # 在这里根据 text 执行动作... else: player.play_voice(block=True, type=\u0026#34;sorry\u0026#34;) 🧯 故障排查 没有反应 / 设备占用：检查是否有其他应用占用麦克风；尝试在系统声音设置中启用设备。 识别慢：试用更小的 fast-whisper 模型或关闭其他高占用程序。 唤醒不灵敏：更换更清晰的唤醒词模型 .ppn，或在安静环境下测试。 提示音被识别进去：增大 beep_guard（如 0.7）。 🙌 致谢 Picovoice Porcupine（本地唤醒） fast-whisper（快速 ASR） ","permalink":"http://localhost:1313/posts/windows%E8%AF%AD%E9%9F%B3%E5%94%A4%E9%86%92%E5%8A%A9%E6%89%8B/","summary":"\u003cp\u003e最近闲着无聊随便做了一个\u003ca href=\"https://github.com/wanghai673/WinAssistant/\"\u003ewindows的语音唤醒助手\u003c/a\u003e，主要是闲平常要出门，或者不方便的时候（比如运动、躺床上的时候），可以叫一声电脑就做我想让他做的内容（可以连接LLM/GUI agent/MCP等等）。\u003c/p\u003e\n\u003cp\u003e再加上现在GUIAgent发展的很快，网上还没有语音唤醒形式的链接，也就自己搭了一个出来。\u003c/p\u003e\n\u003cp\u003e下面是这个项目的readme。\u003c/p\u003e\n\u003ch1 id=\"winassistant--windows-本地语音唤醒与自动化执行\"\u003eWinAssistant – Windows 本地语音唤醒与自动化执行\u003c/h1\u003e\n\u003cp\u003e一个在 \u003cstrong\u003eWindows\u003c/strong\u003e 上运行的本地语音助手：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e说出唤醒词 → 识别你的语音 → 自动执行自定义动作（脚本、GUI Agent、MCP 等）。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e全离线\u003c/strong\u003e（唤醒+识别均可离线），即插即用，优先使用耳机麦克风。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"演示视频\"\u003e演示视频\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/user-attachments/assets/a48b8e94-8b95-46eb-9aa5-a4085c2341c4\"\u003ehttps://github.com/user-attachments/assets/a48b8e94-8b95-46eb-9aa5-a4085c2341c4\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"-核心特性\"\u003e✨ 核心特性\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e多唤醒词可选 / 可自定义\u003c/strong\u003e\n内置多种常见唤醒词，也可替换为你训练的 \u003ccode\u003e.ppn\u003c/code\u003e 文件。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e本地唤醒：Picovoice Porcupine\u003c/strong\u003e\n轻量、低延迟、可靠，离线运行。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e语音识别：fast-whisper\u003c/strong\u003e\n内置\u003cstrong\u003e去噪\u003c/strong\u003e、\u003cstrong\u003eVAD 端点检测\u003c/strong\u003e，自动判断“用户是否说完”，可按需调节模型大小（速度/准确度权衡）。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e自动音频设备选择\u003c/strong\u003e\n自动选择可用的输入/输出设备，\u003cstrong\u003e优先耳机\u003c/strong\u003e。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e可插拔“处理态”\u003c/strong\u003e\n识别到文本后进入你的“处理态”（可自定义），例如：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e调用 MCP / 工具调用\u003c/li\u003e\n\u003cli\u003e触发 GUI Agent\u003c/li\u003e\n\u003cli\u003e执行脚本、打开应用、查询信息等\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"-工作流--状态机\"\u003e🧠 工作流 / 状态机\u003c/h2\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode class=\"language-mermaid\" data-lang=\"mermaid\"\u003estateDiagram-v2\n    [*] --\u0026gt; 空闲态\n    空闲态 --\u0026gt; 唤醒态: 语音唤醒\n    唤醒态 --\u0026gt; 处理态: 用户语音结束\n    处理态 --\u0026gt; 空闲态\n    唤醒态 --\u0026gt; 空闲态: 用户长时间无应答\n    空闲态 --\u0026gt; 空闲态: （持续监听）\n\u003c/code\u003e\u003c/pre\u003e\u003cblockquote\u003e\n\u003cp\u003e说明：唤醒后进入实时听写；若检测到\u003cstrong\u003e长时间静音\u003c/strong\u003e则回退到空闲态。\u003c/p\u003e","title":"Windows语音唤醒助手"},{"content":"之前看过很多成功学/心理学众所周知的道理，但是都是空头说话，没有任何数据证明，但这门课，能通过实验的方式展示结果，看到了让我更加信服（科学是最大的迷信hhh）。\n课程纠正了我非常多的偏见，让我对自己有了更清晰的认识，强烈推荐给大家！\n下面是The Science of Well-Being | Coursera的LLM的总结。\n1. 幸福的常见误解 1.1 “知道就够了”（G.I. Joe 谬误） 仅“知道道理”并不会自动改变行为；需要情境与练习把“知道”变“做到”。 1.2 找工作与被拒 被拒的痛苦通常没想的那样强与久，心理免疫系统会缓冲。 1.3 金钱与收入 年轻人的价值观更偏向“高收入为先”。 收入增长与主观幸福并非一一对应；整体幸福感在富足年代并未同步上扬。 超过某一阈值后，收入主要提升“生活评价”，对日常情绪的边际效用有限。 1.4 “酷东西”与物质主义 流行文化强化对豪车、名酒等的向往。 物质主义目标与更低的长期满意度相关。 1.5 真爱与婚姻 婚后幸福感常在几年内回落到基线（适应效应）。 1.6 完美身材/整形与完美成绩 减重或整形未必带来更好的长期心理健康或幸福。 人们普遍高估成绩变化带来的情绪涨落。 幸福并非被基因与环境“写死”，相当比例可由行为与思维方式塑造。 2. 我们为什么总是判断失准 2.1 误想（Miswanting） 对“未来会多喜欢/多讨厌”经常判断错误。 2.2 相对参照点 我们按比较而非绝对值评估自己：同侪收入、媒体/社交媒体的呈现、班级曲线、外貌对比等都会扭曲感受与选择。 2.3 适应力强 对“好事/坏事”都会逐渐习惯：收入提升、中彩票、婚姻等皆会回到常态。 2.4 忽视我们会适应 预测未来情绪时，容易“聚焦于单一事件”并忽略适应与其他生活面向，导致高估负面事件的持续影响。 3. 如何克服偏误（可操作策略） 3.1 重新定义“酷东西”：投资体验而非物质 把钱与精力优先投入能被分享与反复回味的体验（旅行、学习、共创）。 3.2 阻断/延缓适应 品味/回味（savoring）：刻意思考并记录正向时刻。 积极回忆 \u0026amp; 书写消化：写下负面事件并完成认知加工。 负向想象：设想“若没有这件好事会怎样”，提升珍惜度。 时间稀缺：把某些体验当作“最后一次”，增强投入。 感恩练习：数祝福、写感谢信、表达谢意。 重置参照点：有意切换比较标准，校准高/低参照引发的偏差。 打断消费：给愉悦体验加入“短暂停”，延长新鲜感。 4. 真正更有效的幸福来源 4.1 更好的“想要”（Part 1） 优势运用：识别并在工作中高频使用个人优势，提升满足与“天职感”。 心流（Flow）：挑战×能力匹配，带来深度专注与高质量体验。 成长型思维：相信能力可发展，更能从挫折中学习与精进。 4.2 更好的“想要”（Part 2 \u0026amp; 3） 善意与给予：随机善举、为他人花钱、助人使人更幸福（跨文化成立）。 社会连接：重视亲密与日常社交；与陌生人开启对话、共享体验。 时间富足：优先时间而非金钱；思考“我如何用时间与人相处？”。 冥想与正念：降低走神、提升幸福、工作记忆与社会连结感。 健康习惯：规律运动与高质量睡眠，稳定情绪与认知表现。 5. 把策略落地：从“知道”到“做到” 5.1 情境支持（让好行为“更顺手”） 把诱因放远、把好选择放近：远离随手零食，台面摆水果；为运动与阅读预先布置环境。 5.2 目标设定（从愿望到执行） 具体目标：定义清晰的量化标准与截止时间。 实施意图（If–Then）：为关键情境写下触发语句（例：“如果吃完午饭，就散步10分钟”）。 WOOP 技术：愿望（Wish）→成果（Outcome）→障碍（Obstacle）→计划（Plan）。 5.3 速查清单（一周可上手） 每周一次新方式运用你的前五优势；在岗尽量覆盖≥4个优势。 把钱优先用在体验/他人上；为娱乐安排小而频繁的享受并刻意中断。 每日感恩 3 件事＋每周一封感谢讯息。 正念/慈心冥想10–15 分钟，配合每周≥3次运动与固定就寝/起床。 社交优先：与同事/陌生人开启短聊，把体验与人分享。 为关键习惯写 3 条 If–Then，并用 WOOP 复盘障碍与应对。 6. 主要参考 6.1 认知与预测偏误 Santos \u0026amp; Gendler (2014). Knowing is half the battle? Edge. Gilbert \u0026amp; Wilson (2000). Miswanting: Some problems in the forecasting of future affective states. Levine et al. (2012). Accuracy and artifact: Reexamining the intensity bias in affective forecasting. Dunn et al. (2002). Location, location, location. Ayton et al. (2007). Affective forecasting: Why can\u0026rsquo;t people predict their emotions? Gilbert et al. (1998). Immune neglect… Gilbert (2007). Stumbling on Happiness. 6.2 金钱与价值观 Eagan et al. (2015). The American Freshman Survey. LinkedIn Survey (2014). What recent grads care the most about. Diener \u0026amp; Oishi (2000). Money and happiness… Myers (2000). The American Paradox. Lyubomirsky (2007). The How of Happiness. Kahneman \u0026amp; Deaton (2010). High income improves evaluation of life… New York Times. Economic diversity and student outcomes at Yale University. 6.3 参照点与社会比较 Medvec et al. (1995). Olympic medalists \u0026amp; counterfactuals. van Praag \u0026amp; Frijters (1999). Leyden approach. Clark \u0026amp; Oswald (1996). Satisfaction and comparison income. Solnick \u0026amp; Hemenway (1997). Positional concerns. Clark (2003). Unemployment as a social norm. O’Guinn \u0026amp; Shrum (1997). Television \u0026amp; consumer reality. Schor (1999). The Overspent American. Kuhn et al. (2011). Dutch Postcode Lottery. Kenrick et al. (1989; 1993). Attractiveness \u0026amp; comparison. Vogel et al. (2014). Social media \u0026amp; self-esteem. Burleigh \u0026amp; Meegan (2013). Keeping Up with the Joneses \u0026amp; justice. 6.4 适应与物质/体验 Brickman et al. (1978). Lottery winners \u0026amp; accident victims. Di Tella et al. (2010). Adaptation to income \u0026amp; status. Lucas et al. (2003). Adaptation to marriage. Boven \u0026amp; Gilovich (2003). To do or to have? Kumar et al. (2014). Anticipatory consumption of experiential purchases. Pchelin \u0026amp; Howell (2014). Hidden cost of value-seeking. Howell \u0026amp; Hill (2009). Mediators of experiential purchases. Nelson \u0026amp; Meyvis (2008). Interrupted consumption. Nelson et al. (2009). Commercial interruptions \u0026amp; TV. 6.5 优势/心流/心态与善意社交时间 Seligman (2004); Seligman et al. (2005). Signature strengths \u0026amp; interventions. Lavy \u0026amp; Littman-Ovadia (2017); Harzer \u0026amp; Ruch (2012). Strengths at work. Csikszentmihalyi (1992; 2008; 1999). Flow. Deci (1971); Dweck (2007); Grant \u0026amp; Dweck (2003); Blackwell et al. (2007); Mangels et al. (2006). Growth mindset。 Otake et al. (2006); Lyubomirsky (2005); Dunn (2014); Dunn et al. (2008); Aknin et al. (2013). Kindness \u0026amp; prosocial spending. Myers (2000); Diener \u0026amp; Seligman (2002); Epley (2014); Epley \u0026amp; Schroeder (2014); Boothby et al. (2014). Social connection. Whillans et al. (2016); Hershfield et al. (2016); Moligner (2010). Time over money. 6.6 正念、健康与执行 Killingsworth \u0026amp; Gilbert (2010); Mason et al. (2007); Brewer et al. (2011); Fredrickson et al. (2008); Hölzel et al. (2011); Mrazek et al. (2013); Hutcherson et al. (2008). Mind-wandering \u0026amp; meditation. Babyak et al. (2000); Hillman et al. (2008). Exercise \u0026amp; cognition. Dinges et al. (1997); Walker et al. (2002); Wagner et al. (2004); Huffington Post（睡眠图解）. Sleep \u0026amp; performance. Wansink et al. (2006; 2016). Situation support \u0026amp; default choices. Klein et al. (1990); Gollwitzer \u0026amp; Brandstätter (1997); Stadler \u0026amp; Oettingen (2010); Duckworth et al. (2013); Stadler et al. (2009). 目标与实施意图/WOOP。 ","permalink":"http://localhost:1313/posts/the_science_of_well-being_%E6%80%BB%E7%BB%93/","summary":"\u003cp\u003e之前看过很多成功学/心理学众所周知的道理，但是都是空头说话，没有任何数据证明，但这门课，能通过实验的方式展示结果，看到了让我更加信服（科学是最大的迷信hhh）。\u003c/p\u003e\n\u003cp\u003e课程纠正了我非常多的偏见，让我对自己有了更清晰的认识，强烈推荐给大家！\u003c/p\u003e\n\u003cp\u003e下面是\u003ca href=\"https://www.coursera.org/learn/the-science-of-well-being\"\u003eThe Science of Well-Being | Coursera\u003c/a\u003e的LLM的总结。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"1-幸福的常见误解\"\u003e1. 幸福的常见误解\u003c/h2\u003e\n\u003ch3 id=\"11-知道就够了gi-joe-谬误\"\u003e1.1 “知道就够了”（G.I. Joe 谬误）\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e仅“知道道理”并不会自动改变行为；需要情境与练习把“知道”变“做到”。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"12-找工作与被拒\"\u003e1.2 找工作与被拒\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e被拒的痛苦通常没想的那样强与久，心理免疫系统会缓冲。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"13-金钱与收入\"\u003e1.3 金钱与收入\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e年轻人的价值观更偏向“高收入为先”。\u003c/li\u003e\n\u003cli\u003e收入增长与主观幸福并非一一对应；整体幸福感在富足年代并未同步上扬。\u003c/li\u003e\n\u003cli\u003e超过某一阈值后，收入主要提升“生活评价”，对日常情绪的边际效用有限。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"14-酷东西与物质主义\"\u003e1.4 “酷东西”与物质主义\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e流行文化强化对豪车、名酒等的向往。\u003c/li\u003e\n\u003cli\u003e物质主义目标与更低的长期满意度相关。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"15-真爱与婚姻\"\u003e1.5 真爱与婚姻\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e婚后幸福感常在几年内回落到基线（适应效应）。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"16-完美身材整形与完美成绩\"\u003e1.6 完美身材/整形与完美成绩\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e减重或整形未必带来更好的长期心理健康或幸福。\u003c/li\u003e\n\u003cli\u003e人们普遍高估成绩变化带来的情绪涨落。\u003c/li\u003e\n\u003cli\u003e幸福并非被基因与环境“写死”，相当比例可由行为与思维方式塑造。\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"2-我们为什么总是判断失准\"\u003e2. 我们为什么总是判断失准\u003c/h2\u003e\n\u003ch3 id=\"21-误想miswanting\"\u003e2.1 误想（Miswanting）\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e对“未来会多喜欢/多讨厌”经常判断错误。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"22-相对参照点\"\u003e2.2 相对参照点\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e我们按比较而非绝对值评估自己：同侪收入、媒体/社交媒体的呈现、班级曲线、外貌对比等都会扭曲感受与选择。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"23-适应力强\"\u003e2.3 适应力强\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e对“好事/坏事”都会逐渐习惯：收入提升、中彩票、婚姻等皆会回到常态。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"24-忽视我们会适应\"\u003e2.4 忽视我们会适应\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e预测未来情绪时，容易“聚焦于单一事件”并忽略适应与其他生活面向，导致高估负面事件的持续影响。\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"3-如何克服偏误可操作策略\"\u003e3. 如何克服偏误（可操作策略）\u003c/h2\u003e\n\u003ch3 id=\"31-重新定义酷东西投资体验而非物质\"\u003e3.1 重新定义“酷东西”：投资体验而非物质\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e把钱与精力优先投入能被分享与反复回味的体验（旅行、学习、共创）。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"32-阻断延缓适应\"\u003e3.2 阻断/延缓适应\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e品味/回味（savoring）\u003c/strong\u003e：刻意思考并记录正向时刻。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e积极回忆 \u0026amp; 书写消化\u003c/strong\u003e：写下负面事件并完成认知加工。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e负向想象\u003c/strong\u003e：设想“若没有这件好事会怎样”，提升珍惜度。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e时间稀缺\u003c/strong\u003e：把某些体验当作“最后一次”，增强投入。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e感恩练习\u003c/strong\u003e：数祝福、写感谢信、表达谢意。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e重置参照点\u003c/strong\u003e：有意切换比较标准，校准高/低参照引发的偏差。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e打断消费\u003c/strong\u003e：给愉悦体验加入“短暂停”，延长新鲜感。\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"4-真正更有效的幸福来源\"\u003e4. 真正更有效的幸福来源\u003c/h2\u003e\n\u003ch3 id=\"41-更好的想要part-1\"\u003e4.1 更好的“想要”（Part 1）\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e优势运用\u003c/strong\u003e：识别并在工作中高频使用个人优势，提升满足与“天职感”。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e心流（Flow）\u003c/strong\u003e：挑战×能力匹配，带来深度专注与高质量体验。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e成长型思维\u003c/strong\u003e：相信能力可发展，更能从挫折中学习与精进。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"42-更好的想要part-2--3\"\u003e4.2 更好的“想要”（Part 2 \u0026amp; 3）\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e善意与给予\u003c/strong\u003e：随机善举、为他人花钱、助人使人更幸福（跨文化成立）。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e社会连接\u003c/strong\u003e：重视亲密与日常社交；与陌生人开启对话、共享体验。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e时间富足\u003c/strong\u003e：优先时间而非金钱；思考“我如何用时间与人相处？”。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e冥想与正念\u003c/strong\u003e：降低走神、提升幸福、工作记忆与社会连结感。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e健康习惯\u003c/strong\u003e：规律运动与高质量睡眠，稳定情绪与认知表现。\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"5-把策略落地从知道到做到\"\u003e5. 把策略落地：从“知道”到“做到”\u003c/h2\u003e\n\u003ch3 id=\"51-情境支持让好行为更顺手\"\u003e5.1 情境支持（让好行为“更顺手”）\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e把诱因放远、把好选择放近：远离随手零食，台面摆水果；为运动与阅读预先布置环境。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"52-目标设定从愿望到执行\"\u003e5.2 目标设定（从愿望到执行）\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e具体目标\u003c/strong\u003e：定义清晰的量化标准与截止时间。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e实施意图（If–Then）\u003c/strong\u003e：为关键情境写下触发语句（例：“如果吃完午饭，就散步10分钟”）。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eWOOP 技术\u003c/strong\u003e：愿望（Wish）→成果（Outcome）→障碍（Obstacle）→计划（Plan）。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"53-速查清单一周可上手\"\u003e5.3 速查清单（一周可上手）\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e每周\u003cstrong\u003e一次新方式\u003c/strong\u003e运用你的\u003cstrong\u003e前五优势\u003c/strong\u003e；在岗尽量覆盖≥4个优势。\u003c/li\u003e\n\u003cli\u003e把\u003cstrong\u003e钱\u003c/strong\u003e优先用在\u003cstrong\u003e体验/他人\u003c/strong\u003e上；为娱乐安排\u003cstrong\u003e小而频繁\u003c/strong\u003e的享受并\u003cstrong\u003e刻意中断\u003c/strong\u003e。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e每日感恩 3 件事\u003c/strong\u003e＋\u003cstrong\u003e每周一封感谢讯息\u003c/strong\u003e。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e正念/慈心冥想\u003c/strong\u003e10–15 分钟，配合\u003cstrong\u003e每周≥3次运动\u003c/strong\u003e与\u003cstrong\u003e固定就寝/起床\u003c/strong\u003e。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e社交优先\u003c/strong\u003e：与同事/陌生人开启短聊，把体验与人分享。\u003c/li\u003e\n\u003cli\u003e为关键习惯写 3 条 \u003cstrong\u003eIf–Then\u003c/strong\u003e，并用 \u003cstrong\u003eWOOP\u003c/strong\u003e 复盘障碍与应对。\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"6-主要参考\"\u003e6. 主要参考\u003c/h2\u003e\n\u003ch3 id=\"61-认知与预测偏误\"\u003e6.1 认知与预测偏误\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eSantos \u0026amp; Gendler (2014). Knowing is half the battle? Edge.\u003c/li\u003e\n\u003cli\u003eGilbert \u0026amp; Wilson (2000). Miswanting: Some problems in the forecasting of future affective states.\u003c/li\u003e\n\u003cli\u003eLevine et al. (2012). Accuracy and artifact: Reexamining the intensity bias in affective forecasting.\u003c/li\u003e\n\u003cli\u003eDunn et al. (2002). Location, location, location.\u003c/li\u003e\n\u003cli\u003eAyton et al. (2007). Affective forecasting: Why can\u0026rsquo;t people predict their emotions?\u003c/li\u003e\n\u003cli\u003eGilbert et al. (1998). Immune neglect…\u003c/li\u003e\n\u003cli\u003eGilbert (2007). \u003cem\u003eStumbling on Happiness\u003c/em\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"62-金钱与价值观\"\u003e6.2 金钱与价值观\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eEagan et al. (2015). \u003cem\u003eThe American Freshman Survey\u003c/em\u003e.\u003c/li\u003e\n\u003cli\u003eLinkedIn Survey (2014). What recent grads care the most about.\u003c/li\u003e\n\u003cli\u003eDiener \u0026amp; Oishi (2000). Money and happiness…\u003c/li\u003e\n\u003cli\u003eMyers (2000). \u003cem\u003eThe American Paradox\u003c/em\u003e.\u003c/li\u003e\n\u003cli\u003eLyubomirsky (2007). \u003cem\u003eThe How of Happiness\u003c/em\u003e.\u003c/li\u003e\n\u003cli\u003eKahneman \u0026amp; Deaton (2010). High income improves evaluation of life…\u003c/li\u003e\n\u003cli\u003eNew York Times. Economic diversity and student outcomes at Yale University.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"63-参照点与社会比较\"\u003e6.3 参照点与社会比较\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eMedvec et al. (1995). Olympic medalists \u0026amp; counterfactuals.\u003c/li\u003e\n\u003cli\u003evan Praag \u0026amp; Frijters (1999). Leyden approach.\u003c/li\u003e\n\u003cli\u003eClark \u0026amp; Oswald (1996). Satisfaction and comparison income.\u003c/li\u003e\n\u003cli\u003eSolnick \u0026amp; Hemenway (1997). Positional concerns.\u003c/li\u003e\n\u003cli\u003eClark (2003). Unemployment as a social norm.\u003c/li\u003e\n\u003cli\u003eO’Guinn \u0026amp; Shrum (1997). Television \u0026amp; consumer reality.\u003c/li\u003e\n\u003cli\u003eSchor (1999). \u003cem\u003eThe Overspent American\u003c/em\u003e.\u003c/li\u003e\n\u003cli\u003eKuhn et al. (2011). Dutch Postcode Lottery.\u003c/li\u003e\n\u003cli\u003eKenrick et al. (1989; 1993). Attractiveness \u0026amp; comparison.\u003c/li\u003e\n\u003cli\u003eVogel et al. (2014). Social media \u0026amp; self-esteem.\u003c/li\u003e\n\u003cli\u003eBurleigh \u0026amp; Meegan (2013). Keeping Up with the Joneses \u0026amp; justice.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"64-适应与物质体验\"\u003e6.4 适应与物质/体验\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eBrickman et al. (1978). Lottery winners \u0026amp; accident victims.\u003c/li\u003e\n\u003cli\u003eDi Tella et al. (2010). Adaptation to income \u0026amp; status.\u003c/li\u003e\n\u003cli\u003eLucas et al. (2003). Adaptation to marriage.\u003c/li\u003e\n\u003cli\u003eBoven \u0026amp; Gilovich (2003). To do or to have?\u003c/li\u003e\n\u003cli\u003eKumar et al. (2014). Anticipatory consumption of experiential purchases.\u003c/li\u003e\n\u003cli\u003ePchelin \u0026amp; Howell (2014). Hidden cost of value-seeking.\u003c/li\u003e\n\u003cli\u003eHowell \u0026amp; Hill (2009). Mediators of experiential purchases.\u003c/li\u003e\n\u003cli\u003eNelson \u0026amp; Meyvis (2008). Interrupted consumption.\u003c/li\u003e\n\u003cli\u003eNelson et al. (2009). Commercial interruptions \u0026amp; TV.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"65-优势心流心态与善意社交时间\"\u003e6.5 优势/心流/心态与善意社交时间\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eSeligman (2004); Seligman et al. (2005). Signature strengths \u0026amp; interventions.\u003c/li\u003e\n\u003cli\u003eLavy \u0026amp; Littman-Ovadia (2017); Harzer \u0026amp; Ruch (2012). Strengths at work.\u003c/li\u003e\n\u003cli\u003eCsikszentmihalyi (1992; 2008; 1999). Flow.\u003c/li\u003e\n\u003cli\u003eDeci (1971); Dweck (2007); Grant \u0026amp; Dweck (2003); Blackwell et al. (2007); Mangels et al. (2006). Growth mindset。\u003c/li\u003e\n\u003cli\u003eOtake et al. (2006); Lyubomirsky (2005); Dunn (2014); Dunn et al. (2008); Aknin et al. (2013). Kindness \u0026amp; prosocial spending.\u003c/li\u003e\n\u003cli\u003eMyers (2000); Diener \u0026amp; Seligman (2002); Epley (2014); Epley \u0026amp; Schroeder (2014); Boothby et al. (2014). Social connection.\u003c/li\u003e\n\u003cli\u003eWhillans et al. (2016); Hershfield et al. (2016); Moligner (2010). Time over money.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"66-正念健康与执行\"\u003e6.6 正念、健康与执行\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eKillingsworth \u0026amp; Gilbert (2010); Mason et al. (2007); Brewer et al. (2011); Fredrickson et al. (2008); Hölzel et al. (2011); Mrazek et al. (2013); Hutcherson et al. (2008). Mind-wandering \u0026amp; meditation.\u003c/li\u003e\n\u003cli\u003eBabyak et al. (2000); Hillman et al. (2008). Exercise \u0026amp; cognition.\u003c/li\u003e\n\u003cli\u003eDinges et al. (1997); Walker et al. (2002); Wagner et al. (2004); \u003cem\u003eHuffington Post\u003c/em\u003e（睡眠图解）. Sleep \u0026amp; performance.\u003c/li\u003e\n\u003cli\u003eWansink et al. (2006; 2016). Situation support \u0026amp; default choices.\u003c/li\u003e\n\u003cli\u003eKlein et al. (1990); Gollwitzer \u0026amp; Brandstätter (1997); Stadler \u0026amp; Oettingen (2010); Duckworth et al. (2013); Stadler et al. (2009). 目标与实施意图/WOOP。\u003c/li\u003e\n\u003c/ul\u003e","title":"耶鲁大学幸福科学课程总结"},{"content":"最近都在广泛学习一些有趣的内容，主要是通过coursera平台。在家呆了2个多月了，也不知道未来啥方向，目前也是有些迷茫的状态，还是学些东西充实下自己吧，搜寻一下感兴趣的东东。\ncoursera平台类似于国外的mooc，国内外还有好多这样的平台，如中国大学mooc、bilibili大学、网易云课等等。coursera需要付费会员才能观看课程，而且只能通过国外信用卡付款（无）。于是，我在淘宝一搜，这么多卖号，而且很便宜，86半年，立马充值了一波。\n有了平台，我立马重新在coursera里，拾起深度学习的基础知识，吴恩达的课程。之前只听过，在coursera认真地观看，还是感觉受益匪浅，毕竟有作业有互动，感觉b站还是差点味道。\n现在主要看了深度学习专项课程的前3个：\n其实就相当于复习了一下之前在李沐动手学深度学习的内容。\n然后光看深度学习也有些乏味，我在网上搜索coursera有没有其他好课程，打开了一个课程排名，类似于垃圾小网站的那种：\n然后最近在看幸福科学，才刚开始看，讲的是如何变得幸福，通过科学的方式，感觉讲的还挺好的，在实验的加持下，科学成为人们可以坚持最大的迷信，hhh，但是还是要有反驳精神，感觉很多科学实验严谨性还是有些欠缺。\n之后的日子，想了解一下金融相关的知识，挺感兴趣的。马上要开学了，5555，希望能保持学习一些课外内容的习惯。还有，运动也要保持，在家和爸妈打了一个暑假的乒乓球，每日锻炼~\n","permalink":"http://localhost:1313/posts/%E6%9C%80%E8%BF%91%E5%9C%A8%E5%81%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E4%BA%8B/","summary":"\u003cp\u003e最近都在广泛学习一些有趣的内容，主要是通过coursera平台。在家呆了2个多月了，也不知道未来啥方向，目前也是有些迷茫的状态，还是学些东西充实下自己吧，搜寻一下感兴趣的东东。\u003c/p\u003e\n\u003cp\u003ecoursera平台类似于国外的mooc，国内外还有好多这样的平台，如中国大学mooc、bilibili大学、网易云课等等。coursera需要付费会员才能观看课程，而且只能通过国外信用卡付款（无）。于是，我在淘宝一搜，这么多卖号，而且很便宜，86半年，立马充值了一波。\u003c/p\u003e\n\u003cp\u003e有了平台，我立马重新在coursera里，拾起深度学习的基础知识，吴恩达的课程。之前只听过，在coursera认真地观看，还是感觉受益匪浅，毕竟有作业有互动，感觉b站还是差点味道。\u003c/p\u003e\n\u003cp\u003e现在主要看了深度学习专项课程的前3个：\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"233\" loading=\"lazy\" src=\"/posts/%E6%9C%80%E8%BF%91%E5%9C%A8%E5%81%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E4%BA%8B/image-20250825155253827.png\"\u003e\u003c/p\u003e\n\u003cp\u003e其实就相当于复习了一下之前在李沐动手学深度学习的内容。\u003c/p\u003e\n\u003cp\u003e然后光看深度学习也有些乏味，我在网上搜索coursera有没有其他好课程，打开了一个课程排名，类似于垃圾小网站的那种：\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"2333\" loading=\"lazy\" src=\"/posts/%E6%9C%80%E8%BF%91%E5%9C%A8%E5%81%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E4%BA%8B/image-20250825155452140.png\"\u003e\u003c/p\u003e\n\u003cp\u003e然后最近在看幸福科学，才刚开始看，讲的是如何变得幸福，通过科学的方式，感觉讲的还挺好的，在实验的加持下，科学成为人们可以坚持最大的迷信，hhh，但是还是要有反驳精神，感觉很多科学实验严谨性还是有些欠缺。\u003c/p\u003e\n\u003cp\u003e之后的日子，想了解一下金融相关的知识，挺感兴趣的。马上要开学了，5555，希望能保持学习一些课外内容的习惯。还有，运动也要保持，在家和爸妈打了一个暑假的乒乓球，每日锻炼~\u003c/p\u003e","title":"最近在做的一些事"},{"content":"softmax是一个经典的多分类概率分布的公式，有n个类，softmax公式如下， $$ \\text{softmax}(z)_j = \\frac{e^{z_j}}{\\sum_{i=1}^n e^{z_i}}, \\quad j = 1, 2, \\dots, n $$ 首先，考虑一个样本每个类的预测分数做一个softmax，转换成每类预测的概率形式。\n$$ a^{[L]} = \\text{softmax}(z^{[L]}) $$$$ \\hat{y} = a^{[L]}\\quad $$然后，利用样本标签，结合极大似然估计的损失函数如下。 $$ L(\\hat{y}, y) = - \\sum_{i=1}^{n} y_i \\log(\\hat{y}_i) $$由于需要做反向传播，我们想求 $\\frac{\\partial L}{\\partial z^{[L]}}$，也就是做完softmax的前的偏导数。\n假设 $y$ 的分类为 $1$，则 $y_1 = 1$，其余 $y_j = 0\\ (j\\neq 1)$，$y=[1,0,.....,0]$ 则有， $$ L(\\hat{y}, y) = -\\log(\\hat{y}_1) $$$$ L(\\hat{y}, y) = - \\ln \\left( \\frac{e^{z_1^{[L]}}}{e^{z_1^{[L]}} + e^{z_2^{[L]}} + \\cdots + e^{z_n^{[L]}}} \\right), \\quad S = e^{z_1^{[L]}} + e^{z_2^{[L]}} + \\cdots + e^{z_n^{[L]}} $$接下来求 $Z^{[L]}$ 的偏导， $$ \\frac{\\partial L}{\\partial z^{[L]}_1} = -\\frac{S}{e^{z^{[L]}_1}} \\cdot \\frac{e^{z^{[L]}_1} \\cdot S - \\big(e^{z^{[L]}_1}\\big)^2}{S^2} = \\frac{e^{z^{[L]}_1}}{S} - 1 $$$$ \\frac{\\partial L}{\\partial z^{[L]}_j} = - \\frac{S}{e^{z^{[L]}_1}} \\cdot \\frac{-e^{z^{[L]}_1} \\cdot e^{z^{[L]}_j}}{S^2} = \\frac{e^{z^{[L]}_j}}{S}, \\quad j \\neq 1 $$因为， $$ a_j^{[L]} = \\frac{e^{z_j^{[L]}}}{S}, $$ 所以， $$ \\frac{\\partial L}{\\partial z^{[L]}_1} = a_1^{[L]} - 1 $$$$ \\frac{\\partial L}{\\partial z^{[L]}_j} = a_j^{[L]}, \\quad (j \\neq 1) $$由于不同分类标签的对称性，从而得到最终化简结果， $$ \\frac{\\partial L}{\\partial z^{[L]}} = \\hat{y} - y $$ 对于多样本，每个样本间独立，则有， $$ \\frac{\\partial L}{\\partial Z^{[L]}} = \\hat{Y} - Y $$","permalink":"http://localhost:1313/posts/softmax%E7%9A%84%E5%AF%BC%E6%95%B0%E6%8E%A8%E5%AF%BC/","summary":"\u003cp\u003esoftmax是一个经典的多分类概率分布的公式，有n个类，softmax公式如下，\n\u003c/p\u003e\n$$\n\\text{softmax}(z)_j = \\frac{e^{z_j}}{\\sum_{i=1}^n  e^{z_i}}, \\quad j = 1, 2, \\dots, n\n$$\u003cp\u003e\n首先，考虑一个样本每个类的预测分数做一个softmax，转换成每类预测的概率形式。\u003c/p\u003e\n$$\na^{[L]} = \\text{softmax}(z^{[L]})\n$$$$\n\\hat{y} = a^{[L]}\\quad\n$$\u003cp\u003e然后，利用样本标签，结合极大似然估计的损失函数如下。\n\u003c/p\u003e\n$$\nL(\\hat{y}, y) = - \\sum_{i=1}^{n} y_i \\log(\\hat{y}_i)\n$$\u003cp\u003e由于需要做反向传播，我们想求 $\\frac{\\partial L}{\\partial z^{[L]}}$，也就是做完softmax的前的偏导数。\u003c/p\u003e\n\u003cp\u003e假设 $y$ 的分类为 $1$，则 $y_1 = 1$，其余 $y_j = 0\\ (j\\neq 1)$，$y=[1,0,.....,0]$\n则有，\n\u003c/p\u003e\n$$\nL(\\hat{y}, y) = -\\log(\\hat{y}_1)\n$$$$\nL(\\hat{y}, y) = - \\ln \\left( \\frac{e^{z_1^{[L]}}}{e^{z_1^{[L]}} + e^{z_2^{[L]}} + \\cdots + e^{z_n^{[L]}}} \\right),\n\\quad S = e^{z_1^{[L]}} + e^{z_2^{[L]}} + \\cdots + e^{z_n^{[L]}}\n$$\u003cp\u003e接下来求 $Z^{[L]}$ 的偏导，\n\u003c/p\u003e","title":"Softmax的反向传播推导"},{"content":"\n最近在重新回顾深度学习相关基础，之前大概过了一遍李沐的动手学深度学习，但很多内容还一知半解， 感觉网上课程难度曲线还是不太平滑。\n无意间看到 Coursera平台，在淘宝上花了80买了个半年号，仿佛打开新世界了，第一次看到了原来真的有课程能把深度学习的学习曲线 弄的这么平滑的，爱了，有点像算法竞赛的acwing、牛客。感觉b站确实不错，但是反馈和互动肯定远远比不上Coursera的。\n现在刚学完第一门课程，并手动设计并实现了多层卷积神经网络（只用到numpy），在这里记录一下forward/back propagation的数学知识（主要是线性代数）。\n正向传播 非常简单易懂，就是矩阵乘法。\n反向传播 引理一 搞懂这个引理反向传播就差不多弄懂了，求哪个偏导，固定某行/列值算贡献 就好求了（A固定行，B固定列），因为矩阵乘法是B的列与A的行做点积。\n以上就是神经网络里的线性代数的一些知识，其实不需要太多基础弄得矩阵乘法，和求导链式法则即可手写神经网络。\n","permalink":"http://localhost:1313/posts/%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC/","summary":"\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC/2.png\"\u003e\u003c/p\u003e\n\u003cp\u003e最近在重新回顾深度学习相关基础，之前大概过了一遍李沐的动手学深度学习，但很多内容还一知半解，\n感觉网上课程难度曲线还是不太平滑。\u003c/p\u003e\n\u003cp\u003e无意间看到 \u003ca href=\"https://www.coursera.org/\"\u003eCoursera平台\u003c/a\u003e，在淘宝上花了80买了个半年号，仿佛打开新世界了，第一次看到了原来真的有课程能把深度学习的学习曲线\n弄的这么平滑的，爱了，有点像算法竞赛的acwing、牛客。感觉b站确实不错，但是反馈和互动肯定远远比不上Coursera的。\u003c/p\u003e\n\u003cp\u003e现在刚学完第一门课程，并手动设计并实现了多层卷积神经网络（只用到numpy），在这里记录一下forward/back propagation的数学知识（主要是线性代数）。\u003c/p\u003e\n\u003ch4 id=\"正向传播\"\u003e正向传播\u003c/h4\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC/%281%29.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003e非常简单易懂，就是矩阵乘法。\u003c/p\u003e\n\u003ch4 id=\"反向传播\"\u003e反向传播\u003c/h4\u003e\n\u003ch5 id=\"引理一\"\u003e引理一\u003c/h5\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC/%282%29.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC/%283%29.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003e搞懂这个引理反向传播就差不多弄懂了，求哪个偏导，固定某行/列值算贡献 就好求了（A固定行，B固定列），因为矩阵乘法是B的列与A的行做点积。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC/%284%29.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003e以上就是神经网络里的线性代数的一些知识，其实不需要太多基础弄得矩阵乘法，和求导链式法则即可手写神经网络。\u003c/p\u003e","title":"神经网络反向传播 数学推导"},{"content":"工具介绍 Hugo 简介：Hugo 是一个用 Go 语言编写的静态网站生成器。它以极快的生成速度著称，可以在几秒内构建上千页面。\n特点：\n不依赖数据库，所有页面都是静态文件，部署简单且性能高。 支持 Markdown 写作，适合博客和文档站点。 拥有强大的模板系统和主题生态。 跨平台运行（Windows、Linux、macOS）。 PaperMod 简介：PaperMod 是 Hugo 社区里非常流行的一个 简洁、现代的主题，灵感来自 Google Material Design。\n特点：\n设计简洁清爽，注重阅读体验。 自带夜间模式、搜索、标签分类等功能。 对 SEO 和性能友好，开箱即用。 支持高度自定义，比如文章目录、社交链接、评论系统等。 👉 总结：Hugo 是建站工具，PaperMod 是在 Hugo 上常用的主题之一。\nStep 1 按照下面视频安装hugo+papermod，搭建demo\n【雷】Hugo + Github免费搭建博客，并实现自动化部署\nStep 2 配置papermod主题，结合大语言模型，想要什么功能直接询问即可，并修改配置文件，主题大部分都是配有相关功能的。\n","permalink":"http://localhost:1313/posts/hugo+paermod%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%95%99%E7%A8%8B/","summary":"\u003ch3 id=\"工具介绍\"\u003e工具介绍\u003c/h3\u003e\n\u003ch4 id=\"hugo\"\u003eHugo\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e简介\u003c/strong\u003e：Hugo 是一个用 Go 语言编写的\u003cstrong\u003e静态网站生成器\u003c/strong\u003e。它以极快的生成速度著称，可以在几秒内构建上千页面。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e特点\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e不依赖数据库，所有页面都是静态文件，部署简单且性能高。\u003c/li\u003e\n\u003cli\u003e支持 Markdown 写作，适合博客和文档站点。\u003c/li\u003e\n\u003cli\u003e拥有强大的模板系统和主题生态。\u003c/li\u003e\n\u003cli\u003e跨平台运行（Windows、Linux、macOS）。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"papermod\"\u003ePaperMod\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e简介\u003c/strong\u003e：PaperMod 是 Hugo 社区里非常流行的一个 \u003cstrong\u003e简洁、现代的主题\u003c/strong\u003e，灵感来自 Google Material Design。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e特点\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e设计简洁清爽，注重阅读体验。\u003c/li\u003e\n\u003cli\u003e自带夜间模式、搜索、标签分类等功能。\u003c/li\u003e\n\u003cli\u003e对 SEO 和性能友好，开箱即用。\u003c/li\u003e\n\u003cli\u003e支持高度自定义，比如文章目录、社交链接、评论系统等。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e👉 总结：\u003cstrong\u003eHugo\u003c/strong\u003e 是建站工具，\u003cstrong\u003ePaperMod\u003c/strong\u003e 是在 Hugo 上常用的主题之一。\u003c/p\u003e\n\u003ch3 id=\"step-1\"\u003eStep 1\u003c/h3\u003e\n\u003cp\u003e按照下面视频安装hugo+papermod，搭建demo\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://www.bilibili.com/video/BV1bovfeaEtQ?vd_source=89574dec834a4f547f86ccea8df6514e\"\u003e【雷】Hugo + Github免费搭建博客，并实现自动化部署\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id=\"step-2\"\u003eStep 2\u003c/h3\u003e\n\u003cp\u003e配置papermod主题，结合大语言模型，想要什么功能直接询问即可，并修改配置文件，主题大部分都是配有相关功能的。\u003c/p\u003e","title":"hugo+papermod博客搭建教程"},{"content":"你好，我是 wanghai673，一名正在攻读 计算机科学与技术 的研究生（研 0），本科毕业于东华大学，目前就读于华东师范大学。\n💻 编程语言：C++、Python、Java\n🔍 研究兴趣：深度学习、大语言模型、智能体\n🏆 竞赛经历：\nICPC 亚洲区域赛 金奖（第 49 届） 蓝桥杯全国总决赛 一等奖（全国第 6 名） 百度之星全国总决赛 金奖 多次 ICPC/CCPC 银奖 上海市大学生程序设计竞赛 一等奖 我正在不断学习和提升自己，期待将所学应用于实际问题。如果有相关的 实习机会 或者 研究合作，非常欢迎联系我。\n📫 联系方式：微信、邮件\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e你好，我是 \u003cstrong\u003ewanghai673\u003c/strong\u003e，一名正在攻读 \u003cstrong\u003e计算机科学与技术\u003c/strong\u003e 的研究生（研 0），本科毕业于东华大学，目前就读于华东师范大学。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e💻 编程语言：C++、Python、Java\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e🔍 研究兴趣：深度学习、大语言模型、智能体\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e🏆 竞赛经历：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eICPC 亚洲区域赛 \u003cstrong\u003e金奖（第 49 届）\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e蓝桥杯全国总决赛 \u003cstrong\u003e一等奖（全国第 6 名）\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e百度之星全国总决赛 \u003cstrong\u003e金奖\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e多次 ICPC/CCPC \u003cstrong\u003e银奖\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e上海市大学生程序设计竞赛 \u003cstrong\u003e一等奖\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e我正在不断学习和提升自己，期待将所学应用于实际问题。如果有相关的 \u003cstrong\u003e实习机会\u003c/strong\u003e 或者 \u003cstrong\u003e研究合作\u003c/strong\u003e，非常欢迎联系我。\u003c/p\u003e\n\u003cp\u003e📫 联系方式：\u003ca href=\"wechat.jpg\"\u003e微信\u003c/a\u003e、\u003ca href=\"https://mail.qq.com/cgi-bin/qm_share?t=qm_mailme\u0026amp;email=1154103986@qq.com\"\u003e邮件\u003c/a\u003e\u003c/p\u003e","title":"关于"},{"content":"EduAgent: Generative Student Agents in Learning 总结\n本文是针对线上教育领域的学生模仿相关的研究，之前的模型多利用庞大的数据对学生学习行为进行预测，随着LLM的问世，LLM提供的前置知识能很好的针对不同场景不同内容线上教育的学生行为预测。\n学生行为预测受到多方面的影响，如性格、学生储备知识等，本文提供了一个数据集（350个sample），针对一段5分钟的幻灯片讲解，提供学生个人信息和每个小时间段的学生注意窗口、行为、认知状态信息等。\n作者结合LLM强大的推理功能，让LLM自主推理出不同信息间的关联，从而实现学生行为的预测和模仿，但这篇论文的实验没咋看懂\u0026hellip;\nLLM-mediated domain-specific voice agents: the case of TextileBot 总结\n粗粒度地看了下\u0026hellip;\n只看了摘要和引言和结论，讲的是如何原型化地设计一个垂直领域的对话agent，包含prompt模板，随后作者自己设计了一个宣传服装环保领域的一个agent（在购物的时候跟顾客交流的），并做了用户实验。\nWhy language models hallucinate 总结\nWhy language models hallucinate | OpenAI\nOpenAI 9月5号刚发布的文章，主要讲述了为什么大语言模型会产生幻觉。\n作者描述，LLM（大语言模型）之所以产生幻觉，是因为现在对模型后训练的奖励函数，往往将答错一道题和拒答一道题（承认不知道）的惩罚都是一致的，导致LLM更倾向于去猜题，这样还有概率猜对。\n那有人就会说了，让答错的惩罚提升一些不就行了。确实可以，但是作者回应到现如今大多数的benchmark，只有对/错两个选项，并没有考虑到幻觉的因素，从而导致大家更宁愿LLM猜题，增加一些benchmark的准确率，而不是拒答（大幅度降低幻觉，但准确率会略微降低）。\n作者呼吁所有benchmark的制作者们，将幻觉这个评价指标加入到benchmark的评测之中，从而抑制LLM的胡言乱语。但现在的benchmark对幻觉的评判往往是特定的一类，大多数benmark没有考虑幻觉因素。\n上面都是通过后训练降低LLM幻觉的途径，那能不能在预训练的时候降低大语言模型的幻觉呢？作者回答，现在的数据都是无监督的，导致LLM并没有办法对每段数据的真实性做判断，更好的办法还是在后训练的时候减少大模型的幻觉。\n下面文字是原文的提出的LLM幻觉的一些误解与澄清：\n我们希望论文中的统计视角能够澄清幻觉（hallucinations）的本质，并纠正一些常见的误解：\n主张： 通过提高准确率可以消除幻觉，因为一个 100% 准确的模型永远不会产生幻觉。\n发现： 准确率永远无法达到 100%，因为无论模型规模、检索能力和推理能力如何，一些现实世界中的问题本质上是无法回答的。\n主张： 幻觉是不可避免的。\n发现： 不是的，因为语言模型在不确定时可以选择不作答。\n主张： 避免幻觉需要一种只能通过更大模型才能实现的智能水平。\n发现： 小模型有时更容易知道自己的局限。例如，当被问到毛利语问题时，一个完全不懂毛利语的小模型可以直接说“我不知道”；而一个懂一些毛利语的模型则需要判断自己的置信度。正如论文中所讨论的，“校准”所需的计算量远小于“准确”。\n主张： 幻觉是现代语言模型中的某种神秘故障。\n发现： 我们理解幻觉产生并在评估中被奖励的统计机制。\n主张： 衡量幻觉，只需要一个好的幻觉评测。\n发现： 已经有幻觉评测被发表。然而，一个好的幻觉评测在数百个传统的基于准确率的评测面前几乎无效，因为后者会惩罚谦逊、奖励猜测。因此，所有主要的评测指标都需要重新设计，以奖励表达不确定性的能力。\n","permalink":"http://localhost:1313/posts/9.6_%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/","summary":"\u003ch3 id=\"eduagent-generative-student-agents-in-learning\"\u003eEduAgent: Generative Student Agents in Learning\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e总结\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e本文是针对线上教育领域的学生模仿相关的研究，之前的模型多利用庞大的数据对学生学习行为进行预测，随着LLM的问世，LLM提供的前置知识能很好的针对不同场景不同内容线上教育的学生行为预测。\u003c/p\u003e\n\u003cp\u003e学生行为预测受到多方面的影响，如性格、学生储备知识等，本文提供了一个数据集（350个sample），针对一段5分钟的幻灯片讲解，提供学生个人信息和每个小时间段的学生注意窗口、行为、认知状态信息等。\u003c/p\u003e\n\u003cp\u003e作者结合LLM强大的推理功能，让LLM自主推理出不同信息间的关联，从而实现学生行为的预测和模仿，但这篇论文的实验没咋看懂\u0026hellip;\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"llm-mediated-domain-specific-voice-agents-the-case-of-textilebot\"\u003eLLM-mediated domain-specific voice agents: the case of TextileBot\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e总结\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e粗粒度地看了下\u0026hellip;\u003c/p\u003e\n\u003cp\u003e只看了摘要和引言和结论，讲的是如何原型化地设计一个垂直领域的对话agent，包含prompt模板，随后作者自己设计了一个宣传服装环保领域的一个agent（在购物的时候跟顾客交流的），并做了用户实验。\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"why-language-models-hallucinate\"\u003eWhy language models hallucinate\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e总结\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://openai.com/index/why-language-models-hallucinate/\"\u003eWhy language models hallucinate | OpenAI\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eOpenAI 9月5号刚发布的文章，主要讲述了为什么大语言模型会产生幻觉。\u003c/p\u003e\n\u003cp\u003e作者描述，LLM（大语言模型）之所以产生幻觉，是因为现在对模型后训练的奖励函数，往往将答错一道题和拒答一道题（承认不知道）的惩罚都是一致的，导致LLM更倾向于去猜题，这样还有概率猜对。\u003c/p\u003e\n\u003cp\u003e那有人就会说了，让答错的惩罚提升一些不就行了。确实可以，但是作者回应到现如今大多数的benchmark，只有对/错两个选项，并没有考虑到幻觉的因素，从而导致大家更宁愿LLM猜题，增加一些benchmark的准确率，而不是拒答（大幅度降低幻觉，但准确率会略微降低）。\u003c/p\u003e\n\u003cp\u003e作者呼吁所有benchmark的制作者们，将幻觉这个评价指标加入到benchmark的评测之中，从而抑制LLM的胡言乱语。但现在的benchmark对幻觉的评判往往是特定的一类，大多数benmark没有考虑幻觉因素。\u003c/p\u003e\n\u003cp\u003e上面都是通过后训练降低LLM幻觉的途径，那能不能在预训练的时候降低大语言模型的幻觉呢？作者回答，现在的数据都是无监督的，导致LLM并没有办法对每段数据的真实性做判断，更好的办法还是在后训练的时候减少大模型的幻觉。\u003c/p\u003e\n\u003cp\u003e下面文字是原文的提出的LLM幻觉的一些误解与澄清：\u003c/p\u003e\n\u003cp\u003e我们希望论文中的统计视角能够澄清幻觉（hallucinations）的本质，并纠正一些常见的误解：\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e主张：\u003c/strong\u003e 通过提高准确率可以消除幻觉，因为一个 100% 准确的模型永远不会产生幻觉。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e发现：\u003c/strong\u003e 准确率永远无法达到 100%，因为无论模型规模、检索能力和推理能力如何，一些现实世界中的问题本质上是无法回答的。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e主张：\u003c/strong\u003e 幻觉是不可避免的。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e发现：\u003c/strong\u003e 不是的，因为语言模型在不确定时可以选择不作答。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e主张：\u003c/strong\u003e 避免幻觉需要一种只能通过更大模型才能实现的智能水平。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e发现：\u003c/strong\u003e 小模型有时更容易知道自己的局限。例如，当被问到毛利语问题时，一个完全不懂毛利语的小模型可以直接说“我不知道”；而一个懂一些毛利语的模型则需要判断自己的置信度。正如论文中所讨论的，“校准”所需的计算量远小于“准确”。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e主张：\u003c/strong\u003e 幻觉是现代语言模型中的某种神秘故障。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e发现：\u003c/strong\u003e 我们理解幻觉产生并在评估中被奖励的统计机制。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e主张：\u003c/strong\u003e 衡量幻觉，只需要一个好的幻觉评测。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e发现：\u003c/strong\u003e 已经有幻觉评测被发表。然而，一个好的幻觉评测在数百个传统的基于准确率的评测面前几乎无效，因为后者会惩罚谦逊、奖励猜测。因此，所有主要的评测指标都需要重新设计，以奖励表达不确定性的能力。\u003c/p\u003e","title":"9.6 论文阅读"},{"content":"LLM Agents for Education: Advances and Applications 总结\n这是一篇综述论文，讲述了现在LLM agents在领域的各种运用。作者将教育agent分为 教学agent 和 垂直领域agent。\n教学agent又分为面向学生和面向教师的，垂直领域的分为很多不同学科类的agent，不同学科agent也有不同的功能的agent，整体分类思维导图见下图。\n然后作者讲述了，现有教育agent所面临的困难，如道德、偏见方面的，也有幻觉、可靠性方面的。现有的agent大多数不具备结构化的形式（更多是对话类型），无法直接在现实教育场景中插入。\n最后整理介绍了现有测评教育agent各种benchmark，以供后来研究者使用。\nMATHAGENT: Leveraging a Mixture-of-Math-Agent Framework for Real-World Multimodal Mathematical Error Detection 背景\n大语言模型在数学问题求解中已经非常厉害了，但是在数学错误发现上还很少涉足。传统的数学老师批改，耗时耗力，并且不具备可扩展性，如无法为学生指明学生具体错误（人工成本高），多模态大模型可以识别图片，并且为学生提供错误位置和错误分类，但是MLLM还在存在较多错误，对于有细微错误的地方无法很好识别。并且现在研究多聚焦纯文本数学题改错，对于带有图片信息的不能很好应对。\n方法\n数据集合为下图，有文本问题描述，图片类信息，正确答案，学生的不正确答案，解题步骤。 任务分为 1：找到第一个错误步骤，2：错误分类，指标都是准确率。\n作者引入了个多智能体框架，分为三个部分，流程如下图。\n文本-图像一致性检测：判断图片和文字是否高度一致，避免使用图片识别功能，从而增强题目解读能力 公式-表格识别：用专门model将各种公式、表格等识别为文本形式 融合找错：将文本和转文本的图片信息融合为一个完整题目，并且让LLM完成上面具体两个任务 实验结果\n将该方法运用到多个多模态大模型，大部分都能提升准确率，但相较于人工还有很大的差距。 论文写的浅显易懂，结构也很清晰，可惜本论文并未公布数据集。。。\n","permalink":"http://localhost:1313/posts/9%E6%9C%885%E6%97%A5%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/","summary":"\u003ch3 id=\"llm-agents-for-education-advances-and-applications\"\u003eLLM Agents for Education: Advances and Applications\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e总结\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e这是一篇综述论文，讲述了现在LLM agents在领域的各种运用。作者将教育agent分为 教学agent 和 垂直领域agent。\u003c/p\u003e\n\u003cp\u003e教学agent又分为面向学生和面向教师的，垂直领域的分为很多不同学科类的agent，不同学科agent也有不同的功能的agent，整体分类思维导图见下图。\u003c/p\u003e\n\u003cp\u003e然后作者讲述了，现有教育agent所面临的困难，如道德、偏见方面的，也有幻觉、可靠性方面的。现有的agent大多数不具备结构化的形式（更多是对话类型），无法直接在现实教育场景中插入。\u003c/p\u003e\n\u003cp\u003e最后整理介绍了现有测评教育agent各种benchmark，以供后来研究者使用。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250905134524279\" loading=\"lazy\" src=\"/posts/9%E6%9C%885%E6%97%A5%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/image-20250905134524279.png\"\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"mathagent-leveraging-a-mixture-of-math-agent-framework-for-real-world-multimodal-mathematical-error-detection\"\u003eMATHAGENT: Leveraging a Mixture-of-Math-Agent Framework for Real-World Multimodal Mathematical Error Detection\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e背景\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e大语言模型在数学问题求解中已经非常厉害了，但是在数学错误发现上还很少涉足。传统的数学老师批改，耗时耗力，并且不具备可扩展性，如无法为学生指明学生具体错误（人工成本高），多模态大模型可以识别图片，并且为学生提供错误位置和错误分类，但是MLLM还在存在较多错误，对于有细微错误的地方无法很好识别。并且现在研究多聚焦纯文本数学题改错，对于带有图片信息的不能很好应对。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e方法\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e数据集合为下图，有文本问题描述，图片类信息，正确答案，学生的不正确答案，解题步骤。\n任务分为  1：找到第一个错误步骤，2：错误分类，指标都是准确率。\u003c/p\u003e\n\u003cimg src=\"image-20250905153558820.png\" alt=\"image-20250905153558820\" style=\"zoom:67%;\" /\u003e\n\u003cp\u003e作者引入了个多智能体框架，分为三个部分，流程如下图。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e文本-图像一致性检测：判断图片和文字是否高度一致，避免使用图片识别功能，从而增强题目解读能力\u003c/li\u003e\n\u003cli\u003e公式-表格识别：用专门model将各种公式、表格等识别为文本形式\u003c/li\u003e\n\u003cli\u003e融合找错：将文本和转文本的图片信息融合为一个完整题目，并且让LLM完成上面具体两个任务\u003cimg src=\"image-20250905153953903.png\" alt=\"image-20250905153953903\" style=\"zoom:67%;\" /\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e实验结果\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e将该方法运用到多个多模态大模型，大部分都能提升准确率，但相较于人工还有很大的差距。\n\u003cimg alt=\"image-20250905154103167\" loading=\"lazy\" src=\"/posts/9%E6%9C%885%E6%97%A5%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/image-20250905154103167.png\"\u003e\u003c/p\u003e\n\u003cp\u003e论文写的浅显易懂，结构也很清晰，可惜本论文并未公布数据集。。。\u003c/p\u003e","title":"9.5 论文阅读"},{"content":"最近闲着无聊随便做了一个windows的语音唤醒助手，主要是闲平常要出门，或者不方便的时候（比如运动、躺床上的时候），可以叫一声电脑就做我想让他做的内容（可以连接LLM/GUI agent/MCP等等）。\n再加上现在GUIAgent发展的很快，网上还没有语音唤醒形式的链接，也就自己搭了一个出来。\n下面是这个项目的readme。\nWinAssistant – Windows 本地语音唤醒与自动化执行 一个在 Windows 上运行的本地语音助手：\n说出唤醒词 → 识别你的语音 → 自动执行自定义动作（脚本、GUI Agent、MCP 等）。 全离线（唤醒+识别均可离线），即插即用，优先使用耳机麦克风。 演示视频 https://github.com/user-attachments/assets/a48b8e94-8b95-46eb-9aa5-a4085c2341c4\n✨ 核心特性 多唤醒词可选 / 可自定义 内置多种常见唤醒词，也可替换为你训练的 .ppn 文件。\n本地唤醒：Picovoice Porcupine 轻量、低延迟、可靠，离线运行。\n语音识别：fast-whisper 内置去噪、VAD 端点检测，自动判断“用户是否说完”，可按需调节模型大小（速度/准确度权衡）。\n自动音频设备选择 自动选择可用的输入/输出设备，优先耳机。\n可插拔“处理态” 识别到文本后进入你的“处理态”（可自定义），例如：\n调用 MCP / 工具调用 触发 GUI Agent 执行脚本、打开应用、查询信息等 🧠 工作流 / 状态机 stateDiagram-v2 [*] --\u0026gt; 空闲态 空闲态 --\u0026gt; 唤醒态: 语音唤醒 唤醒态 --\u0026gt; 处理态: 用户语音结束 处理态 --\u0026gt; 空闲态 唤醒态 --\u0026gt; 空闲态: 用户长时间无应答 空闲态 --\u0026gt; 空闲态: （持续监听） 说明：唤醒后进入实时听写；若检测到长时间静音则回退到空闲态。\n📦 目录结构 WINASSISTANT/ ├─ model/ │ ├─ 小智.ppn # 自定义/内置唤醒词（Porcupine） │ └─ porcupine_params_zh.pv # 中文参数 ├─ music/ # 系统提示音 │ ├─ ok.wav │ ├─ sorry.wav │ └─ zai.wav ├─ utils/ │ ├─ player.py # 播放器：播放提示音/反馈 │ ├─ reader.py # 识别器：fast-whisper + VAD │ ├─ rouser.py # 唤醒：Porcupine 推理 │ └─ UIoperator.py # 处理态模板（可自定义） ├─ .env # 环境变量（见下） ├─ main.py # 入口：python main.py └─ requirements.txt # 依赖 🚀 快速开始 1) 环境准备 Windows 10/11 Python 3.9+（建议 64-bit） 麦克风 \u0026amp; 扬声器/耳机 git clone https://github.com/wanghai673/WinAssistant cd WINASSISTANT # 建议：创建虚拟环境 python -m venv .venv .\\.venv\\Scripts\\activate pip install -r requirements.txt 2) 申请 Picovoice Access Key 前往 https://picovoice.ai/ 免费获取 ACCESS_KEY。\n3) 配置 .env 在项目根目录创建或修改 .env：\nACCESS_KEY=你的AccessKey # 唤醒词（可选：小智, hey google, grasshopper, computer, americano, # bumblebee, hey barista, ok google, pico clock, porcupine, # picovoice, jarvis, terminator, grapefruit, blueberry, alexa, hey siri） ROUSE_WORD=小智 想用自定义唤醒词？把训练好的 .ppn 文件放到 model/ 并在代码/ENV 中指向它即可。\n4) 运行 python main.py 说出唤醒词（默认 “小智”）→ 说出命令 → 听到提示音并执行。\n🧩 自定义“处理态” 识别结果会进入你的“处理态”模块（示例：utils/UIoperator.py）。 你可以在这里：\n串接 MCP 工具调用 通过 GUI Agent 操作桌面 执行脚本 / 打开应用 / 系统自动化 回放 music/ok.wav / sorry.wav 作为反馈 建议将业务逻辑与语音管线解耦：保留 player / reader / rouser 作为通用能力层，处理态专注于“要做什么”。\n⚙️ 常用调优点 VAD/静音阈值：在 reader.py 中调整 MAX_SILENCE_SECS 等参数，影响“说完就停”的敏感度。 模型大小：根据机器性能切换 fast-whisper 模型（小模型更快，大模型更准）。 提示音屏蔽：通过 realtime_zh(..., beep_guard=0.5) 吞掉前 0.5s 系统“滴”声，避免影响识别。 音频设备：默认自动选择，优先耳机；如需固定设备，可在 player/reader 中指定设备索引。 🔐 隐私与本地化 唤醒与识别均可离线完成；音频不会上传到云端。 仅在你显式配置联网服务时才会产生外部调用。 🧪 简单示例（伪代码） # 极简示例：监听唤醒 → 识别 from utils.player import Player from utils.reader import Reader from utils.rouser import Rouser from pvrecorder import PvRecorder from dotenv import load_dotenv import os load_dotenv() ACCESS_KEY = os.getenv(\u0026#34;ACCESS_KEY\u0026#34;) ROUSE_WORD = os.getenv(\u0026#34;ROUSE_WORD\u0026#34;, \u0026#34;小智\u0026#34;) DEVICE_INDEX = -1 # 使用系统默认输入设备 rouser = Rouser(access_key=ACCESS_KEY, device_index=DEVICE_INDEX, keyword=ROUSE_WORD) player = Player() reader = Reader(device_index=DEVICE_INDEX) recorder = PvRecorder(device_index=DEVICE_INDEX, frame_length=rouser.porcupine.frame_length) recorder.start() print(f\u0026#34;正在监听唤醒词：『{ROUSE_WORD}』 (Ctrl+C 退出)\u0026#34;) while True: pcm = recorder.read() if rouser.process(pcm) \u0026gt;= 0: # 检测到唤醒 player.play_voice(block=True) # 提示音 text = reader.realtime_zh(rec_shared=recorder, beep_guard=0.0) if text: print(\u0026#34;识别文本：\u0026#34;, text) player.play_voice(block=True, type=\u0026#34;ok\u0026#34;) # 在这里根据 text 执行动作... else: player.play_voice(block=True, type=\u0026#34;sorry\u0026#34;) 🧯 故障排查 没有反应 / 设备占用：检查是否有其他应用占用麦克风；尝试在系统声音设置中启用设备。 识别慢：试用更小的 fast-whisper 模型或关闭其他高占用程序。 唤醒不灵敏：更换更清晰的唤醒词模型 .ppn，或在安静环境下测试。 提示音被识别进去：增大 beep_guard（如 0.7）。 🙌 致谢 Picovoice Porcupine（本地唤醒） fast-whisper（快速 ASR） ","permalink":"http://localhost:1313/posts/windows%E8%AF%AD%E9%9F%B3%E5%94%A4%E9%86%92%E5%8A%A9%E6%89%8B/","summary":"\u003cp\u003e最近闲着无聊随便做了一个\u003ca href=\"https://github.com/wanghai673/WinAssistant/\"\u003ewindows的语音唤醒助手\u003c/a\u003e，主要是闲平常要出门，或者不方便的时候（比如运动、躺床上的时候），可以叫一声电脑就做我想让他做的内容（可以连接LLM/GUI agent/MCP等等）。\u003c/p\u003e\n\u003cp\u003e再加上现在GUIAgent发展的很快，网上还没有语音唤醒形式的链接，也就自己搭了一个出来。\u003c/p\u003e\n\u003cp\u003e下面是这个项目的readme。\u003c/p\u003e\n\u003ch1 id=\"winassistant--windows-本地语音唤醒与自动化执行\"\u003eWinAssistant – Windows 本地语音唤醒与自动化执行\u003c/h1\u003e\n\u003cp\u003e一个在 \u003cstrong\u003eWindows\u003c/strong\u003e 上运行的本地语音助手：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e说出唤醒词 → 识别你的语音 → 自动执行自定义动作（脚本、GUI Agent、MCP 等）。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e全离线\u003c/strong\u003e（唤醒+识别均可离线），即插即用，优先使用耳机麦克风。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"演示视频\"\u003e演示视频\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/user-attachments/assets/a48b8e94-8b95-46eb-9aa5-a4085c2341c4\"\u003ehttps://github.com/user-attachments/assets/a48b8e94-8b95-46eb-9aa5-a4085c2341c4\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"-核心特性\"\u003e✨ 核心特性\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e多唤醒词可选 / 可自定义\u003c/strong\u003e\n内置多种常见唤醒词，也可替换为你训练的 \u003ccode\u003e.ppn\u003c/code\u003e 文件。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e本地唤醒：Picovoice Porcupine\u003c/strong\u003e\n轻量、低延迟、可靠，离线运行。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e语音识别：fast-whisper\u003c/strong\u003e\n内置\u003cstrong\u003e去噪\u003c/strong\u003e、\u003cstrong\u003eVAD 端点检测\u003c/strong\u003e，自动判断“用户是否说完”，可按需调节模型大小（速度/准确度权衡）。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e自动音频设备选择\u003c/strong\u003e\n自动选择可用的输入/输出设备，\u003cstrong\u003e优先耳机\u003c/strong\u003e。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e可插拔“处理态”\u003c/strong\u003e\n识别到文本后进入你的“处理态”（可自定义），例如：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e调用 MCP / 工具调用\u003c/li\u003e\n\u003cli\u003e触发 GUI Agent\u003c/li\u003e\n\u003cli\u003e执行脚本、打开应用、查询信息等\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"-工作流--状态机\"\u003e🧠 工作流 / 状态机\u003c/h2\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode class=\"language-mermaid\" data-lang=\"mermaid\"\u003estateDiagram-v2\n    [*] --\u0026gt; 空闲态\n    空闲态 --\u0026gt; 唤醒态: 语音唤醒\n    唤醒态 --\u0026gt; 处理态: 用户语音结束\n    处理态 --\u0026gt; 空闲态\n    唤醒态 --\u0026gt; 空闲态: 用户长时间无应答\n    空闲态 --\u0026gt; 空闲态: （持续监听）\n\u003c/code\u003e\u003c/pre\u003e\u003cblockquote\u003e\n\u003cp\u003e说明：唤醒后进入实时听写；若检测到\u003cstrong\u003e长时间静音\u003c/strong\u003e则回退到空闲态。\u003c/p\u003e","title":"Windows语音唤醒助手"},{"content":"之前看过很多成功学/心理学众所周知的道理，但是都是空头说话，没有任何数据证明，但这门课，能通过实验的方式展示结果，看到了让我更加信服（科学是最大的迷信hhh）。\n课程纠正了我非常多的偏见，让我对自己有了更清晰的认识，强烈推荐给大家！\n下面是The Science of Well-Being | Coursera的LLM的总结。\n1. 幸福的常见误解 1.1 “知道就够了”（G.I. Joe 谬误） 仅“知道道理”并不会自动改变行为；需要情境与练习把“知道”变“做到”。 1.2 找工作与被拒 被拒的痛苦通常没想的那样强与久，心理免疫系统会缓冲。 1.3 金钱与收入 年轻人的价值观更偏向“高收入为先”。 收入增长与主观幸福并非一一对应；整体幸福感在富足年代并未同步上扬。 超过某一阈值后，收入主要提升“生活评价”，对日常情绪的边际效用有限。 1.4 “酷东西”与物质主义 流行文化强化对豪车、名酒等的向往。 物质主义目标与更低的长期满意度相关。 1.5 真爱与婚姻 婚后幸福感常在几年内回落到基线（适应效应）。 1.6 完美身材/整形与完美成绩 减重或整形未必带来更好的长期心理健康或幸福。 人们普遍高估成绩变化带来的情绪涨落。 幸福并非被基因与环境“写死”，相当比例可由行为与思维方式塑造。 2. 我们为什么总是判断失准 2.1 误想（Miswanting） 对“未来会多喜欢/多讨厌”经常判断错误。 2.2 相对参照点 我们按比较而非绝对值评估自己：同侪收入、媒体/社交媒体的呈现、班级曲线、外貌对比等都会扭曲感受与选择。 2.3 适应力强 对“好事/坏事”都会逐渐习惯：收入提升、中彩票、婚姻等皆会回到常态。 2.4 忽视我们会适应 预测未来情绪时，容易“聚焦于单一事件”并忽略适应与其他生活面向，导致高估负面事件的持续影响。 3. 如何克服偏误（可操作策略） 3.1 重新定义“酷东西”：投资体验而非物质 把钱与精力优先投入能被分享与反复回味的体验（旅行、学习、共创）。 3.2 阻断/延缓适应 品味/回味（savoring）：刻意思考并记录正向时刻。 积极回忆 \u0026amp; 书写消化：写下负面事件并完成认知加工。 负向想象：设想“若没有这件好事会怎样”，提升珍惜度。 时间稀缺：把某些体验当作“最后一次”，增强投入。 感恩练习：数祝福、写感谢信、表达谢意。 重置参照点：有意切换比较标准，校准高/低参照引发的偏差。 打断消费：给愉悦体验加入“短暂停”，延长新鲜感。 4. 真正更有效的幸福来源 4.1 更好的“想要”（Part 1） 优势运用：识别并在工作中高频使用个人优势，提升满足与“天职感”。 心流（Flow）：挑战×能力匹配，带来深度专注与高质量体验。 成长型思维：相信能力可发展，更能从挫折中学习与精进。 4.2 更好的“想要”（Part 2 \u0026amp; 3） 善意与给予：随机善举、为他人花钱、助人使人更幸福（跨文化成立）。 社会连接：重视亲密与日常社交；与陌生人开启对话、共享体验。 时间富足：优先时间而非金钱；思考“我如何用时间与人相处？”。 冥想与正念：降低走神、提升幸福、工作记忆与社会连结感。 健康习惯：规律运动与高质量睡眠，稳定情绪与认知表现。 5. 把策略落地：从“知道”到“做到” 5.1 情境支持（让好行为“更顺手”） 把诱因放远、把好选择放近：远离随手零食，台面摆水果；为运动与阅读预先布置环境。 5.2 目标设定（从愿望到执行） 具体目标：定义清晰的量化标准与截止时间。 实施意图（If–Then）：为关键情境写下触发语句（例：“如果吃完午饭，就散步10分钟”）。 WOOP 技术：愿望（Wish）→成果（Outcome）→障碍（Obstacle）→计划（Plan）。 5.3 速查清单（一周可上手） 每周一次新方式运用你的前五优势；在岗尽量覆盖≥4个优势。 把钱优先用在体验/他人上；为娱乐安排小而频繁的享受并刻意中断。 每日感恩 3 件事＋每周一封感谢讯息。 正念/慈心冥想10–15 分钟，配合每周≥3次运动与固定就寝/起床。 社交优先：与同事/陌生人开启短聊，把体验与人分享。 为关键习惯写 3 条 If–Then，并用 WOOP 复盘障碍与应对。 6. 主要参考 6.1 认知与预测偏误 Santos \u0026amp; Gendler (2014). Knowing is half the battle? Edge. Gilbert \u0026amp; Wilson (2000). Miswanting: Some problems in the forecasting of future affective states. Levine et al. (2012). Accuracy and artifact: Reexamining the intensity bias in affective forecasting. Dunn et al. (2002). Location, location, location. Ayton et al. (2007). Affective forecasting: Why can\u0026rsquo;t people predict their emotions? Gilbert et al. (1998). Immune neglect… Gilbert (2007). Stumbling on Happiness. 6.2 金钱与价值观 Eagan et al. (2015). The American Freshman Survey. LinkedIn Survey (2014). What recent grads care the most about. Diener \u0026amp; Oishi (2000). Money and happiness… Myers (2000). The American Paradox. Lyubomirsky (2007). The How of Happiness. Kahneman \u0026amp; Deaton (2010). High income improves evaluation of life… New York Times. Economic diversity and student outcomes at Yale University. 6.3 参照点与社会比较 Medvec et al. (1995). Olympic medalists \u0026amp; counterfactuals. van Praag \u0026amp; Frijters (1999). Leyden approach. Clark \u0026amp; Oswald (1996). Satisfaction and comparison income. Solnick \u0026amp; Hemenway (1997). Positional concerns. Clark (2003). Unemployment as a social norm. O’Guinn \u0026amp; Shrum (1997). Television \u0026amp; consumer reality. Schor (1999). The Overspent American. Kuhn et al. (2011). Dutch Postcode Lottery. Kenrick et al. (1989; 1993). Attractiveness \u0026amp; comparison. Vogel et al. (2014). Social media \u0026amp; self-esteem. Burleigh \u0026amp; Meegan (2013). Keeping Up with the Joneses \u0026amp; justice. 6.4 适应与物质/体验 Brickman et al. (1978). Lottery winners \u0026amp; accident victims. Di Tella et al. (2010). Adaptation to income \u0026amp; status. Lucas et al. (2003). Adaptation to marriage. Boven \u0026amp; Gilovich (2003). To do or to have? Kumar et al. (2014). Anticipatory consumption of experiential purchases. Pchelin \u0026amp; Howell (2014). Hidden cost of value-seeking. Howell \u0026amp; Hill (2009). Mediators of experiential purchases. Nelson \u0026amp; Meyvis (2008). Interrupted consumption. Nelson et al. (2009). Commercial interruptions \u0026amp; TV. 6.5 优势/心流/心态与善意社交时间 Seligman (2004); Seligman et al. (2005). Signature strengths \u0026amp; interventions. Lavy \u0026amp; Littman-Ovadia (2017); Harzer \u0026amp; Ruch (2012). Strengths at work. Csikszentmihalyi (1992; 2008; 1999). Flow. Deci (1971); Dweck (2007); Grant \u0026amp; Dweck (2003); Blackwell et al. (2007); Mangels et al. (2006). Growth mindset。 Otake et al. (2006); Lyubomirsky (2005); Dunn (2014); Dunn et al. (2008); Aknin et al. (2013). Kindness \u0026amp; prosocial spending. Myers (2000); Diener \u0026amp; Seligman (2002); Epley (2014); Epley \u0026amp; Schroeder (2014); Boothby et al. (2014). Social connection. Whillans et al. (2016); Hershfield et al. (2016); Moligner (2010). Time over money. 6.6 正念、健康与执行 Killingsworth \u0026amp; Gilbert (2010); Mason et al. (2007); Brewer et al. (2011); Fredrickson et al. (2008); Hölzel et al. (2011); Mrazek et al. (2013); Hutcherson et al. (2008). Mind-wandering \u0026amp; meditation. Babyak et al. (2000); Hillman et al. (2008). Exercise \u0026amp; cognition. Dinges et al. (1997); Walker et al. (2002); Wagner et al. (2004); Huffington Post（睡眠图解）. Sleep \u0026amp; performance. Wansink et al. (2006; 2016). Situation support \u0026amp; default choices. Klein et al. (1990); Gollwitzer \u0026amp; Brandstätter (1997); Stadler \u0026amp; Oettingen (2010); Duckworth et al. (2013); Stadler et al. (2009). 目标与实施意图/WOOP。 ","permalink":"http://localhost:1313/posts/the_science_of_well-being_%E6%80%BB%E7%BB%93/","summary":"\u003cp\u003e之前看过很多成功学/心理学众所周知的道理，但是都是空头说话，没有任何数据证明，但这门课，能通过实验的方式展示结果，看到了让我更加信服（科学是最大的迷信hhh）。\u003c/p\u003e\n\u003cp\u003e课程纠正了我非常多的偏见，让我对自己有了更清晰的认识，强烈推荐给大家！\u003c/p\u003e\n\u003cp\u003e下面是\u003ca href=\"https://www.coursera.org/learn/the-science-of-well-being\"\u003eThe Science of Well-Being | Coursera\u003c/a\u003e的LLM的总结。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"1-幸福的常见误解\"\u003e1. 幸福的常见误解\u003c/h2\u003e\n\u003ch3 id=\"11-知道就够了gi-joe-谬误\"\u003e1.1 “知道就够了”（G.I. Joe 谬误）\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e仅“知道道理”并不会自动改变行为；需要情境与练习把“知道”变“做到”。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"12-找工作与被拒\"\u003e1.2 找工作与被拒\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e被拒的痛苦通常没想的那样强与久，心理免疫系统会缓冲。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"13-金钱与收入\"\u003e1.3 金钱与收入\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e年轻人的价值观更偏向“高收入为先”。\u003c/li\u003e\n\u003cli\u003e收入增长与主观幸福并非一一对应；整体幸福感在富足年代并未同步上扬。\u003c/li\u003e\n\u003cli\u003e超过某一阈值后，收入主要提升“生活评价”，对日常情绪的边际效用有限。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"14-酷东西与物质主义\"\u003e1.4 “酷东西”与物质主义\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e流行文化强化对豪车、名酒等的向往。\u003c/li\u003e\n\u003cli\u003e物质主义目标与更低的长期满意度相关。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"15-真爱与婚姻\"\u003e1.5 真爱与婚姻\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e婚后幸福感常在几年内回落到基线（适应效应）。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"16-完美身材整形与完美成绩\"\u003e1.6 完美身材/整形与完美成绩\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e减重或整形未必带来更好的长期心理健康或幸福。\u003c/li\u003e\n\u003cli\u003e人们普遍高估成绩变化带来的情绪涨落。\u003c/li\u003e\n\u003cli\u003e幸福并非被基因与环境“写死”，相当比例可由行为与思维方式塑造。\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"2-我们为什么总是判断失准\"\u003e2. 我们为什么总是判断失准\u003c/h2\u003e\n\u003ch3 id=\"21-误想miswanting\"\u003e2.1 误想（Miswanting）\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e对“未来会多喜欢/多讨厌”经常判断错误。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"22-相对参照点\"\u003e2.2 相对参照点\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e我们按比较而非绝对值评估自己：同侪收入、媒体/社交媒体的呈现、班级曲线、外貌对比等都会扭曲感受与选择。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"23-适应力强\"\u003e2.3 适应力强\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e对“好事/坏事”都会逐渐习惯：收入提升、中彩票、婚姻等皆会回到常态。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"24-忽视我们会适应\"\u003e2.4 忽视我们会适应\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e预测未来情绪时，容易“聚焦于单一事件”并忽略适应与其他生活面向，导致高估负面事件的持续影响。\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"3-如何克服偏误可操作策略\"\u003e3. 如何克服偏误（可操作策略）\u003c/h2\u003e\n\u003ch3 id=\"31-重新定义酷东西投资体验而非物质\"\u003e3.1 重新定义“酷东西”：投资体验而非物质\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e把钱与精力优先投入能被分享与反复回味的体验（旅行、学习、共创）。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"32-阻断延缓适应\"\u003e3.2 阻断/延缓适应\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e品味/回味（savoring）\u003c/strong\u003e：刻意思考并记录正向时刻。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e积极回忆 \u0026amp; 书写消化\u003c/strong\u003e：写下负面事件并完成认知加工。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e负向想象\u003c/strong\u003e：设想“若没有这件好事会怎样”，提升珍惜度。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e时间稀缺\u003c/strong\u003e：把某些体验当作“最后一次”，增强投入。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e感恩练习\u003c/strong\u003e：数祝福、写感谢信、表达谢意。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e重置参照点\u003c/strong\u003e：有意切换比较标准，校准高/低参照引发的偏差。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e打断消费\u003c/strong\u003e：给愉悦体验加入“短暂停”，延长新鲜感。\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"4-真正更有效的幸福来源\"\u003e4. 真正更有效的幸福来源\u003c/h2\u003e\n\u003ch3 id=\"41-更好的想要part-1\"\u003e4.1 更好的“想要”（Part 1）\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e优势运用\u003c/strong\u003e：识别并在工作中高频使用个人优势，提升满足与“天职感”。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e心流（Flow）\u003c/strong\u003e：挑战×能力匹配，带来深度专注与高质量体验。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e成长型思维\u003c/strong\u003e：相信能力可发展，更能从挫折中学习与精进。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"42-更好的想要part-2--3\"\u003e4.2 更好的“想要”（Part 2 \u0026amp; 3）\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e善意与给予\u003c/strong\u003e：随机善举、为他人花钱、助人使人更幸福（跨文化成立）。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e社会连接\u003c/strong\u003e：重视亲密与日常社交；与陌生人开启对话、共享体验。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e时间富足\u003c/strong\u003e：优先时间而非金钱；思考“我如何用时间与人相处？”。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e冥想与正念\u003c/strong\u003e：降低走神、提升幸福、工作记忆与社会连结感。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e健康习惯\u003c/strong\u003e：规律运动与高质量睡眠，稳定情绪与认知表现。\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"5-把策略落地从知道到做到\"\u003e5. 把策略落地：从“知道”到“做到”\u003c/h2\u003e\n\u003ch3 id=\"51-情境支持让好行为更顺手\"\u003e5.1 情境支持（让好行为“更顺手”）\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e把诱因放远、把好选择放近：远离随手零食，台面摆水果；为运动与阅读预先布置环境。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"52-目标设定从愿望到执行\"\u003e5.2 目标设定（从愿望到执行）\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e具体目标\u003c/strong\u003e：定义清晰的量化标准与截止时间。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e实施意图（If–Then）\u003c/strong\u003e：为关键情境写下触发语句（例：“如果吃完午饭，就散步10分钟”）。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eWOOP 技术\u003c/strong\u003e：愿望（Wish）→成果（Outcome）→障碍（Obstacle）→计划（Plan）。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"53-速查清单一周可上手\"\u003e5.3 速查清单（一周可上手）\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e每周\u003cstrong\u003e一次新方式\u003c/strong\u003e运用你的\u003cstrong\u003e前五优势\u003c/strong\u003e；在岗尽量覆盖≥4个优势。\u003c/li\u003e\n\u003cli\u003e把\u003cstrong\u003e钱\u003c/strong\u003e优先用在\u003cstrong\u003e体验/他人\u003c/strong\u003e上；为娱乐安排\u003cstrong\u003e小而频繁\u003c/strong\u003e的享受并\u003cstrong\u003e刻意中断\u003c/strong\u003e。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e每日感恩 3 件事\u003c/strong\u003e＋\u003cstrong\u003e每周一封感谢讯息\u003c/strong\u003e。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e正念/慈心冥想\u003c/strong\u003e10–15 分钟，配合\u003cstrong\u003e每周≥3次运动\u003c/strong\u003e与\u003cstrong\u003e固定就寝/起床\u003c/strong\u003e。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e社交优先\u003c/strong\u003e：与同事/陌生人开启短聊，把体验与人分享。\u003c/li\u003e\n\u003cli\u003e为关键习惯写 3 条 \u003cstrong\u003eIf–Then\u003c/strong\u003e，并用 \u003cstrong\u003eWOOP\u003c/strong\u003e 复盘障碍与应对。\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"6-主要参考\"\u003e6. 主要参考\u003c/h2\u003e\n\u003ch3 id=\"61-认知与预测偏误\"\u003e6.1 认知与预测偏误\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eSantos \u0026amp; Gendler (2014). Knowing is half the battle? Edge.\u003c/li\u003e\n\u003cli\u003eGilbert \u0026amp; Wilson (2000). Miswanting: Some problems in the forecasting of future affective states.\u003c/li\u003e\n\u003cli\u003eLevine et al. (2012). Accuracy and artifact: Reexamining the intensity bias in affective forecasting.\u003c/li\u003e\n\u003cli\u003eDunn et al. (2002). Location, location, location.\u003c/li\u003e\n\u003cli\u003eAyton et al. (2007). Affective forecasting: Why can\u0026rsquo;t people predict their emotions?\u003c/li\u003e\n\u003cli\u003eGilbert et al. (1998). Immune neglect…\u003c/li\u003e\n\u003cli\u003eGilbert (2007). \u003cem\u003eStumbling on Happiness\u003c/em\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"62-金钱与价值观\"\u003e6.2 金钱与价值观\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eEagan et al. (2015). \u003cem\u003eThe American Freshman Survey\u003c/em\u003e.\u003c/li\u003e\n\u003cli\u003eLinkedIn Survey (2014). What recent grads care the most about.\u003c/li\u003e\n\u003cli\u003eDiener \u0026amp; Oishi (2000). Money and happiness…\u003c/li\u003e\n\u003cli\u003eMyers (2000). \u003cem\u003eThe American Paradox\u003c/em\u003e.\u003c/li\u003e\n\u003cli\u003eLyubomirsky (2007). \u003cem\u003eThe How of Happiness\u003c/em\u003e.\u003c/li\u003e\n\u003cli\u003eKahneman \u0026amp; Deaton (2010). High income improves evaluation of life…\u003c/li\u003e\n\u003cli\u003eNew York Times. Economic diversity and student outcomes at Yale University.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"63-参照点与社会比较\"\u003e6.3 参照点与社会比较\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eMedvec et al. (1995). Olympic medalists \u0026amp; counterfactuals.\u003c/li\u003e\n\u003cli\u003evan Praag \u0026amp; Frijters (1999). Leyden approach.\u003c/li\u003e\n\u003cli\u003eClark \u0026amp; Oswald (1996). Satisfaction and comparison income.\u003c/li\u003e\n\u003cli\u003eSolnick \u0026amp; Hemenway (1997). Positional concerns.\u003c/li\u003e\n\u003cli\u003eClark (2003). Unemployment as a social norm.\u003c/li\u003e\n\u003cli\u003eO’Guinn \u0026amp; Shrum (1997). Television \u0026amp; consumer reality.\u003c/li\u003e\n\u003cli\u003eSchor (1999). \u003cem\u003eThe Overspent American\u003c/em\u003e.\u003c/li\u003e\n\u003cli\u003eKuhn et al. (2011). Dutch Postcode Lottery.\u003c/li\u003e\n\u003cli\u003eKenrick et al. (1989; 1993). Attractiveness \u0026amp; comparison.\u003c/li\u003e\n\u003cli\u003eVogel et al. (2014). Social media \u0026amp; self-esteem.\u003c/li\u003e\n\u003cli\u003eBurleigh \u0026amp; Meegan (2013). Keeping Up with the Joneses \u0026amp; justice.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"64-适应与物质体验\"\u003e6.4 适应与物质/体验\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eBrickman et al. (1978). Lottery winners \u0026amp; accident victims.\u003c/li\u003e\n\u003cli\u003eDi Tella et al. (2010). Adaptation to income \u0026amp; status.\u003c/li\u003e\n\u003cli\u003eLucas et al. (2003). Adaptation to marriage.\u003c/li\u003e\n\u003cli\u003eBoven \u0026amp; Gilovich (2003). To do or to have?\u003c/li\u003e\n\u003cli\u003eKumar et al. (2014). Anticipatory consumption of experiential purchases.\u003c/li\u003e\n\u003cli\u003ePchelin \u0026amp; Howell (2014). Hidden cost of value-seeking.\u003c/li\u003e\n\u003cli\u003eHowell \u0026amp; Hill (2009). Mediators of experiential purchases.\u003c/li\u003e\n\u003cli\u003eNelson \u0026amp; Meyvis (2008). Interrupted consumption.\u003c/li\u003e\n\u003cli\u003eNelson et al. (2009). Commercial interruptions \u0026amp; TV.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"65-优势心流心态与善意社交时间\"\u003e6.5 优势/心流/心态与善意社交时间\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eSeligman (2004); Seligman et al. (2005). Signature strengths \u0026amp; interventions.\u003c/li\u003e\n\u003cli\u003eLavy \u0026amp; Littman-Ovadia (2017); Harzer \u0026amp; Ruch (2012). Strengths at work.\u003c/li\u003e\n\u003cli\u003eCsikszentmihalyi (1992; 2008; 1999). Flow.\u003c/li\u003e\n\u003cli\u003eDeci (1971); Dweck (2007); Grant \u0026amp; Dweck (2003); Blackwell et al. (2007); Mangels et al. (2006). Growth mindset。\u003c/li\u003e\n\u003cli\u003eOtake et al. (2006); Lyubomirsky (2005); Dunn (2014); Dunn et al. (2008); Aknin et al. (2013). Kindness \u0026amp; prosocial spending.\u003c/li\u003e\n\u003cli\u003eMyers (2000); Diener \u0026amp; Seligman (2002); Epley (2014); Epley \u0026amp; Schroeder (2014); Boothby et al. (2014). Social connection.\u003c/li\u003e\n\u003cli\u003eWhillans et al. (2016); Hershfield et al. (2016); Moligner (2010). Time over money.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"66-正念健康与执行\"\u003e6.6 正念、健康与执行\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eKillingsworth \u0026amp; Gilbert (2010); Mason et al. (2007); Brewer et al. (2011); Fredrickson et al. (2008); Hölzel et al. (2011); Mrazek et al. (2013); Hutcherson et al. (2008). Mind-wandering \u0026amp; meditation.\u003c/li\u003e\n\u003cli\u003eBabyak et al. (2000); Hillman et al. (2008). Exercise \u0026amp; cognition.\u003c/li\u003e\n\u003cli\u003eDinges et al. (1997); Walker et al. (2002); Wagner et al. (2004); \u003cem\u003eHuffington Post\u003c/em\u003e（睡眠图解）. Sleep \u0026amp; performance.\u003c/li\u003e\n\u003cli\u003eWansink et al. (2006; 2016). Situation support \u0026amp; default choices.\u003c/li\u003e\n\u003cli\u003eKlein et al. (1990); Gollwitzer \u0026amp; Brandstätter (1997); Stadler \u0026amp; Oettingen (2010); Duckworth et al. (2013); Stadler et al. (2009). 目标与实施意图/WOOP。\u003c/li\u003e\n\u003c/ul\u003e","title":"耶鲁大学幸福科学课程总结"},{"content":"最近都在广泛学习一些有趣的内容，主要是通过coursera平台。在家呆了2个多月了，也不知道未来啥方向，目前也是有些迷茫的状态，还是学些东西充实下自己吧，搜寻一下感兴趣的东东。\ncoursera平台类似于国外的mooc，国内外还有好多这样的平台，如中国大学mooc、bilibili大学、网易云课等等。coursera需要付费会员才能观看课程，而且只能通过国外信用卡付款（无）。于是，我在淘宝一搜，这么多卖号，而且很便宜，86半年，立马充值了一波。\n有了平台，我立马重新在coursera里，拾起深度学习的基础知识，吴恩达的课程。之前只听过，在coursera认真地观看，还是感觉受益匪浅，毕竟有作业有互动，感觉b站还是差点味道。\n现在主要看了深度学习专项课程的前3个：\n其实就相当于复习了一下之前在李沐动手学深度学习的内容。\n然后光看深度学习也有些乏味，我在网上搜索coursera有没有其他好课程，打开了一个课程排名，类似于垃圾小网站的那种：\n然后最近在看幸福科学，才刚开始看，讲的是如何变得幸福，通过科学的方式，感觉讲的还挺好的，在实验的加持下，科学成为人们可以坚持最大的迷信，hhh，但是还是要有反驳精神，感觉很多科学实验严谨性还是有些欠缺。\n之后的日子，想了解一下金融相关的知识，挺感兴趣的。马上要开学了，5555，希望能保持学习一些课外内容的习惯。还有，运动也要保持，在家和爸妈打了一个暑假的乒乓球，每日锻炼~\n","permalink":"http://localhost:1313/posts/%E6%9C%80%E8%BF%91%E5%9C%A8%E5%81%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E4%BA%8B/","summary":"\u003cp\u003e最近都在广泛学习一些有趣的内容，主要是通过coursera平台。在家呆了2个多月了，也不知道未来啥方向，目前也是有些迷茫的状态，还是学些东西充实下自己吧，搜寻一下感兴趣的东东。\u003c/p\u003e\n\u003cp\u003ecoursera平台类似于国外的mooc，国内外还有好多这样的平台，如中国大学mooc、bilibili大学、网易云课等等。coursera需要付费会员才能观看课程，而且只能通过国外信用卡付款（无）。于是，我在淘宝一搜，这么多卖号，而且很便宜，86半年，立马充值了一波。\u003c/p\u003e\n\u003cp\u003e有了平台，我立马重新在coursera里，拾起深度学习的基础知识，吴恩达的课程。之前只听过，在coursera认真地观看，还是感觉受益匪浅，毕竟有作业有互动，感觉b站还是差点味道。\u003c/p\u003e\n\u003cp\u003e现在主要看了深度学习专项课程的前3个：\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"233\" loading=\"lazy\" src=\"/posts/%E6%9C%80%E8%BF%91%E5%9C%A8%E5%81%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E4%BA%8B/image-20250825155253827.png\"\u003e\u003c/p\u003e\n\u003cp\u003e其实就相当于复习了一下之前在李沐动手学深度学习的内容。\u003c/p\u003e\n\u003cp\u003e然后光看深度学习也有些乏味，我在网上搜索coursera有没有其他好课程，打开了一个课程排名，类似于垃圾小网站的那种：\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"2333\" loading=\"lazy\" src=\"/posts/%E6%9C%80%E8%BF%91%E5%9C%A8%E5%81%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E4%BA%8B/image-20250825155452140.png\"\u003e\u003c/p\u003e\n\u003cp\u003e然后最近在看幸福科学，才刚开始看，讲的是如何变得幸福，通过科学的方式，感觉讲的还挺好的，在实验的加持下，科学成为人们可以坚持最大的迷信，hhh，但是还是要有反驳精神，感觉很多科学实验严谨性还是有些欠缺。\u003c/p\u003e\n\u003cp\u003e之后的日子，想了解一下金融相关的知识，挺感兴趣的。马上要开学了，5555，希望能保持学习一些课外内容的习惯。还有，运动也要保持，在家和爸妈打了一个暑假的乒乓球，每日锻炼~\u003c/p\u003e","title":"最近在做的一些事"},{"content":"softmax是一个经典的多分类概率分布的公式，有n个类，softmax公式如下， $$ \\text{softmax}(z)_j = \\frac{e^{z_j}}{\\sum_{i=1}^n e^{z_i}}, \\quad j = 1, 2, \\dots, n $$ 首先，考虑一个样本每个类的预测分数做一个softmax，转换成每类预测的概率形式。\n$$ a^{[L]} = \\text{softmax}(z^{[L]}) $$$$ \\hat{y} = a^{[L]}\\quad $$然后，利用样本标签，结合极大似然估计的损失函数如下。 $$ L(\\hat{y}, y) = - \\sum_{i=1}^{n} y_i \\log(\\hat{y}_i) $$由于需要做反向传播，我们想求 $\\frac{\\partial L}{\\partial z^{[L]}}$，也就是做完softmax的前的偏导数。\n假设 $y$ 的分类为 $1$，则 $y_1 = 1$，其余 $y_j = 0\\ (j\\neq 1)$，$y=[1,0,.....,0]$ 则有， $$ L(\\hat{y}, y) = -\\log(\\hat{y}_1) $$$$ L(\\hat{y}, y) = - \\ln \\left( \\frac{e^{z_1^{[L]}}}{e^{z_1^{[L]}} + e^{z_2^{[L]}} + \\cdots + e^{z_n^{[L]}}} \\right), \\quad S = e^{z_1^{[L]}} + e^{z_2^{[L]}} + \\cdots + e^{z_n^{[L]}} $$接下来求 $Z^{[L]}$ 的偏导， $$ \\frac{\\partial L}{\\partial z^{[L]}_1} = -\\frac{S}{e^{z^{[L]}_1}} \\cdot \\frac{e^{z^{[L]}_1} \\cdot S - \\big(e^{z^{[L]}_1}\\big)^2}{S^2} = \\frac{e^{z^{[L]}_1}}{S} - 1 $$$$ \\frac{\\partial L}{\\partial z^{[L]}_j} = - \\frac{S}{e^{z^{[L]}_1}} \\cdot \\frac{-e^{z^{[L]}_1} \\cdot e^{z^{[L]}_j}}{S^2} = \\frac{e^{z^{[L]}_j}}{S}, \\quad j \\neq 1 $$因为， $$ a_j^{[L]} = \\frac{e^{z_j^{[L]}}}{S}, $$ 所以， $$ \\frac{\\partial L}{\\partial z^{[L]}_1} = a_1^{[L]} - 1 $$$$ \\frac{\\partial L}{\\partial z^{[L]}_j} = a_j^{[L]}, \\quad (j \\neq 1) $$由于不同分类标签的对称性，从而得到最终化简结果， $$ \\frac{\\partial L}{\\partial z^{[L]}} = \\hat{y} - y $$ 对于多样本，每个样本间独立，则有， $$ \\frac{\\partial L}{\\partial Z^{[L]}} = \\hat{Y} - Y $$","permalink":"http://localhost:1313/posts/softmax%E7%9A%84%E5%AF%BC%E6%95%B0%E6%8E%A8%E5%AF%BC/","summary":"\u003cp\u003esoftmax是一个经典的多分类概率分布的公式，有n个类，softmax公式如下，\n\u003c/p\u003e\n$$\n\\text{softmax}(z)_j = \\frac{e^{z_j}}{\\sum_{i=1}^n  e^{z_i}}, \\quad j = 1, 2, \\dots, n\n$$\u003cp\u003e\n首先，考虑一个样本每个类的预测分数做一个softmax，转换成每类预测的概率形式。\u003c/p\u003e\n$$\na^{[L]} = \\text{softmax}(z^{[L]})\n$$$$\n\\hat{y} = a^{[L]}\\quad\n$$\u003cp\u003e然后，利用样本标签，结合极大似然估计的损失函数如下。\n\u003c/p\u003e\n$$\nL(\\hat{y}, y) = - \\sum_{i=1}^{n} y_i \\log(\\hat{y}_i)\n$$\u003cp\u003e由于需要做反向传播，我们想求 $\\frac{\\partial L}{\\partial z^{[L]}}$，也就是做完softmax的前的偏导数。\u003c/p\u003e\n\u003cp\u003e假设 $y$ 的分类为 $1$，则 $y_1 = 1$，其余 $y_j = 0\\ (j\\neq 1)$，$y=[1,0,.....,0]$\n则有，\n\u003c/p\u003e\n$$\nL(\\hat{y}, y) = -\\log(\\hat{y}_1)\n$$$$\nL(\\hat{y}, y) = - \\ln \\left( \\frac{e^{z_1^{[L]}}}{e^{z_1^{[L]}} + e^{z_2^{[L]}} + \\cdots + e^{z_n^{[L]}}} \\right),\n\\quad S = e^{z_1^{[L]}} + e^{z_2^{[L]}} + \\cdots + e^{z_n^{[L]}}\n$$\u003cp\u003e接下来求 $Z^{[L]}$ 的偏导，\n\u003c/p\u003e","title":"Softmax的反向传播推导"},{"content":"\n最近在重新回顾深度学习相关基础，之前大概过了一遍李沐的动手学深度学习，但很多内容还一知半解， 感觉网上课程难度曲线还是不太平滑。\n无意间看到 Coursera平台，在淘宝上花了80买了个半年号，仿佛打开新世界了，第一次看到了原来真的有课程能把深度学习的学习曲线 弄的这么平滑的，爱了，有点像算法竞赛的acwing、牛客。感觉b站确实不错，但是反馈和互动肯定远远比不上Coursera的。\n现在刚学完第一门课程，并手动设计并实现了多层卷积神经网络（只用到numpy），在这里记录一下forward/back propagation的数学知识（主要是线性代数）。\n正向传播 非常简单易懂，就是矩阵乘法。\n反向传播 引理一 搞懂这个引理反向传播就差不多弄懂了，求哪个偏导，固定某行/列值算贡献 就好求了（A固定行，B固定列），因为矩阵乘法是B的列与A的行做点积。\n以上就是神经网络里的线性代数的一些知识，其实不需要太多基础弄得矩阵乘法，和求导链式法则即可手写神经网络。\n","permalink":"http://localhost:1313/posts/%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC/","summary":"\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC/2.png\"\u003e\u003c/p\u003e\n\u003cp\u003e最近在重新回顾深度学习相关基础，之前大概过了一遍李沐的动手学深度学习，但很多内容还一知半解，\n感觉网上课程难度曲线还是不太平滑。\u003c/p\u003e\n\u003cp\u003e无意间看到 \u003ca href=\"https://www.coursera.org/\"\u003eCoursera平台\u003c/a\u003e，在淘宝上花了80买了个半年号，仿佛打开新世界了，第一次看到了原来真的有课程能把深度学习的学习曲线\n弄的这么平滑的，爱了，有点像算法竞赛的acwing、牛客。感觉b站确实不错，但是反馈和互动肯定远远比不上Coursera的。\u003c/p\u003e\n\u003cp\u003e现在刚学完第一门课程，并手动设计并实现了多层卷积神经网络（只用到numpy），在这里记录一下forward/back propagation的数学知识（主要是线性代数）。\u003c/p\u003e\n\u003ch4 id=\"正向传播\"\u003e正向传播\u003c/h4\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC/%281%29.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003e非常简单易懂，就是矩阵乘法。\u003c/p\u003e\n\u003ch4 id=\"反向传播\"\u003e反向传播\u003c/h4\u003e\n\u003ch5 id=\"引理一\"\u003e引理一\u003c/h5\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC/%282%29.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC/%283%29.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003e搞懂这个引理反向传播就差不多弄懂了，求哪个偏导，固定某行/列值算贡献 就好求了（A固定行，B固定列），因为矩阵乘法是B的列与A的行做点积。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC/%284%29.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003e以上就是神经网络里的线性代数的一些知识，其实不需要太多基础弄得矩阵乘法，和求导链式法则即可手写神经网络。\u003c/p\u003e","title":"神经网络反向传播 数学推导"},{"content":"工具介绍 Hugo 简介：Hugo 是一个用 Go 语言编写的静态网站生成器。它以极快的生成速度著称，可以在几秒内构建上千页面。\n特点：\n不依赖数据库，所有页面都是静态文件，部署简单且性能高。 支持 Markdown 写作，适合博客和文档站点。 拥有强大的模板系统和主题生态。 跨平台运行（Windows、Linux、macOS）。 PaperMod 简介：PaperMod 是 Hugo 社区里非常流行的一个 简洁、现代的主题，灵感来自 Google Material Design。\n特点：\n设计简洁清爽，注重阅读体验。 自带夜间模式、搜索、标签分类等功能。 对 SEO 和性能友好，开箱即用。 支持高度自定义，比如文章目录、社交链接、评论系统等。 👉 总结：Hugo 是建站工具，PaperMod 是在 Hugo 上常用的主题之一。\nStep 1 按照下面视频安装hugo+papermod，搭建demo\n【雷】Hugo + Github免费搭建博客，并实现自动化部署\nStep 2 配置papermod主题，结合大语言模型，想要什么功能直接询问即可，并修改配置文件，主题大部分都是配有相关功能的。\n","permalink":"http://localhost:1313/posts/hugo+paermod%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%95%99%E7%A8%8B/","summary":"\u003ch3 id=\"工具介绍\"\u003e工具介绍\u003c/h3\u003e\n\u003ch4 id=\"hugo\"\u003eHugo\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e简介\u003c/strong\u003e：Hugo 是一个用 Go 语言编写的\u003cstrong\u003e静态网站生成器\u003c/strong\u003e。它以极快的生成速度著称，可以在几秒内构建上千页面。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e特点\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e不依赖数据库，所有页面都是静态文件，部署简单且性能高。\u003c/li\u003e\n\u003cli\u003e支持 Markdown 写作，适合博客和文档站点。\u003c/li\u003e\n\u003cli\u003e拥有强大的模板系统和主题生态。\u003c/li\u003e\n\u003cli\u003e跨平台运行（Windows、Linux、macOS）。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"papermod\"\u003ePaperMod\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e简介\u003c/strong\u003e：PaperMod 是 Hugo 社区里非常流行的一个 \u003cstrong\u003e简洁、现代的主题\u003c/strong\u003e，灵感来自 Google Material Design。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e特点\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e设计简洁清爽，注重阅读体验。\u003c/li\u003e\n\u003cli\u003e自带夜间模式、搜索、标签分类等功能。\u003c/li\u003e\n\u003cli\u003e对 SEO 和性能友好，开箱即用。\u003c/li\u003e\n\u003cli\u003e支持高度自定义，比如文章目录、社交链接、评论系统等。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e👉 总结：\u003cstrong\u003eHugo\u003c/strong\u003e 是建站工具，\u003cstrong\u003ePaperMod\u003c/strong\u003e 是在 Hugo 上常用的主题之一。\u003c/p\u003e\n\u003ch3 id=\"step-1\"\u003eStep 1\u003c/h3\u003e\n\u003cp\u003e按照下面视频安装hugo+papermod，搭建demo\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://www.bilibili.com/video/BV1bovfeaEtQ?vd_source=89574dec834a4f547f86ccea8df6514e\"\u003e【雷】Hugo + Github免费搭建博客，并实现自动化部署\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id=\"step-2\"\u003eStep 2\u003c/h3\u003e\n\u003cp\u003e配置papermod主题，结合大语言模型，想要什么功能直接询问即可，并修改配置文件，主题大部分都是配有相关功能的。\u003c/p\u003e","title":"hugo+papermod博客搭建教程"},{"content":"你好，我是 wanghai673，一名正在攻读 计算机科学与技术 的研究生（研 0），本科毕业于东华大学，目前就读于华东师范大学。\n💻 编程语言：C++、Python、Java\n🔍 研究兴趣：深度学习、大语言模型、智能体\n🏆 竞赛经历：\nICPC 亚洲区域赛 金奖（第 49 届） 蓝桥杯全国总决赛 一等奖（全国第 6 名） 百度之星全国总决赛 金奖 多次 ICPC/CCPC 银奖 上海市大学生程序设计竞赛 一等奖 我正在不断学习和提升自己，期待将所学应用于实际问题。如果有相关的 实习机会 或者 研究合作，非常欢迎联系我。\n📫 联系方式：微信、邮件\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e你好，我是 \u003cstrong\u003ewanghai673\u003c/strong\u003e，一名正在攻读 \u003cstrong\u003e计算机科学与技术\u003c/strong\u003e 的研究生（研 0），本科毕业于东华大学，目前就读于华东师范大学。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e💻 编程语言：C++、Python、Java\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e🔍 研究兴趣：深度学习、大语言模型、智能体\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e🏆 竞赛经历：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eICPC 亚洲区域赛 \u003cstrong\u003e金奖（第 49 届）\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e蓝桥杯全国总决赛 \u003cstrong\u003e一等奖（全国第 6 名）\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e百度之星全国总决赛 \u003cstrong\u003e金奖\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e多次 ICPC/CCPC \u003cstrong\u003e银奖\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e上海市大学生程序设计竞赛 \u003cstrong\u003e一等奖\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e我正在不断学习和提升自己，期待将所学应用于实际问题。如果有相关的 \u003cstrong\u003e实习机会\u003c/strong\u003e 或者 \u003cstrong\u003e研究合作\u003c/strong\u003e，非常欢迎联系我。\u003c/p\u003e\n\u003cp\u003e📫 联系方式：\u003ca href=\"wechat.jpg\"\u003e微信\u003c/a\u003e、\u003ca href=\"https://mail.qq.com/cgi-bin/qm_share?t=qm_mailme\u0026amp;email=1154103986@qq.com\"\u003e邮件\u003c/a\u003e\u003c/p\u003e","title":"关于"},{"content":"EduAgent: Generative Student Agents in Learning 总结\n本文是针对线上教育领域的学生模仿相关的研究，之前的模型多利用庞大的数据对学生学习行为进行预测，随着LLM的问世，LLM提供的前置知识能很好的针对不同场景不同内容线上教育的学生行为预测。\n学生行为预测受到多方面的影响，如性格、学生储备知识等，本文提供了一个数据集（350个sample），针对一段5分钟的幻灯片讲解，提供学生个人信息和每个小时间段的学生注意窗口、行为、认知状态信息等。\n作者结合LLM强大的推理功能，让LLM自主推理出不同信息间的关联，从而实现学生行为的预测和模仿，但这篇论文的实验没咋看懂\u0026hellip;\nLLM-mediated domain-specific voice agents: the case of TextileBot 总结\n粗粒度地看了下\u0026hellip;\n只看了摘要和引言和结论，讲的是如何原型化地设计一个垂直领域的对话agent，包含prompt模板，随后作者自己设计了一个宣传服装环保领域的一个agent（在购物的时候跟顾客交流的），并做了用户实验。\nWhy language models hallucinate 总结\nWhy language models hallucinate | OpenAI\nOpenAI 9月5号刚发布的文章，主要讲述了为什么大语言模型会产生幻觉。\n作者描述，LLM（大语言模型）之所以产生幻觉，是因为现在对模型后训练的奖励函数，往往将答错一道题和拒答一道题（承认不知道）的惩罚都是一致的，导致LLM更倾向于去猜题，这样还有概率猜对。\n那有人就会说了，让答错的惩罚提升一些不就行了。确实可以，但是作者回应到现如今大多数的benchmark，只有对/错两个选项，并没有考虑到幻觉的因素，从而导致大家更宁愿LLM猜题，增加一些benchmark的准确率，而不是拒答（大幅度降低幻觉，但准确率会略微降低）。\n作者呼吁所有benchmark的制作者们，将幻觉这个评价指标加入到benchmark的评测之中，从而抑制LLM的胡言乱语。但现在的benchmark对幻觉的评判往往是特定的一类，大多数benmark没有考虑幻觉因素。\n上面都是通过后训练降低LLM幻觉的途径，那能不能在预训练的时候降低大语言模型的幻觉呢？作者回答，现在的数据都是无监督的，导致LLM并没有办法对每段数据的真实性做判断，更好的办法还是在后训练的时候减少大模型的幻觉。\n下图是原文的提出的LLM幻觉的一些误解与澄清：\n","permalink":"http://localhost:1313/posts/9.6_%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/","summary":"\u003ch3 id=\"eduagent-generative-student-agents-in-learning\"\u003eEduAgent: Generative Student Agents in Learning\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e总结\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e本文是针对线上教育领域的学生模仿相关的研究，之前的模型多利用庞大的数据对学生学习行为进行预测，随着LLM的问世，LLM提供的前置知识能很好的针对不同场景不同内容线上教育的学生行为预测。\u003c/p\u003e\n\u003cp\u003e学生行为预测受到多方面的影响，如性格、学生储备知识等，本文提供了一个数据集（350个sample），针对一段5分钟的幻灯片讲解，提供学生个人信息和每个小时间段的学生注意窗口、行为、认知状态信息等。\u003c/p\u003e\n\u003cp\u003e作者结合LLM强大的推理功能，让LLM自主推理出不同信息间的关联，从而实现学生行为的预测和模仿，但这篇论文的实验没咋看懂\u0026hellip;\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"llm-mediated-domain-specific-voice-agents-the-case-of-textilebot\"\u003eLLM-mediated domain-specific voice agents: the case of TextileBot\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e总结\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e粗粒度地看了下\u0026hellip;\u003c/p\u003e\n\u003cp\u003e只看了摘要和引言和结论，讲的是如何原型化地设计一个垂直领域的对话agent，包含prompt模板，随后作者自己设计了一个宣传服装环保领域的一个agent（在购物的时候跟顾客交流的），并做了用户实验。\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"why-language-models-hallucinate\"\u003eWhy language models hallucinate\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e总结\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://openai.com/index/why-language-models-hallucinate/\"\u003eWhy language models hallucinate | OpenAI\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eOpenAI 9月5号刚发布的文章，主要讲述了为什么大语言模型会产生幻觉。\u003c/p\u003e\n\u003cp\u003e作者描述，LLM（大语言模型）之所以产生幻觉，是因为现在对模型后训练的奖励函数，往往将答错一道题和拒答一道题（承认不知道）的惩罚都是一致的，导致LLM更倾向于去猜题，这样还有概率猜对。\u003c/p\u003e\n\u003cp\u003e那有人就会说了，让答错的惩罚提升一些不就行了。确实可以，但是作者回应到现如今大多数的benchmark，只有对/错两个选项，并没有考虑到幻觉的因素，从而导致大家更宁愿LLM猜题，增加一些benchmark的准确率，而不是拒答（大幅度降低幻觉，但准确率会略微降低）。\u003c/p\u003e\n\u003cp\u003e作者呼吁所有benchmark的制作者们，将幻觉这个评价指标加入到benchmark的评测之中，从而抑制LLM的胡言乱语。但现在的benchmark对幻觉的评判往往是特定的一类，大多数benmark没有考虑幻觉因素。\u003c/p\u003e\n\u003cp\u003e上面都是通过后训练降低LLM幻觉的途径，那能不能在预训练的时候降低大语言模型的幻觉呢？作者回答，现在的数据都是无监督的，导致LLM并没有办法对每段数据的真实性做判断，更好的办法还是在后训练的时候减少大模型的幻觉。\u003c/p\u003e\n\u003cp\u003e下图是原文的提出的LLM幻觉的一些误解与澄清：\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250906164329093\" loading=\"lazy\" src=\"c:\\\\Users\\\\11541\\\\AppData\\\\Roaming\\\\Typora\\\\typora-user-images\\\\image-20250906164329093.png\"\u003e\u003c/p\u003e","title":"9.6 论文阅读"},{"content":"LLM Agents for Education: Advances and Applications 总结\n这是一篇综述论文，讲述了现在LLM agents在领域的各种运用。作者将教育agent分为 教学agent 和 垂直领域agent。\n教学agent又分为面向学生和面向教师的，垂直领域的分为很多不同学科类的agent，不同学科agent也有不同的功能的agent，整体分类思维导图见下图。\n然后作者讲述了，现有教育agent所面临的困难，如道德、偏见方面的，也有幻觉、可靠性方面的。现有的agent大多数不具备结构化的形式（更多是对话类型），无法直接在现实教育场景中插入。\n最后整理介绍了现有测评教育agent各种benchmark，以供后来研究者使用。\nMATHAGENT: Leveraging a Mixture-of-Math-Agent Framework for Real-World Multimodal Mathematical Error Detection 背景\n大语言模型在数学问题求解中已经非常厉害了，但是在数学错误发现上还很少涉足。传统的数学老师批改，耗时耗力，并且不具备可扩展性，如无法为学生指明学生具体错误（人工成本高），多模态大模型可以识别图片，并且为学生提供错误位置和错误分类，但是MLLM还在存在较多错误，对于有细微错误的地方无法很好识别。并且现在研究多聚焦纯文本数学题改错，对于带有图片信息的不能很好应对。\n方法\n数据集合为下图，有文本问题描述，图片类信息，正确答案，学生的不正确答案，解题步骤。 任务分为 1：找到第一个错误步骤，2：错误分类，指标都是准确率。\n作者引入了个多智能体框架，分为三个部分，流程如下图。\n文本-图像一致性检测：判断图片和文字是否高度一致，避免使用图片识别功能，从而增强题目解读能力 公式-表格识别：用专门model将各种公式、表格等识别为文本形式 融合找错：将文本和转文本的图片信息融合为一个完整题目，并且让LLM完成上面具体两个任务 实验结果\n将该方法运用到多个多模态大模型，大部分都能提升准确率，但相较于人工还有很大的差距。 论文写的浅显易懂，结构也很清晰，可惜本论文并未公布数据集。。。\n","permalink":"http://localhost:1313/posts/9%E6%9C%885%E6%97%A5%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/","summary":"\u003ch3 id=\"llm-agents-for-education-advances-and-applications\"\u003eLLM Agents for Education: Advances and Applications\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e总结\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e这是一篇综述论文，讲述了现在LLM agents在领域的各种运用。作者将教育agent分为 教学agent 和 垂直领域agent。\u003c/p\u003e\n\u003cp\u003e教学agent又分为面向学生和面向教师的，垂直领域的分为很多不同学科类的agent，不同学科agent也有不同的功能的agent，整体分类思维导图见下图。\u003c/p\u003e\n\u003cp\u003e然后作者讲述了，现有教育agent所面临的困难，如道德、偏见方面的，也有幻觉、可靠性方面的。现有的agent大多数不具备结构化的形式（更多是对话类型），无法直接在现实教育场景中插入。\u003c/p\u003e\n\u003cp\u003e最后整理介绍了现有测评教育agent各种benchmark，以供后来研究者使用。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250905134524279\" loading=\"lazy\" src=\"/posts/9%E6%9C%885%E6%97%A5%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/image-20250905134524279.png\"\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"mathagent-leveraging-a-mixture-of-math-agent-framework-for-real-world-multimodal-mathematical-error-detection\"\u003eMATHAGENT: Leveraging a Mixture-of-Math-Agent Framework for Real-World Multimodal Mathematical Error Detection\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e背景\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e大语言模型在数学问题求解中已经非常厉害了，但是在数学错误发现上还很少涉足。传统的数学老师批改，耗时耗力，并且不具备可扩展性，如无法为学生指明学生具体错误（人工成本高），多模态大模型可以识别图片，并且为学生提供错误位置和错误分类，但是MLLM还在存在较多错误，对于有细微错误的地方无法很好识别。并且现在研究多聚焦纯文本数学题改错，对于带有图片信息的不能很好应对。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e方法\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e数据集合为下图，有文本问题描述，图片类信息，正确答案，学生的不正确答案，解题步骤。\n任务分为  1：找到第一个错误步骤，2：错误分类，指标都是准确率。\u003c/p\u003e\n\u003cimg src=\"image-20250905153558820.png\" alt=\"image-20250905153558820\" style=\"zoom:67%;\" /\u003e\n\u003cp\u003e作者引入了个多智能体框架，分为三个部分，流程如下图。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e文本-图像一致性检测：判断图片和文字是否高度一致，避免使用图片识别功能，从而增强题目解读能力\u003c/li\u003e\n\u003cli\u003e公式-表格识别：用专门model将各种公式、表格等识别为文本形式\u003c/li\u003e\n\u003cli\u003e融合找错：将文本和转文本的图片信息融合为一个完整题目，并且让LLM完成上面具体两个任务\u003cimg src=\"image-20250905153953903.png\" alt=\"image-20250905153953903\" style=\"zoom:67%;\" /\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e实验结果\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e将该方法运用到多个多模态大模型，大部分都能提升准确率，但相较于人工还有很大的差距。\n\u003cimg alt=\"image-20250905154103167\" loading=\"lazy\" src=\"/posts/9%E6%9C%885%E6%97%A5%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/image-20250905154103167.png\"\u003e\u003c/p\u003e\n\u003cp\u003e论文写的浅显易懂，结构也很清晰，可惜本论文并未公布数据集。。。\u003c/p\u003e","title":"9.5 论文阅读"},{"content":"最近闲着无聊随便做了一个windows的语音唤醒助手，主要是闲平常要出门，或者不方便的时候（比如运动、躺床上的时候），可以叫一声电脑就做我想让他做的内容（可以连接LLM/GUI agent/MCP等等）。\n再加上现在GUIAgent发展的很快，网上还没有语音唤醒形式的链接，也就自己搭了一个出来。\n下面是这个项目的readme。\nWinAssistant – Windows 本地语音唤醒与自动化执行 一个在 Windows 上运行的本地语音助手：\n说出唤醒词 → 识别你的语音 → 自动执行自定义动作（脚本、GUI Agent、MCP 等）。 全离线（唤醒+识别均可离线），即插即用，优先使用耳机麦克风。 演示视频 https://github.com/user-attachments/assets/a48b8e94-8b95-46eb-9aa5-a4085c2341c4\n✨ 核心特性 多唤醒词可选 / 可自定义 内置多种常见唤醒词，也可替换为你训练的 .ppn 文件。\n本地唤醒：Picovoice Porcupine 轻量、低延迟、可靠，离线运行。\n语音识别：fast-whisper 内置去噪、VAD 端点检测，自动判断“用户是否说完”，可按需调节模型大小（速度/准确度权衡）。\n自动音频设备选择 自动选择可用的输入/输出设备，优先耳机。\n可插拔“处理态” 识别到文本后进入你的“处理态”（可自定义），例如：\n调用 MCP / 工具调用 触发 GUI Agent 执行脚本、打开应用、查询信息等 🧠 工作流 / 状态机 stateDiagram-v2 [*] --\u0026gt; 空闲态 空闲态 --\u0026gt; 唤醒态: 语音唤醒 唤醒态 --\u0026gt; 处理态: 用户语音结束 处理态 --\u0026gt; 空闲态 唤醒态 --\u0026gt; 空闲态: 用户长时间无应答 空闲态 --\u0026gt; 空闲态: （持续监听） 说明：唤醒后进入实时听写；若检测到长时间静音则回退到空闲态。\n📦 目录结构 WINASSISTANT/ ├─ model/ │ ├─ 小智.ppn # 自定义/内置唤醒词（Porcupine） │ └─ porcupine_params_zh.pv # 中文参数 ├─ music/ # 系统提示音 │ ├─ ok.wav │ ├─ sorry.wav │ └─ zai.wav ├─ utils/ │ ├─ player.py # 播放器：播放提示音/反馈 │ ├─ reader.py # 识别器：fast-whisper + VAD │ ├─ rouser.py # 唤醒：Porcupine 推理 │ └─ UIoperator.py # 处理态模板（可自定义） ├─ .env # 环境变量（见下） ├─ main.py # 入口：python main.py └─ requirements.txt # 依赖 🚀 快速开始 1) 环境准备 Windows 10/11 Python 3.9+（建议 64-bit） 麦克风 \u0026amp; 扬声器/耳机 git clone https://github.com/wanghai673/WinAssistant cd WINASSISTANT # 建议：创建虚拟环境 python -m venv .venv .\\.venv\\Scripts\\activate pip install -r requirements.txt 2) 申请 Picovoice Access Key 前往 https://picovoice.ai/ 免费获取 ACCESS_KEY。\n3) 配置 .env 在项目根目录创建或修改 .env：\nACCESS_KEY=你的AccessKey # 唤醒词（可选：小智, hey google, grasshopper, computer, americano, # bumblebee, hey barista, ok google, pico clock, porcupine, # picovoice, jarvis, terminator, grapefruit, blueberry, alexa, hey siri） ROUSE_WORD=小智 想用自定义唤醒词？把训练好的 .ppn 文件放到 model/ 并在代码/ENV 中指向它即可。\n4) 运行 python main.py 说出唤醒词（默认 “小智”）→ 说出命令 → 听到提示音并执行。\n🧩 自定义“处理态” 识别结果会进入你的“处理态”模块（示例：utils/UIoperator.py）。 你可以在这里：\n串接 MCP 工具调用 通过 GUI Agent 操作桌面 执行脚本 / 打开应用 / 系统自动化 回放 music/ok.wav / sorry.wav 作为反馈 建议将业务逻辑与语音管线解耦：保留 player / reader / rouser 作为通用能力层，处理态专注于“要做什么”。\n⚙️ 常用调优点 VAD/静音阈值：在 reader.py 中调整 MAX_SILENCE_SECS 等参数，影响“说完就停”的敏感度。 模型大小：根据机器性能切换 fast-whisper 模型（小模型更快，大模型更准）。 提示音屏蔽：通过 realtime_zh(..., beep_guard=0.5) 吞掉前 0.5s 系统“滴”声，避免影响识别。 音频设备：默认自动选择，优先耳机；如需固定设备，可在 player/reader 中指定设备索引。 🔐 隐私与本地化 唤醒与识别均可离线完成；音频不会上传到云端。 仅在你显式配置联网服务时才会产生外部调用。 🧪 简单示例（伪代码） # 极简示例：监听唤醒 → 识别 from utils.player import Player from utils.reader import Reader from utils.rouser import Rouser from pvrecorder import PvRecorder from dotenv import load_dotenv import os load_dotenv() ACCESS_KEY = os.getenv(\u0026#34;ACCESS_KEY\u0026#34;) ROUSE_WORD = os.getenv(\u0026#34;ROUSE_WORD\u0026#34;, \u0026#34;小智\u0026#34;) DEVICE_INDEX = -1 # 使用系统默认输入设备 rouser = Rouser(access_key=ACCESS_KEY, device_index=DEVICE_INDEX, keyword=ROUSE_WORD) player = Player() reader = Reader(device_index=DEVICE_INDEX) recorder = PvRecorder(device_index=DEVICE_INDEX, frame_length=rouser.porcupine.frame_length) recorder.start() print(f\u0026#34;正在监听唤醒词：『{ROUSE_WORD}』 (Ctrl+C 退出)\u0026#34;) while True: pcm = recorder.read() if rouser.process(pcm) \u0026gt;= 0: # 检测到唤醒 player.play_voice(block=True) # 提示音 text = reader.realtime_zh(rec_shared=recorder, beep_guard=0.0) if text: print(\u0026#34;识别文本：\u0026#34;, text) player.play_voice(block=True, type=\u0026#34;ok\u0026#34;) # 在这里根据 text 执行动作... else: player.play_voice(block=True, type=\u0026#34;sorry\u0026#34;) 🧯 故障排查 没有反应 / 设备占用：检查是否有其他应用占用麦克风；尝试在系统声音设置中启用设备。 识别慢：试用更小的 fast-whisper 模型或关闭其他高占用程序。 唤醒不灵敏：更换更清晰的唤醒词模型 .ppn，或在安静环境下测试。 提示音被识别进去：增大 beep_guard（如 0.7）。 🙌 致谢 Picovoice Porcupine（本地唤醒） fast-whisper（快速 ASR） ","permalink":"http://localhost:1313/posts/windows%E8%AF%AD%E9%9F%B3%E5%94%A4%E9%86%92%E5%8A%A9%E6%89%8B/","summary":"\u003cp\u003e最近闲着无聊随便做了一个\u003ca href=\"https://github.com/wanghai673/WinAssistant/\"\u003ewindows的语音唤醒助手\u003c/a\u003e，主要是闲平常要出门，或者不方便的时候（比如运动、躺床上的时候），可以叫一声电脑就做我想让他做的内容（可以连接LLM/GUI agent/MCP等等）。\u003c/p\u003e\n\u003cp\u003e再加上现在GUIAgent发展的很快，网上还没有语音唤醒形式的链接，也就自己搭了一个出来。\u003c/p\u003e\n\u003cp\u003e下面是这个项目的readme。\u003c/p\u003e\n\u003ch1 id=\"winassistant--windows-本地语音唤醒与自动化执行\"\u003eWinAssistant – Windows 本地语音唤醒与自动化执行\u003c/h1\u003e\n\u003cp\u003e一个在 \u003cstrong\u003eWindows\u003c/strong\u003e 上运行的本地语音助手：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e说出唤醒词 → 识别你的语音 → 自动执行自定义动作（脚本、GUI Agent、MCP 等）。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e全离线\u003c/strong\u003e（唤醒+识别均可离线），即插即用，优先使用耳机麦克风。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"演示视频\"\u003e演示视频\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/user-attachments/assets/a48b8e94-8b95-46eb-9aa5-a4085c2341c4\"\u003ehttps://github.com/user-attachments/assets/a48b8e94-8b95-46eb-9aa5-a4085c2341c4\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"-核心特性\"\u003e✨ 核心特性\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e多唤醒词可选 / 可自定义\u003c/strong\u003e\n内置多种常见唤醒词，也可替换为你训练的 \u003ccode\u003e.ppn\u003c/code\u003e 文件。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e本地唤醒：Picovoice Porcupine\u003c/strong\u003e\n轻量、低延迟、可靠，离线运行。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e语音识别：fast-whisper\u003c/strong\u003e\n内置\u003cstrong\u003e去噪\u003c/strong\u003e、\u003cstrong\u003eVAD 端点检测\u003c/strong\u003e，自动判断“用户是否说完”，可按需调节模型大小（速度/准确度权衡）。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e自动音频设备选择\u003c/strong\u003e\n自动选择可用的输入/输出设备，\u003cstrong\u003e优先耳机\u003c/strong\u003e。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e可插拔“处理态”\u003c/strong\u003e\n识别到文本后进入你的“处理态”（可自定义），例如：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e调用 MCP / 工具调用\u003c/li\u003e\n\u003cli\u003e触发 GUI Agent\u003c/li\u003e\n\u003cli\u003e执行脚本、打开应用、查询信息等\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"-工作流--状态机\"\u003e🧠 工作流 / 状态机\u003c/h2\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode class=\"language-mermaid\" data-lang=\"mermaid\"\u003estateDiagram-v2\n    [*] --\u0026gt; 空闲态\n    空闲态 --\u0026gt; 唤醒态: 语音唤醒\n    唤醒态 --\u0026gt; 处理态: 用户语音结束\n    处理态 --\u0026gt; 空闲态\n    唤醒态 --\u0026gt; 空闲态: 用户长时间无应答\n    空闲态 --\u0026gt; 空闲态: （持续监听）\n\u003c/code\u003e\u003c/pre\u003e\u003cblockquote\u003e\n\u003cp\u003e说明：唤醒后进入实时听写；若检测到\u003cstrong\u003e长时间静音\u003c/strong\u003e则回退到空闲态。\u003c/p\u003e","title":"Windows语音唤醒助手"},{"content":"之前看过很多成功学/心理学众所周知的道理，但是都是空头说话，没有任何数据证明，但这门课，能通过实验的方式展示结果，看到了让我更加信服（科学是最大的迷信hhh）。\n课程纠正了我非常多的偏见，让我对自己有了更清晰的认识，强烈推荐给大家！\n下面是The Science of Well-Being | Coursera的LLM的总结。\n1. 幸福的常见误解 1.1 “知道就够了”（G.I. Joe 谬误） 仅“知道道理”并不会自动改变行为；需要情境与练习把“知道”变“做到”。 1.2 找工作与被拒 被拒的痛苦通常没想的那样强与久，心理免疫系统会缓冲。 1.3 金钱与收入 年轻人的价值观更偏向“高收入为先”。 收入增长与主观幸福并非一一对应；整体幸福感在富足年代并未同步上扬。 超过某一阈值后，收入主要提升“生活评价”，对日常情绪的边际效用有限。 1.4 “酷东西”与物质主义 流行文化强化对豪车、名酒等的向往。 物质主义目标与更低的长期满意度相关。 1.5 真爱与婚姻 婚后幸福感常在几年内回落到基线（适应效应）。 1.6 完美身材/整形与完美成绩 减重或整形未必带来更好的长期心理健康或幸福。 人们普遍高估成绩变化带来的情绪涨落。 幸福并非被基因与环境“写死”，相当比例可由行为与思维方式塑造。 2. 我们为什么总是判断失准 2.1 误想（Miswanting） 对“未来会多喜欢/多讨厌”经常判断错误。 2.2 相对参照点 我们按比较而非绝对值评估自己：同侪收入、媒体/社交媒体的呈现、班级曲线、外貌对比等都会扭曲感受与选择。 2.3 适应力强 对“好事/坏事”都会逐渐习惯：收入提升、中彩票、婚姻等皆会回到常态。 2.4 忽视我们会适应 预测未来情绪时，容易“聚焦于单一事件”并忽略适应与其他生活面向，导致高估负面事件的持续影响。 3. 如何克服偏误（可操作策略） 3.1 重新定义“酷东西”：投资体验而非物质 把钱与精力优先投入能被分享与反复回味的体验（旅行、学习、共创）。 3.2 阻断/延缓适应 品味/回味（savoring）：刻意思考并记录正向时刻。 积极回忆 \u0026amp; 书写消化：写下负面事件并完成认知加工。 负向想象：设想“若没有这件好事会怎样”，提升珍惜度。 时间稀缺：把某些体验当作“最后一次”，增强投入。 感恩练习：数祝福、写感谢信、表达谢意。 重置参照点：有意切换比较标准，校准高/低参照引发的偏差。 打断消费：给愉悦体验加入“短暂停”，延长新鲜感。 4. 真正更有效的幸福来源 4.1 更好的“想要”（Part 1） 优势运用：识别并在工作中高频使用个人优势，提升满足与“天职感”。 心流（Flow）：挑战×能力匹配，带来深度专注与高质量体验。 成长型思维：相信能力可发展，更能从挫折中学习与精进。 4.2 更好的“想要”（Part 2 \u0026amp; 3） 善意与给予：随机善举、为他人花钱、助人使人更幸福（跨文化成立）。 社会连接：重视亲密与日常社交；与陌生人开启对话、共享体验。 时间富足：优先时间而非金钱；思考“我如何用时间与人相处？”。 冥想与正念：降低走神、提升幸福、工作记忆与社会连结感。 健康习惯：规律运动与高质量睡眠，稳定情绪与认知表现。 5. 把策略落地：从“知道”到“做到” 5.1 情境支持（让好行为“更顺手”） 把诱因放远、把好选择放近：远离随手零食，台面摆水果；为运动与阅读预先布置环境。 5.2 目标设定（从愿望到执行） 具体目标：定义清晰的量化标准与截止时间。 实施意图（If–Then）：为关键情境写下触发语句（例：“如果吃完午饭，就散步10分钟”）。 WOOP 技术：愿望（Wish）→成果（Outcome）→障碍（Obstacle）→计划（Plan）。 5.3 速查清单（一周可上手） 每周一次新方式运用你的前五优势；在岗尽量覆盖≥4个优势。 把钱优先用在体验/他人上；为娱乐安排小而频繁的享受并刻意中断。 每日感恩 3 件事＋每周一封感谢讯息。 正念/慈心冥想10–15 分钟，配合每周≥3次运动与固定就寝/起床。 社交优先：与同事/陌生人开启短聊，把体验与人分享。 为关键习惯写 3 条 If–Then，并用 WOOP 复盘障碍与应对。 6. 主要参考 6.1 认知与预测偏误 Santos \u0026amp; Gendler (2014). Knowing is half the battle? Edge. Gilbert \u0026amp; Wilson (2000). Miswanting: Some problems in the forecasting of future affective states. Levine et al. (2012). Accuracy and artifact: Reexamining the intensity bias in affective forecasting. Dunn et al. (2002). Location, location, location. Ayton et al. (2007). Affective forecasting: Why can\u0026rsquo;t people predict their emotions? Gilbert et al. (1998). Immune neglect… Gilbert (2007). Stumbling on Happiness. 6.2 金钱与价值观 Eagan et al. (2015). The American Freshman Survey. LinkedIn Survey (2014). What recent grads care the most about. Diener \u0026amp; Oishi (2000). Money and happiness… Myers (2000). The American Paradox. Lyubomirsky (2007). The How of Happiness. Kahneman \u0026amp; Deaton (2010). High income improves evaluation of life… New York Times. Economic diversity and student outcomes at Yale University. 6.3 参照点与社会比较 Medvec et al. (1995). Olympic medalists \u0026amp; counterfactuals. van Praag \u0026amp; Frijters (1999). Leyden approach. Clark \u0026amp; Oswald (1996). Satisfaction and comparison income. Solnick \u0026amp; Hemenway (1997). Positional concerns. Clark (2003). Unemployment as a social norm. O’Guinn \u0026amp; Shrum (1997). Television \u0026amp; consumer reality. Schor (1999). The Overspent American. Kuhn et al. (2011). Dutch Postcode Lottery. Kenrick et al. (1989; 1993). Attractiveness \u0026amp; comparison. Vogel et al. (2014). Social media \u0026amp; self-esteem. Burleigh \u0026amp; Meegan (2013). Keeping Up with the Joneses \u0026amp; justice. 6.4 适应与物质/体验 Brickman et al. (1978). Lottery winners \u0026amp; accident victims. Di Tella et al. (2010). Adaptation to income \u0026amp; status. Lucas et al. (2003). Adaptation to marriage. Boven \u0026amp; Gilovich (2003). To do or to have? Kumar et al. (2014). Anticipatory consumption of experiential purchases. Pchelin \u0026amp; Howell (2014). Hidden cost of value-seeking. Howell \u0026amp; Hill (2009). Mediators of experiential purchases. Nelson \u0026amp; Meyvis (2008). Interrupted consumption. Nelson et al. (2009). Commercial interruptions \u0026amp; TV. 6.5 优势/心流/心态与善意社交时间 Seligman (2004); Seligman et al. (2005). Signature strengths \u0026amp; interventions. Lavy \u0026amp; Littman-Ovadia (2017); Harzer \u0026amp; Ruch (2012). Strengths at work. Csikszentmihalyi (1992; 2008; 1999). Flow. Deci (1971); Dweck (2007); Grant \u0026amp; Dweck (2003); Blackwell et al. (2007); Mangels et al. (2006). Growth mindset。 Otake et al. (2006); Lyubomirsky (2005); Dunn (2014); Dunn et al. (2008); Aknin et al. (2013). Kindness \u0026amp; prosocial spending. Myers (2000); Diener \u0026amp; Seligman (2002); Epley (2014); Epley \u0026amp; Schroeder (2014); Boothby et al. (2014). Social connection. Whillans et al. (2016); Hershfield et al. (2016); Moligner (2010). Time over money. 6.6 正念、健康与执行 Killingsworth \u0026amp; Gilbert (2010); Mason et al. (2007); Brewer et al. (2011); Fredrickson et al. (2008); Hölzel et al. (2011); Mrazek et al. (2013); Hutcherson et al. (2008). Mind-wandering \u0026amp; meditation. Babyak et al. (2000); Hillman et al. (2008). Exercise \u0026amp; cognition. Dinges et al. (1997); Walker et al. (2002); Wagner et al. (2004); Huffington Post（睡眠图解）. Sleep \u0026amp; performance. Wansink et al. (2006; 2016). Situation support \u0026amp; default choices. Klein et al. (1990); Gollwitzer \u0026amp; Brandstätter (1997); Stadler \u0026amp; Oettingen (2010); Duckworth et al. (2013); Stadler et al. (2009). 目标与实施意图/WOOP。 ","permalink":"http://localhost:1313/posts/the_science_of_well-being_%E6%80%BB%E7%BB%93/","summary":"\u003cp\u003e之前看过很多成功学/心理学众所周知的道理，但是都是空头说话，没有任何数据证明，但这门课，能通过实验的方式展示结果，看到了让我更加信服（科学是最大的迷信hhh）。\u003c/p\u003e\n\u003cp\u003e课程纠正了我非常多的偏见，让我对自己有了更清晰的认识，强烈推荐给大家！\u003c/p\u003e\n\u003cp\u003e下面是\u003ca href=\"https://www.coursera.org/learn/the-science-of-well-being\"\u003eThe Science of Well-Being | Coursera\u003c/a\u003e的LLM的总结。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"1-幸福的常见误解\"\u003e1. 幸福的常见误解\u003c/h2\u003e\n\u003ch3 id=\"11-知道就够了gi-joe-谬误\"\u003e1.1 “知道就够了”（G.I. Joe 谬误）\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e仅“知道道理”并不会自动改变行为；需要情境与练习把“知道”变“做到”。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"12-找工作与被拒\"\u003e1.2 找工作与被拒\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e被拒的痛苦通常没想的那样强与久，心理免疫系统会缓冲。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"13-金钱与收入\"\u003e1.3 金钱与收入\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e年轻人的价值观更偏向“高收入为先”。\u003c/li\u003e\n\u003cli\u003e收入增长与主观幸福并非一一对应；整体幸福感在富足年代并未同步上扬。\u003c/li\u003e\n\u003cli\u003e超过某一阈值后，收入主要提升“生活评价”，对日常情绪的边际效用有限。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"14-酷东西与物质主义\"\u003e1.4 “酷东西”与物质主义\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e流行文化强化对豪车、名酒等的向往。\u003c/li\u003e\n\u003cli\u003e物质主义目标与更低的长期满意度相关。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"15-真爱与婚姻\"\u003e1.5 真爱与婚姻\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e婚后幸福感常在几年内回落到基线（适应效应）。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"16-完美身材整形与完美成绩\"\u003e1.6 完美身材/整形与完美成绩\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e减重或整形未必带来更好的长期心理健康或幸福。\u003c/li\u003e\n\u003cli\u003e人们普遍高估成绩变化带来的情绪涨落。\u003c/li\u003e\n\u003cli\u003e幸福并非被基因与环境“写死”，相当比例可由行为与思维方式塑造。\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"2-我们为什么总是判断失准\"\u003e2. 我们为什么总是判断失准\u003c/h2\u003e\n\u003ch3 id=\"21-误想miswanting\"\u003e2.1 误想（Miswanting）\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e对“未来会多喜欢/多讨厌”经常判断错误。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"22-相对参照点\"\u003e2.2 相对参照点\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e我们按比较而非绝对值评估自己：同侪收入、媒体/社交媒体的呈现、班级曲线、外貌对比等都会扭曲感受与选择。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"23-适应力强\"\u003e2.3 适应力强\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e对“好事/坏事”都会逐渐习惯：收入提升、中彩票、婚姻等皆会回到常态。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"24-忽视我们会适应\"\u003e2.4 忽视我们会适应\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e预测未来情绪时，容易“聚焦于单一事件”并忽略适应与其他生活面向，导致高估负面事件的持续影响。\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"3-如何克服偏误可操作策略\"\u003e3. 如何克服偏误（可操作策略）\u003c/h2\u003e\n\u003ch3 id=\"31-重新定义酷东西投资体验而非物质\"\u003e3.1 重新定义“酷东西”：投资体验而非物质\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e把钱与精力优先投入能被分享与反复回味的体验（旅行、学习、共创）。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"32-阻断延缓适应\"\u003e3.2 阻断/延缓适应\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e品味/回味（savoring）\u003c/strong\u003e：刻意思考并记录正向时刻。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e积极回忆 \u0026amp; 书写消化\u003c/strong\u003e：写下负面事件并完成认知加工。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e负向想象\u003c/strong\u003e：设想“若没有这件好事会怎样”，提升珍惜度。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e时间稀缺\u003c/strong\u003e：把某些体验当作“最后一次”，增强投入。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e感恩练习\u003c/strong\u003e：数祝福、写感谢信、表达谢意。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e重置参照点\u003c/strong\u003e：有意切换比较标准，校准高/低参照引发的偏差。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e打断消费\u003c/strong\u003e：给愉悦体验加入“短暂停”，延长新鲜感。\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"4-真正更有效的幸福来源\"\u003e4. 真正更有效的幸福来源\u003c/h2\u003e\n\u003ch3 id=\"41-更好的想要part-1\"\u003e4.1 更好的“想要”（Part 1）\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e优势运用\u003c/strong\u003e：识别并在工作中高频使用个人优势，提升满足与“天职感”。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e心流（Flow）\u003c/strong\u003e：挑战×能力匹配，带来深度专注与高质量体验。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e成长型思维\u003c/strong\u003e：相信能力可发展，更能从挫折中学习与精进。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"42-更好的想要part-2--3\"\u003e4.2 更好的“想要”（Part 2 \u0026amp; 3）\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e善意与给予\u003c/strong\u003e：随机善举、为他人花钱、助人使人更幸福（跨文化成立）。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e社会连接\u003c/strong\u003e：重视亲密与日常社交；与陌生人开启对话、共享体验。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e时间富足\u003c/strong\u003e：优先时间而非金钱；思考“我如何用时间与人相处？”。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e冥想与正念\u003c/strong\u003e：降低走神、提升幸福、工作记忆与社会连结感。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e健康习惯\u003c/strong\u003e：规律运动与高质量睡眠，稳定情绪与认知表现。\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"5-把策略落地从知道到做到\"\u003e5. 把策略落地：从“知道”到“做到”\u003c/h2\u003e\n\u003ch3 id=\"51-情境支持让好行为更顺手\"\u003e5.1 情境支持（让好行为“更顺手”）\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e把诱因放远、把好选择放近：远离随手零食，台面摆水果；为运动与阅读预先布置环境。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"52-目标设定从愿望到执行\"\u003e5.2 目标设定（从愿望到执行）\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e具体目标\u003c/strong\u003e：定义清晰的量化标准与截止时间。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e实施意图（If–Then）\u003c/strong\u003e：为关键情境写下触发语句（例：“如果吃完午饭，就散步10分钟”）。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eWOOP 技术\u003c/strong\u003e：愿望（Wish）→成果（Outcome）→障碍（Obstacle）→计划（Plan）。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"53-速查清单一周可上手\"\u003e5.3 速查清单（一周可上手）\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e每周\u003cstrong\u003e一次新方式\u003c/strong\u003e运用你的\u003cstrong\u003e前五优势\u003c/strong\u003e；在岗尽量覆盖≥4个优势。\u003c/li\u003e\n\u003cli\u003e把\u003cstrong\u003e钱\u003c/strong\u003e优先用在\u003cstrong\u003e体验/他人\u003c/strong\u003e上；为娱乐安排\u003cstrong\u003e小而频繁\u003c/strong\u003e的享受并\u003cstrong\u003e刻意中断\u003c/strong\u003e。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e每日感恩 3 件事\u003c/strong\u003e＋\u003cstrong\u003e每周一封感谢讯息\u003c/strong\u003e。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e正念/慈心冥想\u003c/strong\u003e10–15 分钟，配合\u003cstrong\u003e每周≥3次运动\u003c/strong\u003e与\u003cstrong\u003e固定就寝/起床\u003c/strong\u003e。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e社交优先\u003c/strong\u003e：与同事/陌生人开启短聊，把体验与人分享。\u003c/li\u003e\n\u003cli\u003e为关键习惯写 3 条 \u003cstrong\u003eIf–Then\u003c/strong\u003e，并用 \u003cstrong\u003eWOOP\u003c/strong\u003e 复盘障碍与应对。\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"6-主要参考\"\u003e6. 主要参考\u003c/h2\u003e\n\u003ch3 id=\"61-认知与预测偏误\"\u003e6.1 认知与预测偏误\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eSantos \u0026amp; Gendler (2014). Knowing is half the battle? Edge.\u003c/li\u003e\n\u003cli\u003eGilbert \u0026amp; Wilson (2000). Miswanting: Some problems in the forecasting of future affective states.\u003c/li\u003e\n\u003cli\u003eLevine et al. (2012). Accuracy and artifact: Reexamining the intensity bias in affective forecasting.\u003c/li\u003e\n\u003cli\u003eDunn et al. (2002). Location, location, location.\u003c/li\u003e\n\u003cli\u003eAyton et al. (2007). Affective forecasting: Why can\u0026rsquo;t people predict their emotions?\u003c/li\u003e\n\u003cli\u003eGilbert et al. (1998). Immune neglect…\u003c/li\u003e\n\u003cli\u003eGilbert (2007). \u003cem\u003eStumbling on Happiness\u003c/em\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"62-金钱与价值观\"\u003e6.2 金钱与价值观\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eEagan et al. (2015). \u003cem\u003eThe American Freshman Survey\u003c/em\u003e.\u003c/li\u003e\n\u003cli\u003eLinkedIn Survey (2014). What recent grads care the most about.\u003c/li\u003e\n\u003cli\u003eDiener \u0026amp; Oishi (2000). Money and happiness…\u003c/li\u003e\n\u003cli\u003eMyers (2000). \u003cem\u003eThe American Paradox\u003c/em\u003e.\u003c/li\u003e\n\u003cli\u003eLyubomirsky (2007). \u003cem\u003eThe How of Happiness\u003c/em\u003e.\u003c/li\u003e\n\u003cli\u003eKahneman \u0026amp; Deaton (2010). High income improves evaluation of life…\u003c/li\u003e\n\u003cli\u003eNew York Times. Economic diversity and student outcomes at Yale University.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"63-参照点与社会比较\"\u003e6.3 参照点与社会比较\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eMedvec et al. (1995). Olympic medalists \u0026amp; counterfactuals.\u003c/li\u003e\n\u003cli\u003evan Praag \u0026amp; Frijters (1999). Leyden approach.\u003c/li\u003e\n\u003cli\u003eClark \u0026amp; Oswald (1996). Satisfaction and comparison income.\u003c/li\u003e\n\u003cli\u003eSolnick \u0026amp; Hemenway (1997). Positional concerns.\u003c/li\u003e\n\u003cli\u003eClark (2003). Unemployment as a social norm.\u003c/li\u003e\n\u003cli\u003eO’Guinn \u0026amp; Shrum (1997). Television \u0026amp; consumer reality.\u003c/li\u003e\n\u003cli\u003eSchor (1999). \u003cem\u003eThe Overspent American\u003c/em\u003e.\u003c/li\u003e\n\u003cli\u003eKuhn et al. (2011). Dutch Postcode Lottery.\u003c/li\u003e\n\u003cli\u003eKenrick et al. (1989; 1993). Attractiveness \u0026amp; comparison.\u003c/li\u003e\n\u003cli\u003eVogel et al. (2014). Social media \u0026amp; self-esteem.\u003c/li\u003e\n\u003cli\u003eBurleigh \u0026amp; Meegan (2013). Keeping Up with the Joneses \u0026amp; justice.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"64-适应与物质体验\"\u003e6.4 适应与物质/体验\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eBrickman et al. (1978). Lottery winners \u0026amp; accident victims.\u003c/li\u003e\n\u003cli\u003eDi Tella et al. (2010). Adaptation to income \u0026amp; status.\u003c/li\u003e\n\u003cli\u003eLucas et al. (2003). Adaptation to marriage.\u003c/li\u003e\n\u003cli\u003eBoven \u0026amp; Gilovich (2003). To do or to have?\u003c/li\u003e\n\u003cli\u003eKumar et al. (2014). Anticipatory consumption of experiential purchases.\u003c/li\u003e\n\u003cli\u003ePchelin \u0026amp; Howell (2014). Hidden cost of value-seeking.\u003c/li\u003e\n\u003cli\u003eHowell \u0026amp; Hill (2009). Mediators of experiential purchases.\u003c/li\u003e\n\u003cli\u003eNelson \u0026amp; Meyvis (2008). Interrupted consumption.\u003c/li\u003e\n\u003cli\u003eNelson et al. (2009). Commercial interruptions \u0026amp; TV.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"65-优势心流心态与善意社交时间\"\u003e6.5 优势/心流/心态与善意社交时间\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eSeligman (2004); Seligman et al. (2005). Signature strengths \u0026amp; interventions.\u003c/li\u003e\n\u003cli\u003eLavy \u0026amp; Littman-Ovadia (2017); Harzer \u0026amp; Ruch (2012). Strengths at work.\u003c/li\u003e\n\u003cli\u003eCsikszentmihalyi (1992; 2008; 1999). Flow.\u003c/li\u003e\n\u003cli\u003eDeci (1971); Dweck (2007); Grant \u0026amp; Dweck (2003); Blackwell et al. (2007); Mangels et al. (2006). Growth mindset。\u003c/li\u003e\n\u003cli\u003eOtake et al. (2006); Lyubomirsky (2005); Dunn (2014); Dunn et al. (2008); Aknin et al. (2013). Kindness \u0026amp; prosocial spending.\u003c/li\u003e\n\u003cli\u003eMyers (2000); Diener \u0026amp; Seligman (2002); Epley (2014); Epley \u0026amp; Schroeder (2014); Boothby et al. (2014). Social connection.\u003c/li\u003e\n\u003cli\u003eWhillans et al. (2016); Hershfield et al. (2016); Moligner (2010). Time over money.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"66-正念健康与执行\"\u003e6.6 正念、健康与执行\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eKillingsworth \u0026amp; Gilbert (2010); Mason et al. (2007); Brewer et al. (2011); Fredrickson et al. (2008); Hölzel et al. (2011); Mrazek et al. (2013); Hutcherson et al. (2008). Mind-wandering \u0026amp; meditation.\u003c/li\u003e\n\u003cli\u003eBabyak et al. (2000); Hillman et al. (2008). Exercise \u0026amp; cognition.\u003c/li\u003e\n\u003cli\u003eDinges et al. (1997); Walker et al. (2002); Wagner et al. (2004); \u003cem\u003eHuffington Post\u003c/em\u003e（睡眠图解）. Sleep \u0026amp; performance.\u003c/li\u003e\n\u003cli\u003eWansink et al. (2006; 2016). Situation support \u0026amp; default choices.\u003c/li\u003e\n\u003cli\u003eKlein et al. (1990); Gollwitzer \u0026amp; Brandstätter (1997); Stadler \u0026amp; Oettingen (2010); Duckworth et al. (2013); Stadler et al. (2009). 目标与实施意图/WOOP。\u003c/li\u003e\n\u003c/ul\u003e","title":"耶鲁大学幸福科学课程总结"},{"content":"最近都在广泛学习一些有趣的内容，主要是通过coursera平台。在家呆了2个多月了，也不知道未来啥方向，目前也是有些迷茫的状态，还是学些东西充实下自己吧，搜寻一下感兴趣的东东。\ncoursera平台类似于国外的mooc，国内外还有好多这样的平台，如中国大学mooc、bilibili大学、网易云课等等。coursera需要付费会员才能观看课程，而且只能通过国外信用卡付款（无）。于是，我在淘宝一搜，这么多卖号，而且很便宜，86半年，立马充值了一波。\n有了平台，我立马重新在coursera里，拾起深度学习的基础知识，吴恩达的课程。之前只听过，在coursera认真地观看，还是感觉受益匪浅，毕竟有作业有互动，感觉b站还是差点味道。\n现在主要看了深度学习专项课程的前3个：\n其实就相当于复习了一下之前在李沐动手学深度学习的内容。\n然后光看深度学习也有些乏味，我在网上搜索coursera有没有其他好课程，打开了一个课程排名，类似于垃圾小网站的那种：\n然后最近在看幸福科学，才刚开始看，讲的是如何变得幸福，通过科学的方式，感觉讲的还挺好的，在实验的加持下，科学成为人们可以坚持最大的迷信，hhh，但是还是要有反驳精神，感觉很多科学实验严谨性还是有些欠缺。\n之后的日子，想了解一下金融相关的知识，挺感兴趣的。马上要开学了，5555，希望能保持学习一些课外内容的习惯。还有，运动也要保持，在家和爸妈打了一个暑假的乒乓球，每日锻炼~\n","permalink":"http://localhost:1313/posts/%E6%9C%80%E8%BF%91%E5%9C%A8%E5%81%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E4%BA%8B/","summary":"\u003cp\u003e最近都在广泛学习一些有趣的内容，主要是通过coursera平台。在家呆了2个多月了，也不知道未来啥方向，目前也是有些迷茫的状态，还是学些东西充实下自己吧，搜寻一下感兴趣的东东。\u003c/p\u003e\n\u003cp\u003ecoursera平台类似于国外的mooc，国内外还有好多这样的平台，如中国大学mooc、bilibili大学、网易云课等等。coursera需要付费会员才能观看课程，而且只能通过国外信用卡付款（无）。于是，我在淘宝一搜，这么多卖号，而且很便宜，86半年，立马充值了一波。\u003c/p\u003e\n\u003cp\u003e有了平台，我立马重新在coursera里，拾起深度学习的基础知识，吴恩达的课程。之前只听过，在coursera认真地观看，还是感觉受益匪浅，毕竟有作业有互动，感觉b站还是差点味道。\u003c/p\u003e\n\u003cp\u003e现在主要看了深度学习专项课程的前3个：\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"233\" loading=\"lazy\" src=\"/posts/%E6%9C%80%E8%BF%91%E5%9C%A8%E5%81%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E4%BA%8B/image-20250825155253827.png\"\u003e\u003c/p\u003e\n\u003cp\u003e其实就相当于复习了一下之前在李沐动手学深度学习的内容。\u003c/p\u003e\n\u003cp\u003e然后光看深度学习也有些乏味，我在网上搜索coursera有没有其他好课程，打开了一个课程排名，类似于垃圾小网站的那种：\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"2333\" loading=\"lazy\" src=\"/posts/%E6%9C%80%E8%BF%91%E5%9C%A8%E5%81%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E4%BA%8B/image-20250825155452140.png\"\u003e\u003c/p\u003e\n\u003cp\u003e然后最近在看幸福科学，才刚开始看，讲的是如何变得幸福，通过科学的方式，感觉讲的还挺好的，在实验的加持下，科学成为人们可以坚持最大的迷信，hhh，但是还是要有反驳精神，感觉很多科学实验严谨性还是有些欠缺。\u003c/p\u003e\n\u003cp\u003e之后的日子，想了解一下金融相关的知识，挺感兴趣的。马上要开学了，5555，希望能保持学习一些课外内容的习惯。还有，运动也要保持，在家和爸妈打了一个暑假的乒乓球，每日锻炼~\u003c/p\u003e","title":"最近在做的一些事"},{"content":"softmax是一个经典的多分类概率分布的公式，有n个类，softmax公式如下， $$ \\text{softmax}(z)_j = \\frac{e^{z_j}}{\\sum_{i=1}^n e^{z_i}}, \\quad j = 1, 2, \\dots, n $$ 首先，考虑一个样本每个类的预测分数做一个softmax，转换成每类预测的概率形式。\n$$ a^{[L]} = \\text{softmax}(z^{[L]}) $$$$ \\hat{y} = a^{[L]}\\quad $$然后，利用样本标签，结合极大似然估计的损失函数如下。 $$ L(\\hat{y}, y) = - \\sum_{i=1}^{n} y_i \\log(\\hat{y}_i) $$由于需要做反向传播，我们想求 $\\frac{\\partial L}{\\partial z^{[L]}}$，也就是做完softmax的前的偏导数。\n假设 $y$ 的分类为 $1$，则 $y_1 = 1$，其余 $y_j = 0\\ (j\\neq 1)$，$y=[1,0,.....,0]$ 则有， $$ L(\\hat{y}, y) = -\\log(\\hat{y}_1) $$$$ L(\\hat{y}, y) = - \\ln \\left( \\frac{e^{z_1^{[L]}}}{e^{z_1^{[L]}} + e^{z_2^{[L]}} + \\cdots + e^{z_n^{[L]}}} \\right), \\quad S = e^{z_1^{[L]}} + e^{z_2^{[L]}} + \\cdots + e^{z_n^{[L]}} $$接下来求 $Z^{[L]}$ 的偏导， $$ \\frac{\\partial L}{\\partial z^{[L]}_1} = -\\frac{S}{e^{z^{[L]}_1}} \\cdot \\frac{e^{z^{[L]}_1} \\cdot S - \\big(e^{z^{[L]}_1}\\big)^2}{S^2} = \\frac{e^{z^{[L]}_1}}{S} - 1 $$$$ \\frac{\\partial L}{\\partial z^{[L]}_j} = - \\frac{S}{e^{z^{[L]}_1}} \\cdot \\frac{-e^{z^{[L]}_1} \\cdot e^{z^{[L]}_j}}{S^2} = \\frac{e^{z^{[L]}_j}}{S}, \\quad j \\neq 1 $$因为， $$ a_j^{[L]} = \\frac{e^{z_j^{[L]}}}{S}, $$ 所以， $$ \\frac{\\partial L}{\\partial z^{[L]}_1} = a_1^{[L]} - 1 $$$$ \\frac{\\partial L}{\\partial z^{[L]}_j} = a_j^{[L]}, \\quad (j \\neq 1) $$由于不同分类标签的对称性，从而得到最终化简结果， $$ \\frac{\\partial L}{\\partial z^{[L]}} = \\hat{y} - y $$ 对于多样本，每个样本间独立，则有， $$ \\frac{\\partial L}{\\partial Z^{[L]}} = \\hat{Y} - Y $$","permalink":"http://localhost:1313/posts/softmax%E7%9A%84%E5%AF%BC%E6%95%B0%E6%8E%A8%E5%AF%BC/","summary":"\u003cp\u003esoftmax是一个经典的多分类概率分布的公式，有n个类，softmax公式如下，\n\u003c/p\u003e\n$$\n\\text{softmax}(z)_j = \\frac{e^{z_j}}{\\sum_{i=1}^n  e^{z_i}}, \\quad j = 1, 2, \\dots, n\n$$\u003cp\u003e\n首先，考虑一个样本每个类的预测分数做一个softmax，转换成每类预测的概率形式。\u003c/p\u003e\n$$\na^{[L]} = \\text{softmax}(z^{[L]})\n$$$$\n\\hat{y} = a^{[L]}\\quad\n$$\u003cp\u003e然后，利用样本标签，结合极大似然估计的损失函数如下。\n\u003c/p\u003e\n$$\nL(\\hat{y}, y) = - \\sum_{i=1}^{n} y_i \\log(\\hat{y}_i)\n$$\u003cp\u003e由于需要做反向传播，我们想求 $\\frac{\\partial L}{\\partial z^{[L]}}$，也就是做完softmax的前的偏导数。\u003c/p\u003e\n\u003cp\u003e假设 $y$ 的分类为 $1$，则 $y_1 = 1$，其余 $y_j = 0\\ (j\\neq 1)$，$y=[1,0,.....,0]$\n则有，\n\u003c/p\u003e\n$$\nL(\\hat{y}, y) = -\\log(\\hat{y}_1)\n$$$$\nL(\\hat{y}, y) = - \\ln \\left( \\frac{e^{z_1^{[L]}}}{e^{z_1^{[L]}} + e^{z_2^{[L]}} + \\cdots + e^{z_n^{[L]}}} \\right),\n\\quad S = e^{z_1^{[L]}} + e^{z_2^{[L]}} + \\cdots + e^{z_n^{[L]}}\n$$\u003cp\u003e接下来求 $Z^{[L]}$ 的偏导，\n\u003c/p\u003e","title":"Softmax的反向传播推导"},{"content":"\n最近在重新回顾深度学习相关基础，之前大概过了一遍李沐的动手学深度学习，但很多内容还一知半解， 感觉网上课程难度曲线还是不太平滑。\n无意间看到 Coursera平台，在淘宝上花了80买了个半年号，仿佛打开新世界了，第一次看到了原来真的有课程能把深度学习的学习曲线 弄的这么平滑的，爱了，有点像算法竞赛的acwing、牛客。感觉b站确实不错，但是反馈和互动肯定远远比不上Coursera的。\n现在刚学完第一门课程，并手动设计并实现了多层卷积神经网络（只用到numpy），在这里记录一下forward/back propagation的数学知识（主要是线性代数）。\n正向传播 非常简单易懂，就是矩阵乘法。\n反向传播 引理一 搞懂这个引理反向传播就差不多弄懂了，求哪个偏导，固定某行/列值算贡献 就好求了（A固定行，B固定列），因为矩阵乘法是B的列与A的行做点积。\n以上就是神经网络里的线性代数的一些知识，其实不需要太多基础弄得矩阵乘法，和求导链式法则即可手写神经网络。\n","permalink":"http://localhost:1313/posts/%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC/","summary":"\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC/2.png\"\u003e\u003c/p\u003e\n\u003cp\u003e最近在重新回顾深度学习相关基础，之前大概过了一遍李沐的动手学深度学习，但很多内容还一知半解，\n感觉网上课程难度曲线还是不太平滑。\u003c/p\u003e\n\u003cp\u003e无意间看到 \u003ca href=\"https://www.coursera.org/\"\u003eCoursera平台\u003c/a\u003e，在淘宝上花了80买了个半年号，仿佛打开新世界了，第一次看到了原来真的有课程能把深度学习的学习曲线\n弄的这么平滑的，爱了，有点像算法竞赛的acwing、牛客。感觉b站确实不错，但是反馈和互动肯定远远比不上Coursera的。\u003c/p\u003e\n\u003cp\u003e现在刚学完第一门课程，并手动设计并实现了多层卷积神经网络（只用到numpy），在这里记录一下forward/back propagation的数学知识（主要是线性代数）。\u003c/p\u003e\n\u003ch4 id=\"正向传播\"\u003e正向传播\u003c/h4\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC/%281%29.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003e非常简单易懂，就是矩阵乘法。\u003c/p\u003e\n\u003ch4 id=\"反向传播\"\u003e反向传播\u003c/h4\u003e\n\u003ch5 id=\"引理一\"\u003e引理一\u003c/h5\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC/%282%29.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC/%283%29.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003e搞懂这个引理反向传播就差不多弄懂了，求哪个偏导，固定某行/列值算贡献 就好求了（A固定行，B固定列），因为矩阵乘法是B的列与A的行做点积。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC/%284%29.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003e以上就是神经网络里的线性代数的一些知识，其实不需要太多基础弄得矩阵乘法，和求导链式法则即可手写神经网络。\u003c/p\u003e","title":"神经网络反向传播 数学推导"},{"content":"工具介绍 Hugo 简介：Hugo 是一个用 Go 语言编写的静态网站生成器。它以极快的生成速度著称，可以在几秒内构建上千页面。\n特点：\n不依赖数据库，所有页面都是静态文件，部署简单且性能高。 支持 Markdown 写作，适合博客和文档站点。 拥有强大的模板系统和主题生态。 跨平台运行（Windows、Linux、macOS）。 PaperMod 简介：PaperMod 是 Hugo 社区里非常流行的一个 简洁、现代的主题，灵感来自 Google Material Design。\n特点：\n设计简洁清爽，注重阅读体验。 自带夜间模式、搜索、标签分类等功能。 对 SEO 和性能友好，开箱即用。 支持高度自定义，比如文章目录、社交链接、评论系统等。 👉 总结：Hugo 是建站工具，PaperMod 是在 Hugo 上常用的主题之一。\nStep 1 按照下面视频安装hugo+papermod，搭建demo\n【雷】Hugo + Github免费搭建博客，并实现自动化部署\nStep 2 配置papermod主题，结合大语言模型，想要什么功能直接询问即可，并修改配置文件，主题大部分都是配有相关功能的。\n","permalink":"http://localhost:1313/posts/hugo+paermod%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%95%99%E7%A8%8B/","summary":"\u003ch3 id=\"工具介绍\"\u003e工具介绍\u003c/h3\u003e\n\u003ch4 id=\"hugo\"\u003eHugo\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e简介\u003c/strong\u003e：Hugo 是一个用 Go 语言编写的\u003cstrong\u003e静态网站生成器\u003c/strong\u003e。它以极快的生成速度著称，可以在几秒内构建上千页面。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e特点\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e不依赖数据库，所有页面都是静态文件，部署简单且性能高。\u003c/li\u003e\n\u003cli\u003e支持 Markdown 写作，适合博客和文档站点。\u003c/li\u003e\n\u003cli\u003e拥有强大的模板系统和主题生态。\u003c/li\u003e\n\u003cli\u003e跨平台运行（Windows、Linux、macOS）。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"papermod\"\u003ePaperMod\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e简介\u003c/strong\u003e：PaperMod 是 Hugo 社区里非常流行的一个 \u003cstrong\u003e简洁、现代的主题\u003c/strong\u003e，灵感来自 Google Material Design。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e特点\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e设计简洁清爽，注重阅读体验。\u003c/li\u003e\n\u003cli\u003e自带夜间模式、搜索、标签分类等功能。\u003c/li\u003e\n\u003cli\u003e对 SEO 和性能友好，开箱即用。\u003c/li\u003e\n\u003cli\u003e支持高度自定义，比如文章目录、社交链接、评论系统等。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e👉 总结：\u003cstrong\u003eHugo\u003c/strong\u003e 是建站工具，\u003cstrong\u003ePaperMod\u003c/strong\u003e 是在 Hugo 上常用的主题之一。\u003c/p\u003e\n\u003ch3 id=\"step-1\"\u003eStep 1\u003c/h3\u003e\n\u003cp\u003e按照下面视频安装hugo+papermod，搭建demo\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://www.bilibili.com/video/BV1bovfeaEtQ?vd_source=89574dec834a4f547f86ccea8df6514e\"\u003e【雷】Hugo + Github免费搭建博客，并实现自动化部署\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id=\"step-2\"\u003eStep 2\u003c/h3\u003e\n\u003cp\u003e配置papermod主题，结合大语言模型，想要什么功能直接询问即可，并修改配置文件，主题大部分都是配有相关功能的。\u003c/p\u003e","title":"hugo+papermod博客搭建教程"},{"content":"你好，我是 wanghai673，一名正在攻读 计算机科学与技术 的研究生（研 0），本科毕业于东华大学，目前就读于华东师范大学。\n💻 编程语言：C++、Python、Java\n🔍 研究兴趣：深度学习、大语言模型、智能体\n🏆 竞赛经历：\nICPC 亚洲区域赛 金奖（第 49 届） 蓝桥杯全国总决赛 一等奖（全国第 6 名） 百度之星全国总决赛 金奖 多次 ICPC/CCPC 银奖 上海市大学生程序设计竞赛 一等奖 我正在不断学习和提升自己，期待将所学应用于实际问题。如果有相关的 实习机会 或者 研究合作，非常欢迎联系我。\n📫 联系方式：微信、邮件\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e你好，我是 \u003cstrong\u003ewanghai673\u003c/strong\u003e，一名正在攻读 \u003cstrong\u003e计算机科学与技术\u003c/strong\u003e 的研究生（研 0），本科毕业于东华大学，目前就读于华东师范大学。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e💻 编程语言：C++、Python、Java\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e🔍 研究兴趣：深度学习、大语言模型、智能体\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e🏆 竞赛经历：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eICPC 亚洲区域赛 \u003cstrong\u003e金奖（第 49 届）\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e蓝桥杯全国总决赛 \u003cstrong\u003e一等奖（全国第 6 名）\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e百度之星全国总决赛 \u003cstrong\u003e金奖\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e多次 ICPC/CCPC \u003cstrong\u003e银奖\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e上海市大学生程序设计竞赛 \u003cstrong\u003e一等奖\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e我正在不断学习和提升自己，期待将所学应用于实际问题。如果有相关的 \u003cstrong\u003e实习机会\u003c/strong\u003e 或者 \u003cstrong\u003e研究合作\u003c/strong\u003e，非常欢迎联系我。\u003c/p\u003e\n\u003cp\u003e📫 联系方式：\u003ca href=\"wechat.jpg\"\u003e微信\u003c/a\u003e、\u003ca href=\"https://mail.qq.com/cgi-bin/qm_share?t=qm_mailme\u0026amp;email=1154103986@qq.com\"\u003e邮件\u003c/a\u003e\u003c/p\u003e","title":"关于"},{"content":"EduAgent: Generative Student Agents in Learning 总结\n本文是针对线上教育领域的学生模仿相关的研究，之前的模型多利用庞大的数据对学生学习行为进行预测，随着LLM的问世，LLM提供的前置知识能很好的针对不同场景不同内容线上教育的学生行为预测。\n学生行为预测受到多方面的影响，如性格、学生储备知识等，本文提供了一个数据集（350个sample），针对一段5分钟的幻灯片讲解，提供学生个人信息和每个小时间段的学生注意窗口、行为、认知状态信息等。\n作者结合LLM强大的推理功能，让LLM自主推理出不同信息间的关联，从而实现学生行为的预测和模仿，但这篇论文的实验没咋看懂\u0026hellip;\nLLM-mediated domain-specific voice agents: the case of TextileBot 总结\n粗粒度地看了下\u0026hellip;\n只看了摘要和引言和结论，讲的是如何原型化地设计一个垂直领域的对话agent，包含prompt模板，随后作者自己设计了一个宣传服装环保领域的一个agent（在购物的时候跟顾客交流的），并做了用户实验。\nWhy language models hallucinate 总结\nWhy language models hallucinate | OpenAI\nOpenAI 9月5号刚发布的文章，主要讲述了为什么大语言模型会产生幻觉。\n作者描述，LLM（大语言模型）之所以产生幻觉，是因为现在对模型后训练的奖励函数，往往将答错一道题和拒答一道题（承认不知道）的惩罚都是一致的，导致LLM更倾向于去猜题，这样还有概率猜对。\n那有人就会说了，让答错的惩罚提升一些不就行了。确实可以，但是作者回应到现如今大多数的benchmark，只有对/错两个选项，并没有考虑到幻觉的因素，从而导致大家更宁愿LLM猜题，增加一些benchmark的准确率，而不是拒答（大幅度降低幻觉，但准确率会略微降低）。\n作者呼吁所有benchmark的制作者们，将幻觉这个评价指标加入到benchmark的评测之中，从而抑制LLM的胡言乱语。但现在的benchmark对幻觉的评判往往是特定的一类，大多数benmark没有考虑幻觉因素。\n上面都是通过后训练降低LLM幻觉的途径，那能不能在预训练的时候降低大语言模型的幻觉呢？作者回答，现在的数据都是无监督的，导致LLM并没有办法对每段数据的真实性做判断，更好的办法还是在后训练的时候减少大模型的幻觉。\n下图是原文的提出的LLM幻觉的一些误解与澄清：\n","permalink":"http://localhost:1313/posts/9.6_%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/","summary":"\u003ch3 id=\"eduagent-generative-student-agents-in-learning\"\u003eEduAgent: Generative Student Agents in Learning\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e总结\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e本文是针对线上教育领域的学生模仿相关的研究，之前的模型多利用庞大的数据对学生学习行为进行预测，随着LLM的问世，LLM提供的前置知识能很好的针对不同场景不同内容线上教育的学生行为预测。\u003c/p\u003e\n\u003cp\u003e学生行为预测受到多方面的影响，如性格、学生储备知识等，本文提供了一个数据集（350个sample），针对一段5分钟的幻灯片讲解，提供学生个人信息和每个小时间段的学生注意窗口、行为、认知状态信息等。\u003c/p\u003e\n\u003cp\u003e作者结合LLM强大的推理功能，让LLM自主推理出不同信息间的关联，从而实现学生行为的预测和模仿，但这篇论文的实验没咋看懂\u0026hellip;\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"llm-mediated-domain-specific-voice-agents-the-case-of-textilebot\"\u003eLLM-mediated domain-specific voice agents: the case of TextileBot\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e总结\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e粗粒度地看了下\u0026hellip;\u003c/p\u003e\n\u003cp\u003e只看了摘要和引言和结论，讲的是如何原型化地设计一个垂直领域的对话agent，包含prompt模板，随后作者自己设计了一个宣传服装环保领域的一个agent（在购物的时候跟顾客交流的），并做了用户实验。\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"why-language-models-hallucinate\"\u003eWhy language models hallucinate\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e总结\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://openai.com/index/why-language-models-hallucinate/\"\u003eWhy language models hallucinate | OpenAI\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eOpenAI 9月5号刚发布的文章，主要讲述了为什么大语言模型会产生幻觉。\u003c/p\u003e\n\u003cp\u003e作者描述，LLM（大语言模型）之所以产生幻觉，是因为现在对模型后训练的奖励函数，往往将答错一道题和拒答一道题（承认不知道）的惩罚都是一致的，导致LLM更倾向于去猜题，这样还有概率猜对。\u003c/p\u003e\n\u003cp\u003e那有人就会说了，让答错的惩罚提升一些不就行了。确实可以，但是作者回应到现如今大多数的benchmark，只有对/错两个选项，并没有考虑到幻觉的因素，从而导致大家更宁愿LLM猜题，增加一些benchmark的准确率，而不是拒答（大幅度降低幻觉，但准确率会略微降低）。\u003c/p\u003e\n\u003cp\u003e作者呼吁所有benchmark的制作者们，将幻觉这个评价指标加入到benchmark的评测之中，从而抑制LLM的胡言乱语。但现在的benchmark对幻觉的评判往往是特定的一类，大多数benmark没有考虑幻觉因素。\u003c/p\u003e\n\u003cp\u003e上面都是通过后训练降低LLM幻觉的途径，那能不能在预训练的时候降低大语言模型的幻觉呢？作者回答，现在的数据都是无监督的，导致LLM并没有办法对每段数据的真实性做判断，更好的办法还是在后训练的时候减少大模型的幻觉。\u003c/p\u003e\n\u003cp\u003e下图是原文的提出的LLM幻觉的一些误解与澄清：\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250906164329093\" loading=\"lazy\" src=\"c:\\\\Users\\\\11541\\\\AppData\\\\Roaming\\\\Typora\\\\typora-user-images\\\\image-20250906164329093.png\"\u003e\u003c/p\u003e","title":"9.6 论文阅读"},{"content":"LLM Agents for Education: Advances and Applications 总结\n这是一篇综述论文，讲述了现在LLM agents在领域的各种运用。作者将教育agent分为 教学agent 和 垂直领域agent。\n教学agent又分为面向学生和面向教师的，垂直领域的分为很多不同学科类的agent，不同学科agent也有不同的功能的agent，整体分类思维导图见下图。\n然后作者讲述了，现有教育agent所面临的困难，如道德、偏见方面的，也有幻觉、可靠性方面的。现有的agent大多数不具备结构化的形式（更多是对话类型），无法直接在现实教育场景中插入。\n最后整理介绍了现有测评教育agent各种benchmark，以供后来研究者使用。\nMATHAGENT: Leveraging a Mixture-of-Math-Agent Framework for Real-World Multimodal Mathematical Error Detection 背景\n大语言模型在数学问题求解中已经非常厉害了，但是在数学错误发现上还很少涉足。传统的数学老师批改，耗时耗力，并且不具备可扩展性，如无法为学生指明学生具体错误（人工成本高），多模态大模型可以识别图片，并且为学生提供错误位置和错误分类，但是MLLM还在存在较多错误，对于有细微错误的地方无法很好识别。并且现在研究多聚焦纯文本数学题改错，对于带有图片信息的不能很好应对。\n方法\n数据集合为下图，有文本问题描述，图片类信息，正确答案，学生的不正确答案，解题步骤。 任务分为 1：找到第一个错误步骤，2：错误分类，指标都是准确率。\n作者引入了个多智能体框架，分为三个部分，流程如下图。\n文本-图像一致性检测：判断图片和文字是否高度一致，避免使用图片识别功能，从而增强题目解读能力 公式-表格识别：用专门model将各种公式、表格等识别为文本形式 融合找错：将文本和转文本的图片信息融合为一个完整题目，并且让LLM完成上面具体两个任务 实验结果\n将该方法运用到多个多模态大模型，大部分都能提升准确率，但相较于人工还有很大的差距。 论文写的浅显易懂，结构也很清晰，可惜本论文并未公布数据集。。。\n","permalink":"http://localhost:1313/posts/9%E6%9C%885%E6%97%A5%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/","summary":"\u003ch3 id=\"llm-agents-for-education-advances-and-applications\"\u003eLLM Agents for Education: Advances and Applications\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e总结\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e这是一篇综述论文，讲述了现在LLM agents在领域的各种运用。作者将教育agent分为 教学agent 和 垂直领域agent。\u003c/p\u003e\n\u003cp\u003e教学agent又分为面向学生和面向教师的，垂直领域的分为很多不同学科类的agent，不同学科agent也有不同的功能的agent，整体分类思维导图见下图。\u003c/p\u003e\n\u003cp\u003e然后作者讲述了，现有教育agent所面临的困难，如道德、偏见方面的，也有幻觉、可靠性方面的。现有的agent大多数不具备结构化的形式（更多是对话类型），无法直接在现实教育场景中插入。\u003c/p\u003e\n\u003cp\u003e最后整理介绍了现有测评教育agent各种benchmark，以供后来研究者使用。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250905134524279\" loading=\"lazy\" src=\"/posts/9%E6%9C%885%E6%97%A5%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/image-20250905134524279.png\"\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"mathagent-leveraging-a-mixture-of-math-agent-framework-for-real-world-multimodal-mathematical-error-detection\"\u003eMATHAGENT: Leveraging a Mixture-of-Math-Agent Framework for Real-World Multimodal Mathematical Error Detection\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e背景\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e大语言模型在数学问题求解中已经非常厉害了，但是在数学错误发现上还很少涉足。传统的数学老师批改，耗时耗力，并且不具备可扩展性，如无法为学生指明学生具体错误（人工成本高），多模态大模型可以识别图片，并且为学生提供错误位置和错误分类，但是MLLM还在存在较多错误，对于有细微错误的地方无法很好识别。并且现在研究多聚焦纯文本数学题改错，对于带有图片信息的不能很好应对。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e方法\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e数据集合为下图，有文本问题描述，图片类信息，正确答案，学生的不正确答案，解题步骤。\n任务分为  1：找到第一个错误步骤，2：错误分类，指标都是准确率。\u003c/p\u003e\n\u003cimg src=\"image-20250905153558820.png\" alt=\"image-20250905153558820\" style=\"zoom:67%;\" /\u003e\n\u003cp\u003e作者引入了个多智能体框架，分为三个部分，流程如下图。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e文本-图像一致性检测：判断图片和文字是否高度一致，避免使用图片识别功能，从而增强题目解读能力\u003c/li\u003e\n\u003cli\u003e公式-表格识别：用专门model将各种公式、表格等识别为文本形式\u003c/li\u003e\n\u003cli\u003e融合找错：将文本和转文本的图片信息融合为一个完整题目，并且让LLM完成上面具体两个任务\u003cimg src=\"image-20250905153953903.png\" alt=\"image-20250905153953903\" style=\"zoom:67%;\" /\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e实验结果\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e将该方法运用到多个多模态大模型，大部分都能提升准确率，但相较于人工还有很大的差距。\n\u003cimg alt=\"image-20250905154103167\" loading=\"lazy\" src=\"/posts/9%E6%9C%885%E6%97%A5%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/image-20250905154103167.png\"\u003e\u003c/p\u003e\n\u003cp\u003e论文写的浅显易懂，结构也很清晰，可惜本论文并未公布数据集。。。\u003c/p\u003e","title":"9.5 论文阅读"},{"content":"最近闲着无聊随便做了一个windows的语音唤醒助手，主要是闲平常要出门，或者不方便的时候（比如运动、躺床上的时候），可以叫一声电脑就做我想让他做的内容（可以连接LLM/GUI agent/MCP等等）。\n再加上现在GUIAgent发展的很快，网上还没有语音唤醒形式的链接，也就自己搭了一个出来。\n下面是这个项目的readme。\nWinAssistant – Windows 本地语音唤醒与自动化执行 一个在 Windows 上运行的本地语音助手：\n说出唤醒词 → 识别你的语音 → 自动执行自定义动作（脚本、GUI Agent、MCP 等）。 全离线（唤醒+识别均可离线），即插即用，优先使用耳机麦克风。 演示视频 https://github.com/user-attachments/assets/a48b8e94-8b95-46eb-9aa5-a4085c2341c4\n✨ 核心特性 多唤醒词可选 / 可自定义 内置多种常见唤醒词，也可替换为你训练的 .ppn 文件。\n本地唤醒：Picovoice Porcupine 轻量、低延迟、可靠，离线运行。\n语音识别：fast-whisper 内置去噪、VAD 端点检测，自动判断“用户是否说完”，可按需调节模型大小（速度/准确度权衡）。\n自动音频设备选择 自动选择可用的输入/输出设备，优先耳机。\n可插拔“处理态” 识别到文本后进入你的“处理态”（可自定义），例如：\n调用 MCP / 工具调用 触发 GUI Agent 执行脚本、打开应用、查询信息等 🧠 工作流 / 状态机 stateDiagram-v2 [*] --\u0026gt; 空闲态 空闲态 --\u0026gt; 唤醒态: 语音唤醒 唤醒态 --\u0026gt; 处理态: 用户语音结束 处理态 --\u0026gt; 空闲态 唤醒态 --\u0026gt; 空闲态: 用户长时间无应答 空闲态 --\u0026gt; 空闲态: （持续监听） 说明：唤醒后进入实时听写；若检测到长时间静音则回退到空闲态。\n📦 目录结构 WINASSISTANT/ ├─ model/ │ ├─ 小智.ppn # 自定义/内置唤醒词（Porcupine） │ └─ porcupine_params_zh.pv # 中文参数 ├─ music/ # 系统提示音 │ ├─ ok.wav │ ├─ sorry.wav │ └─ zai.wav ├─ utils/ │ ├─ player.py # 播放器：播放提示音/反馈 │ ├─ reader.py # 识别器：fast-whisper + VAD │ ├─ rouser.py # 唤醒：Porcupine 推理 │ └─ UIoperator.py # 处理态模板（可自定义） ├─ .env # 环境变量（见下） ├─ main.py # 入口：python main.py └─ requirements.txt # 依赖 🚀 快速开始 1) 环境准备 Windows 10/11 Python 3.9+（建议 64-bit） 麦克风 \u0026amp; 扬声器/耳机 git clone https://github.com/wanghai673/WinAssistant cd WINASSISTANT # 建议：创建虚拟环境 python -m venv .venv .\\.venv\\Scripts\\activate pip install -r requirements.txt 2) 申请 Picovoice Access Key 前往 https://picovoice.ai/ 免费获取 ACCESS_KEY。\n3) 配置 .env 在项目根目录创建或修改 .env：\nACCESS_KEY=你的AccessKey # 唤醒词（可选：小智, hey google, grasshopper, computer, americano, # bumblebee, hey barista, ok google, pico clock, porcupine, # picovoice, jarvis, terminator, grapefruit, blueberry, alexa, hey siri） ROUSE_WORD=小智 想用自定义唤醒词？把训练好的 .ppn 文件放到 model/ 并在代码/ENV 中指向它即可。\n4) 运行 python main.py 说出唤醒词（默认 “小智”）→ 说出命令 → 听到提示音并执行。\n🧩 自定义“处理态” 识别结果会进入你的“处理态”模块（示例：utils/UIoperator.py）。 你可以在这里：\n串接 MCP 工具调用 通过 GUI Agent 操作桌面 执行脚本 / 打开应用 / 系统自动化 回放 music/ok.wav / sorry.wav 作为反馈 建议将业务逻辑与语音管线解耦：保留 player / reader / rouser 作为通用能力层，处理态专注于“要做什么”。\n⚙️ 常用调优点 VAD/静音阈值：在 reader.py 中调整 MAX_SILENCE_SECS 等参数，影响“说完就停”的敏感度。 模型大小：根据机器性能切换 fast-whisper 模型（小模型更快，大模型更准）。 提示音屏蔽：通过 realtime_zh(..., beep_guard=0.5) 吞掉前 0.5s 系统“滴”声，避免影响识别。 音频设备：默认自动选择，优先耳机；如需固定设备，可在 player/reader 中指定设备索引。 🔐 隐私与本地化 唤醒与识别均可离线完成；音频不会上传到云端。 仅在你显式配置联网服务时才会产生外部调用。 🧪 简单示例（伪代码） # 极简示例：监听唤醒 → 识别 from utils.player import Player from utils.reader import Reader from utils.rouser import Rouser from pvrecorder import PvRecorder from dotenv import load_dotenv import os load_dotenv() ACCESS_KEY = os.getenv(\u0026#34;ACCESS_KEY\u0026#34;) ROUSE_WORD = os.getenv(\u0026#34;ROUSE_WORD\u0026#34;, \u0026#34;小智\u0026#34;) DEVICE_INDEX = -1 # 使用系统默认输入设备 rouser = Rouser(access_key=ACCESS_KEY, device_index=DEVICE_INDEX, keyword=ROUSE_WORD) player = Player() reader = Reader(device_index=DEVICE_INDEX) recorder = PvRecorder(device_index=DEVICE_INDEX, frame_length=rouser.porcupine.frame_length) recorder.start() print(f\u0026#34;正在监听唤醒词：『{ROUSE_WORD}』 (Ctrl+C 退出)\u0026#34;) while True: pcm = recorder.read() if rouser.process(pcm) \u0026gt;= 0: # 检测到唤醒 player.play_voice(block=True) # 提示音 text = reader.realtime_zh(rec_shared=recorder, beep_guard=0.0) if text: print(\u0026#34;识别文本：\u0026#34;, text) player.play_voice(block=True, type=\u0026#34;ok\u0026#34;) # 在这里根据 text 执行动作... else: player.play_voice(block=True, type=\u0026#34;sorry\u0026#34;) 🧯 故障排查 没有反应 / 设备占用：检查是否有其他应用占用麦克风；尝试在系统声音设置中启用设备。 识别慢：试用更小的 fast-whisper 模型或关闭其他高占用程序。 唤醒不灵敏：更换更清晰的唤醒词模型 .ppn，或在安静环境下测试。 提示音被识别进去：增大 beep_guard（如 0.7）。 🙌 致谢 Picovoice Porcupine（本地唤醒） fast-whisper（快速 ASR） ","permalink":"http://localhost:1313/posts/windows%E8%AF%AD%E9%9F%B3%E5%94%A4%E9%86%92%E5%8A%A9%E6%89%8B/","summary":"\u003cp\u003e最近闲着无聊随便做了一个\u003ca href=\"https://github.com/wanghai673/WinAssistant/\"\u003ewindows的语音唤醒助手\u003c/a\u003e，主要是闲平常要出门，或者不方便的时候（比如运动、躺床上的时候），可以叫一声电脑就做我想让他做的内容（可以连接LLM/GUI agent/MCP等等）。\u003c/p\u003e\n\u003cp\u003e再加上现在GUIAgent发展的很快，网上还没有语音唤醒形式的链接，也就自己搭了一个出来。\u003c/p\u003e\n\u003cp\u003e下面是这个项目的readme。\u003c/p\u003e\n\u003ch1 id=\"winassistant--windows-本地语音唤醒与自动化执行\"\u003eWinAssistant – Windows 本地语音唤醒与自动化执行\u003c/h1\u003e\n\u003cp\u003e一个在 \u003cstrong\u003eWindows\u003c/strong\u003e 上运行的本地语音助手：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e说出唤醒词 → 识别你的语音 → 自动执行自定义动作（脚本、GUI Agent、MCP 等）。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e全离线\u003c/strong\u003e（唤醒+识别均可离线），即插即用，优先使用耳机麦克风。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"演示视频\"\u003e演示视频\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/user-attachments/assets/a48b8e94-8b95-46eb-9aa5-a4085c2341c4\"\u003ehttps://github.com/user-attachments/assets/a48b8e94-8b95-46eb-9aa5-a4085c2341c4\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"-核心特性\"\u003e✨ 核心特性\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e多唤醒词可选 / 可自定义\u003c/strong\u003e\n内置多种常见唤醒词，也可替换为你训练的 \u003ccode\u003e.ppn\u003c/code\u003e 文件。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e本地唤醒：Picovoice Porcupine\u003c/strong\u003e\n轻量、低延迟、可靠，离线运行。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e语音识别：fast-whisper\u003c/strong\u003e\n内置\u003cstrong\u003e去噪\u003c/strong\u003e、\u003cstrong\u003eVAD 端点检测\u003c/strong\u003e，自动判断“用户是否说完”，可按需调节模型大小（速度/准确度权衡）。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e自动音频设备选择\u003c/strong\u003e\n自动选择可用的输入/输出设备，\u003cstrong\u003e优先耳机\u003c/strong\u003e。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e可插拔“处理态”\u003c/strong\u003e\n识别到文本后进入你的“处理态”（可自定义），例如：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e调用 MCP / 工具调用\u003c/li\u003e\n\u003cli\u003e触发 GUI Agent\u003c/li\u003e\n\u003cli\u003e执行脚本、打开应用、查询信息等\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"-工作流--状态机\"\u003e🧠 工作流 / 状态机\u003c/h2\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode class=\"language-mermaid\" data-lang=\"mermaid\"\u003estateDiagram-v2\n    [*] --\u0026gt; 空闲态\n    空闲态 --\u0026gt; 唤醒态: 语音唤醒\n    唤醒态 --\u0026gt; 处理态: 用户语音结束\n    处理态 --\u0026gt; 空闲态\n    唤醒态 --\u0026gt; 空闲态: 用户长时间无应答\n    空闲态 --\u0026gt; 空闲态: （持续监听）\n\u003c/code\u003e\u003c/pre\u003e\u003cblockquote\u003e\n\u003cp\u003e说明：唤醒后进入实时听写；若检测到\u003cstrong\u003e长时间静音\u003c/strong\u003e则回退到空闲态。\u003c/p\u003e","title":"Windows语音唤醒助手"},{"content":"之前看过很多成功学/心理学众所周知的道理，但是都是空头说话，没有任何数据证明，但这门课，能通过实验的方式展示结果，看到了让我更加信服（科学是最大的迷信hhh）。\n课程纠正了我非常多的偏见，让我对自己有了更清晰的认识，强烈推荐给大家！\n下面是The Science of Well-Being | Coursera的LLM的总结。\n1. 幸福的常见误解 1.1 “知道就够了”（G.I. Joe 谬误） 仅“知道道理”并不会自动改变行为；需要情境与练习把“知道”变“做到”。 1.2 找工作与被拒 被拒的痛苦通常没想的那样强与久，心理免疫系统会缓冲。 1.3 金钱与收入 年轻人的价值观更偏向“高收入为先”。 收入增长与主观幸福并非一一对应；整体幸福感在富足年代并未同步上扬。 超过某一阈值后，收入主要提升“生活评价”，对日常情绪的边际效用有限。 1.4 “酷东西”与物质主义 流行文化强化对豪车、名酒等的向往。 物质主义目标与更低的长期满意度相关。 1.5 真爱与婚姻 婚后幸福感常在几年内回落到基线（适应效应）。 1.6 完美身材/整形与完美成绩 减重或整形未必带来更好的长期心理健康或幸福。 人们普遍高估成绩变化带来的情绪涨落。 幸福并非被基因与环境“写死”，相当比例可由行为与思维方式塑造。 2. 我们为什么总是判断失准 2.1 误想（Miswanting） 对“未来会多喜欢/多讨厌”经常判断错误。 2.2 相对参照点 我们按比较而非绝对值评估自己：同侪收入、媒体/社交媒体的呈现、班级曲线、外貌对比等都会扭曲感受与选择。 2.3 适应力强 对“好事/坏事”都会逐渐习惯：收入提升、中彩票、婚姻等皆会回到常态。 2.4 忽视我们会适应 预测未来情绪时，容易“聚焦于单一事件”并忽略适应与其他生活面向，导致高估负面事件的持续影响。 3. 如何克服偏误（可操作策略） 3.1 重新定义“酷东西”：投资体验而非物质 把钱与精力优先投入能被分享与反复回味的体验（旅行、学习、共创）。 3.2 阻断/延缓适应 品味/回味（savoring）：刻意思考并记录正向时刻。 积极回忆 \u0026amp; 书写消化：写下负面事件并完成认知加工。 负向想象：设想“若没有这件好事会怎样”，提升珍惜度。 时间稀缺：把某些体验当作“最后一次”，增强投入。 感恩练习：数祝福、写感谢信、表达谢意。 重置参照点：有意切换比较标准，校准高/低参照引发的偏差。 打断消费：给愉悦体验加入“短暂停”，延长新鲜感。 4. 真正更有效的幸福来源 4.1 更好的“想要”（Part 1） 优势运用：识别并在工作中高频使用个人优势，提升满足与“天职感”。 心流（Flow）：挑战×能力匹配，带来深度专注与高质量体验。 成长型思维：相信能力可发展，更能从挫折中学习与精进。 4.2 更好的“想要”（Part 2 \u0026amp; 3） 善意与给予：随机善举、为他人花钱、助人使人更幸福（跨文化成立）。 社会连接：重视亲密与日常社交；与陌生人开启对话、共享体验。 时间富足：优先时间而非金钱；思考“我如何用时间与人相处？”。 冥想与正念：降低走神、提升幸福、工作记忆与社会连结感。 健康习惯：规律运动与高质量睡眠，稳定情绪与认知表现。 5. 把策略落地：从“知道”到“做到” 5.1 情境支持（让好行为“更顺手”） 把诱因放远、把好选择放近：远离随手零食，台面摆水果；为运动与阅读预先布置环境。 5.2 目标设定（从愿望到执行） 具体目标：定义清晰的量化标准与截止时间。 实施意图（If–Then）：为关键情境写下触发语句（例：“如果吃完午饭，就散步10分钟”）。 WOOP 技术：愿望（Wish）→成果（Outcome）→障碍（Obstacle）→计划（Plan）。 5.3 速查清单（一周可上手） 每周一次新方式运用你的前五优势；在岗尽量覆盖≥4个优势。 把钱优先用在体验/他人上；为娱乐安排小而频繁的享受并刻意中断。 每日感恩 3 件事＋每周一封感谢讯息。 正念/慈心冥想10–15 分钟，配合每周≥3次运动与固定就寝/起床。 社交优先：与同事/陌生人开启短聊，把体验与人分享。 为关键习惯写 3 条 If–Then，并用 WOOP 复盘障碍与应对。 6. 主要参考 6.1 认知与预测偏误 Santos \u0026amp; Gendler (2014). Knowing is half the battle? Edge. Gilbert \u0026amp; Wilson (2000). Miswanting: Some problems in the forecasting of future affective states. Levine et al. (2012). Accuracy and artifact: Reexamining the intensity bias in affective forecasting. Dunn et al. (2002). Location, location, location. Ayton et al. (2007). Affective forecasting: Why can\u0026rsquo;t people predict their emotions? Gilbert et al. (1998). Immune neglect… Gilbert (2007). Stumbling on Happiness. 6.2 金钱与价值观 Eagan et al. (2015). The American Freshman Survey. LinkedIn Survey (2014). What recent grads care the most about. Diener \u0026amp; Oishi (2000). Money and happiness… Myers (2000). The American Paradox. Lyubomirsky (2007). The How of Happiness. Kahneman \u0026amp; Deaton (2010). High income improves evaluation of life… New York Times. Economic diversity and student outcomes at Yale University. 6.3 参照点与社会比较 Medvec et al. (1995). Olympic medalists \u0026amp; counterfactuals. van Praag \u0026amp; Frijters (1999). Leyden approach. Clark \u0026amp; Oswald (1996). Satisfaction and comparison income. Solnick \u0026amp; Hemenway (1997). Positional concerns. Clark (2003). Unemployment as a social norm. O’Guinn \u0026amp; Shrum (1997). Television \u0026amp; consumer reality. Schor (1999). The Overspent American. Kuhn et al. (2011). Dutch Postcode Lottery. Kenrick et al. (1989; 1993). Attractiveness \u0026amp; comparison. Vogel et al. (2014). Social media \u0026amp; self-esteem. Burleigh \u0026amp; Meegan (2013). Keeping Up with the Joneses \u0026amp; justice. 6.4 适应与物质/体验 Brickman et al. (1978). Lottery winners \u0026amp; accident victims. Di Tella et al. (2010). Adaptation to income \u0026amp; status. Lucas et al. (2003). Adaptation to marriage. Boven \u0026amp; Gilovich (2003). To do or to have? Kumar et al. (2014). Anticipatory consumption of experiential purchases. Pchelin \u0026amp; Howell (2014). Hidden cost of value-seeking. Howell \u0026amp; Hill (2009). Mediators of experiential purchases. Nelson \u0026amp; Meyvis (2008). Interrupted consumption. Nelson et al. (2009). Commercial interruptions \u0026amp; TV. 6.5 优势/心流/心态与善意社交时间 Seligman (2004); Seligman et al. (2005). Signature strengths \u0026amp; interventions. Lavy \u0026amp; Littman-Ovadia (2017); Harzer \u0026amp; Ruch (2012). Strengths at work. Csikszentmihalyi (1992; 2008; 1999). Flow. Deci (1971); Dweck (2007); Grant \u0026amp; Dweck (2003); Blackwell et al. (2007); Mangels et al. (2006). Growth mindset。 Otake et al. (2006); Lyubomirsky (2005); Dunn (2014); Dunn et al. (2008); Aknin et al. (2013). Kindness \u0026amp; prosocial spending. Myers (2000); Diener \u0026amp; Seligman (2002); Epley (2014); Epley \u0026amp; Schroeder (2014); Boothby et al. (2014). Social connection. Whillans et al. (2016); Hershfield et al. (2016); Moligner (2010). Time over money. 6.6 正念、健康与执行 Killingsworth \u0026amp; Gilbert (2010); Mason et al. (2007); Brewer et al. (2011); Fredrickson et al. (2008); Hölzel et al. (2011); Mrazek et al. (2013); Hutcherson et al. (2008). Mind-wandering \u0026amp; meditation. Babyak et al. (2000); Hillman et al. (2008). Exercise \u0026amp; cognition. Dinges et al. (1997); Walker et al. (2002); Wagner et al. (2004); Huffington Post（睡眠图解）. Sleep \u0026amp; performance. Wansink et al. (2006; 2016). Situation support \u0026amp; default choices. Klein et al. (1990); Gollwitzer \u0026amp; Brandstätter (1997); Stadler \u0026amp; Oettingen (2010); Duckworth et al. (2013); Stadler et al. (2009). 目标与实施意图/WOOP。 ","permalink":"http://localhost:1313/posts/the_science_of_well-being_%E6%80%BB%E7%BB%93/","summary":"\u003cp\u003e之前看过很多成功学/心理学众所周知的道理，但是都是空头说话，没有任何数据证明，但这门课，能通过实验的方式展示结果，看到了让我更加信服（科学是最大的迷信hhh）。\u003c/p\u003e\n\u003cp\u003e课程纠正了我非常多的偏见，让我对自己有了更清晰的认识，强烈推荐给大家！\u003c/p\u003e\n\u003cp\u003e下面是\u003ca href=\"https://www.coursera.org/learn/the-science-of-well-being\"\u003eThe Science of Well-Being | Coursera\u003c/a\u003e的LLM的总结。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"1-幸福的常见误解\"\u003e1. 幸福的常见误解\u003c/h2\u003e\n\u003ch3 id=\"11-知道就够了gi-joe-谬误\"\u003e1.1 “知道就够了”（G.I. Joe 谬误）\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e仅“知道道理”并不会自动改变行为；需要情境与练习把“知道”变“做到”。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"12-找工作与被拒\"\u003e1.2 找工作与被拒\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e被拒的痛苦通常没想的那样强与久，心理免疫系统会缓冲。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"13-金钱与收入\"\u003e1.3 金钱与收入\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e年轻人的价值观更偏向“高收入为先”。\u003c/li\u003e\n\u003cli\u003e收入增长与主观幸福并非一一对应；整体幸福感在富足年代并未同步上扬。\u003c/li\u003e\n\u003cli\u003e超过某一阈值后，收入主要提升“生活评价”，对日常情绪的边际效用有限。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"14-酷东西与物质主义\"\u003e1.4 “酷东西”与物质主义\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e流行文化强化对豪车、名酒等的向往。\u003c/li\u003e\n\u003cli\u003e物质主义目标与更低的长期满意度相关。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"15-真爱与婚姻\"\u003e1.5 真爱与婚姻\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e婚后幸福感常在几年内回落到基线（适应效应）。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"16-完美身材整形与完美成绩\"\u003e1.6 完美身材/整形与完美成绩\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e减重或整形未必带来更好的长期心理健康或幸福。\u003c/li\u003e\n\u003cli\u003e人们普遍高估成绩变化带来的情绪涨落。\u003c/li\u003e\n\u003cli\u003e幸福并非被基因与环境“写死”，相当比例可由行为与思维方式塑造。\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"2-我们为什么总是判断失准\"\u003e2. 我们为什么总是判断失准\u003c/h2\u003e\n\u003ch3 id=\"21-误想miswanting\"\u003e2.1 误想（Miswanting）\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e对“未来会多喜欢/多讨厌”经常判断错误。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"22-相对参照点\"\u003e2.2 相对参照点\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e我们按比较而非绝对值评估自己：同侪收入、媒体/社交媒体的呈现、班级曲线、外貌对比等都会扭曲感受与选择。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"23-适应力强\"\u003e2.3 适应力强\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e对“好事/坏事”都会逐渐习惯：收入提升、中彩票、婚姻等皆会回到常态。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"24-忽视我们会适应\"\u003e2.4 忽视我们会适应\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e预测未来情绪时，容易“聚焦于单一事件”并忽略适应与其他生活面向，导致高估负面事件的持续影响。\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"3-如何克服偏误可操作策略\"\u003e3. 如何克服偏误（可操作策略）\u003c/h2\u003e\n\u003ch3 id=\"31-重新定义酷东西投资体验而非物质\"\u003e3.1 重新定义“酷东西”：投资体验而非物质\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e把钱与精力优先投入能被分享与反复回味的体验（旅行、学习、共创）。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"32-阻断延缓适应\"\u003e3.2 阻断/延缓适应\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e品味/回味（savoring）\u003c/strong\u003e：刻意思考并记录正向时刻。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e积极回忆 \u0026amp; 书写消化\u003c/strong\u003e：写下负面事件并完成认知加工。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e负向想象\u003c/strong\u003e：设想“若没有这件好事会怎样”，提升珍惜度。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e时间稀缺\u003c/strong\u003e：把某些体验当作“最后一次”，增强投入。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e感恩练习\u003c/strong\u003e：数祝福、写感谢信、表达谢意。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e重置参照点\u003c/strong\u003e：有意切换比较标准，校准高/低参照引发的偏差。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e打断消费\u003c/strong\u003e：给愉悦体验加入“短暂停”，延长新鲜感。\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"4-真正更有效的幸福来源\"\u003e4. 真正更有效的幸福来源\u003c/h2\u003e\n\u003ch3 id=\"41-更好的想要part-1\"\u003e4.1 更好的“想要”（Part 1）\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e优势运用\u003c/strong\u003e：识别并在工作中高频使用个人优势，提升满足与“天职感”。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e心流（Flow）\u003c/strong\u003e：挑战×能力匹配，带来深度专注与高质量体验。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e成长型思维\u003c/strong\u003e：相信能力可发展，更能从挫折中学习与精进。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"42-更好的想要part-2--3\"\u003e4.2 更好的“想要”（Part 2 \u0026amp; 3）\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e善意与给予\u003c/strong\u003e：随机善举、为他人花钱、助人使人更幸福（跨文化成立）。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e社会连接\u003c/strong\u003e：重视亲密与日常社交；与陌生人开启对话、共享体验。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e时间富足\u003c/strong\u003e：优先时间而非金钱；思考“我如何用时间与人相处？”。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e冥想与正念\u003c/strong\u003e：降低走神、提升幸福、工作记忆与社会连结感。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e健康习惯\u003c/strong\u003e：规律运动与高质量睡眠，稳定情绪与认知表现。\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"5-把策略落地从知道到做到\"\u003e5. 把策略落地：从“知道”到“做到”\u003c/h2\u003e\n\u003ch3 id=\"51-情境支持让好行为更顺手\"\u003e5.1 情境支持（让好行为“更顺手”）\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e把诱因放远、把好选择放近：远离随手零食，台面摆水果；为运动与阅读预先布置环境。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"52-目标设定从愿望到执行\"\u003e5.2 目标设定（从愿望到执行）\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e具体目标\u003c/strong\u003e：定义清晰的量化标准与截止时间。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e实施意图（If–Then）\u003c/strong\u003e：为关键情境写下触发语句（例：“如果吃完午饭，就散步10分钟”）。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eWOOP 技术\u003c/strong\u003e：愿望（Wish）→成果（Outcome）→障碍（Obstacle）→计划（Plan）。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"53-速查清单一周可上手\"\u003e5.3 速查清单（一周可上手）\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e每周\u003cstrong\u003e一次新方式\u003c/strong\u003e运用你的\u003cstrong\u003e前五优势\u003c/strong\u003e；在岗尽量覆盖≥4个优势。\u003c/li\u003e\n\u003cli\u003e把\u003cstrong\u003e钱\u003c/strong\u003e优先用在\u003cstrong\u003e体验/他人\u003c/strong\u003e上；为娱乐安排\u003cstrong\u003e小而频繁\u003c/strong\u003e的享受并\u003cstrong\u003e刻意中断\u003c/strong\u003e。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e每日感恩 3 件事\u003c/strong\u003e＋\u003cstrong\u003e每周一封感谢讯息\u003c/strong\u003e。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e正念/慈心冥想\u003c/strong\u003e10–15 分钟，配合\u003cstrong\u003e每周≥3次运动\u003c/strong\u003e与\u003cstrong\u003e固定就寝/起床\u003c/strong\u003e。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e社交优先\u003c/strong\u003e：与同事/陌生人开启短聊，把体验与人分享。\u003c/li\u003e\n\u003cli\u003e为关键习惯写 3 条 \u003cstrong\u003eIf–Then\u003c/strong\u003e，并用 \u003cstrong\u003eWOOP\u003c/strong\u003e 复盘障碍与应对。\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"6-主要参考\"\u003e6. 主要参考\u003c/h2\u003e\n\u003ch3 id=\"61-认知与预测偏误\"\u003e6.1 认知与预测偏误\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eSantos \u0026amp; Gendler (2014). Knowing is half the battle? Edge.\u003c/li\u003e\n\u003cli\u003eGilbert \u0026amp; Wilson (2000). Miswanting: Some problems in the forecasting of future affective states.\u003c/li\u003e\n\u003cli\u003eLevine et al. (2012). Accuracy and artifact: Reexamining the intensity bias in affective forecasting.\u003c/li\u003e\n\u003cli\u003eDunn et al. (2002). Location, location, location.\u003c/li\u003e\n\u003cli\u003eAyton et al. (2007). Affective forecasting: Why can\u0026rsquo;t people predict their emotions?\u003c/li\u003e\n\u003cli\u003eGilbert et al. (1998). Immune neglect…\u003c/li\u003e\n\u003cli\u003eGilbert (2007). \u003cem\u003eStumbling on Happiness\u003c/em\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"62-金钱与价值观\"\u003e6.2 金钱与价值观\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eEagan et al. (2015). \u003cem\u003eThe American Freshman Survey\u003c/em\u003e.\u003c/li\u003e\n\u003cli\u003eLinkedIn Survey (2014). What recent grads care the most about.\u003c/li\u003e\n\u003cli\u003eDiener \u0026amp; Oishi (2000). Money and happiness…\u003c/li\u003e\n\u003cli\u003eMyers (2000). \u003cem\u003eThe American Paradox\u003c/em\u003e.\u003c/li\u003e\n\u003cli\u003eLyubomirsky (2007). \u003cem\u003eThe How of Happiness\u003c/em\u003e.\u003c/li\u003e\n\u003cli\u003eKahneman \u0026amp; Deaton (2010). High income improves evaluation of life…\u003c/li\u003e\n\u003cli\u003eNew York Times. Economic diversity and student outcomes at Yale University.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"63-参照点与社会比较\"\u003e6.3 参照点与社会比较\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eMedvec et al. (1995). Olympic medalists \u0026amp; counterfactuals.\u003c/li\u003e\n\u003cli\u003evan Praag \u0026amp; Frijters (1999). Leyden approach.\u003c/li\u003e\n\u003cli\u003eClark \u0026amp; Oswald (1996). Satisfaction and comparison income.\u003c/li\u003e\n\u003cli\u003eSolnick \u0026amp; Hemenway (1997). Positional concerns.\u003c/li\u003e\n\u003cli\u003eClark (2003). Unemployment as a social norm.\u003c/li\u003e\n\u003cli\u003eO’Guinn \u0026amp; Shrum (1997). Television \u0026amp; consumer reality.\u003c/li\u003e\n\u003cli\u003eSchor (1999). \u003cem\u003eThe Overspent American\u003c/em\u003e.\u003c/li\u003e\n\u003cli\u003eKuhn et al. (2011). Dutch Postcode Lottery.\u003c/li\u003e\n\u003cli\u003eKenrick et al. (1989; 1993). Attractiveness \u0026amp; comparison.\u003c/li\u003e\n\u003cli\u003eVogel et al. (2014). Social media \u0026amp; self-esteem.\u003c/li\u003e\n\u003cli\u003eBurleigh \u0026amp; Meegan (2013). Keeping Up with the Joneses \u0026amp; justice.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"64-适应与物质体验\"\u003e6.4 适应与物质/体验\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eBrickman et al. (1978). Lottery winners \u0026amp; accident victims.\u003c/li\u003e\n\u003cli\u003eDi Tella et al. (2010). Adaptation to income \u0026amp; status.\u003c/li\u003e\n\u003cli\u003eLucas et al. (2003). Adaptation to marriage.\u003c/li\u003e\n\u003cli\u003eBoven \u0026amp; Gilovich (2003). To do or to have?\u003c/li\u003e\n\u003cli\u003eKumar et al. (2014). Anticipatory consumption of experiential purchases.\u003c/li\u003e\n\u003cli\u003ePchelin \u0026amp; Howell (2014). Hidden cost of value-seeking.\u003c/li\u003e\n\u003cli\u003eHowell \u0026amp; Hill (2009). Mediators of experiential purchases.\u003c/li\u003e\n\u003cli\u003eNelson \u0026amp; Meyvis (2008). Interrupted consumption.\u003c/li\u003e\n\u003cli\u003eNelson et al. (2009). Commercial interruptions \u0026amp; TV.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"65-优势心流心态与善意社交时间\"\u003e6.5 优势/心流/心态与善意社交时间\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eSeligman (2004); Seligman et al. (2005). Signature strengths \u0026amp; interventions.\u003c/li\u003e\n\u003cli\u003eLavy \u0026amp; Littman-Ovadia (2017); Harzer \u0026amp; Ruch (2012). Strengths at work.\u003c/li\u003e\n\u003cli\u003eCsikszentmihalyi (1992; 2008; 1999). Flow.\u003c/li\u003e\n\u003cli\u003eDeci (1971); Dweck (2007); Grant \u0026amp; Dweck (2003); Blackwell et al. (2007); Mangels et al. (2006). Growth mindset。\u003c/li\u003e\n\u003cli\u003eOtake et al. (2006); Lyubomirsky (2005); Dunn (2014); Dunn et al. (2008); Aknin et al. (2013). Kindness \u0026amp; prosocial spending.\u003c/li\u003e\n\u003cli\u003eMyers (2000); Diener \u0026amp; Seligman (2002); Epley (2014); Epley \u0026amp; Schroeder (2014); Boothby et al. (2014). Social connection.\u003c/li\u003e\n\u003cli\u003eWhillans et al. (2016); Hershfield et al. (2016); Moligner (2010). Time over money.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"66-正念健康与执行\"\u003e6.6 正念、健康与执行\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eKillingsworth \u0026amp; Gilbert (2010); Mason et al. (2007); Brewer et al. (2011); Fredrickson et al. (2008); Hölzel et al. (2011); Mrazek et al. (2013); Hutcherson et al. (2008). Mind-wandering \u0026amp; meditation.\u003c/li\u003e\n\u003cli\u003eBabyak et al. (2000); Hillman et al. (2008). Exercise \u0026amp; cognition.\u003c/li\u003e\n\u003cli\u003eDinges et al. (1997); Walker et al. (2002); Wagner et al. (2004); \u003cem\u003eHuffington Post\u003c/em\u003e（睡眠图解）. Sleep \u0026amp; performance.\u003c/li\u003e\n\u003cli\u003eWansink et al. (2006; 2016). Situation support \u0026amp; default choices.\u003c/li\u003e\n\u003cli\u003eKlein et al. (1990); Gollwitzer \u0026amp; Brandstätter (1997); Stadler \u0026amp; Oettingen (2010); Duckworth et al. (2013); Stadler et al. (2009). 目标与实施意图/WOOP。\u003c/li\u003e\n\u003c/ul\u003e","title":"耶鲁大学幸福科学课程总结"},{"content":"最近都在广泛学习一些有趣的内容，主要是通过coursera平台。在家呆了2个多月了，也不知道未来啥方向，目前也是有些迷茫的状态，还是学些东西充实下自己吧，搜寻一下感兴趣的东东。\ncoursera平台类似于国外的mooc，国内外还有好多这样的平台，如中国大学mooc、bilibili大学、网易云课等等。coursera需要付费会员才能观看课程，而且只能通过国外信用卡付款（无）。于是，我在淘宝一搜，这么多卖号，而且很便宜，86半年，立马充值了一波。\n有了平台，我立马重新在coursera里，拾起深度学习的基础知识，吴恩达的课程。之前只听过，在coursera认真地观看，还是感觉受益匪浅，毕竟有作业有互动，感觉b站还是差点味道。\n现在主要看了深度学习专项课程的前3个：\n其实就相当于复习了一下之前在李沐动手学深度学习的内容。\n然后光看深度学习也有些乏味，我在网上搜索coursera有没有其他好课程，打开了一个课程排名，类似于垃圾小网站的那种：\n然后最近在看幸福科学，才刚开始看，讲的是如何变得幸福，通过科学的方式，感觉讲的还挺好的，在实验的加持下，科学成为人们可以坚持最大的迷信，hhh，但是还是要有反驳精神，感觉很多科学实验严谨性还是有些欠缺。\n之后的日子，想了解一下金融相关的知识，挺感兴趣的。马上要开学了，5555，希望能保持学习一些课外内容的习惯。还有，运动也要保持，在家和爸妈打了一个暑假的乒乓球，每日锻炼~\n","permalink":"http://localhost:1313/posts/%E6%9C%80%E8%BF%91%E5%9C%A8%E5%81%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E4%BA%8B/","summary":"\u003cp\u003e最近都在广泛学习一些有趣的内容，主要是通过coursera平台。在家呆了2个多月了，也不知道未来啥方向，目前也是有些迷茫的状态，还是学些东西充实下自己吧，搜寻一下感兴趣的东东。\u003c/p\u003e\n\u003cp\u003ecoursera平台类似于国外的mooc，国内外还有好多这样的平台，如中国大学mooc、bilibili大学、网易云课等等。coursera需要付费会员才能观看课程，而且只能通过国外信用卡付款（无）。于是，我在淘宝一搜，这么多卖号，而且很便宜，86半年，立马充值了一波。\u003c/p\u003e\n\u003cp\u003e有了平台，我立马重新在coursera里，拾起深度学习的基础知识，吴恩达的课程。之前只听过，在coursera认真地观看，还是感觉受益匪浅，毕竟有作业有互动，感觉b站还是差点味道。\u003c/p\u003e\n\u003cp\u003e现在主要看了深度学习专项课程的前3个：\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"233\" loading=\"lazy\" src=\"/posts/%E6%9C%80%E8%BF%91%E5%9C%A8%E5%81%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E4%BA%8B/image-20250825155253827.png\"\u003e\u003c/p\u003e\n\u003cp\u003e其实就相当于复习了一下之前在李沐动手学深度学习的内容。\u003c/p\u003e\n\u003cp\u003e然后光看深度学习也有些乏味，我在网上搜索coursera有没有其他好课程，打开了一个课程排名，类似于垃圾小网站的那种：\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"2333\" loading=\"lazy\" src=\"/posts/%E6%9C%80%E8%BF%91%E5%9C%A8%E5%81%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E4%BA%8B/image-20250825155452140.png\"\u003e\u003c/p\u003e\n\u003cp\u003e然后最近在看幸福科学，才刚开始看，讲的是如何变得幸福，通过科学的方式，感觉讲的还挺好的，在实验的加持下，科学成为人们可以坚持最大的迷信，hhh，但是还是要有反驳精神，感觉很多科学实验严谨性还是有些欠缺。\u003c/p\u003e\n\u003cp\u003e之后的日子，想了解一下金融相关的知识，挺感兴趣的。马上要开学了，5555，希望能保持学习一些课外内容的习惯。还有，运动也要保持，在家和爸妈打了一个暑假的乒乓球，每日锻炼~\u003c/p\u003e","title":"最近在做的一些事"},{"content":"softmax是一个经典的多分类概率分布的公式，有n个类，softmax公式如下， $$ \\text{softmax}(z)_j = \\frac{e^{z_j}}{\\sum_{i=1}^n e^{z_i}}, \\quad j = 1, 2, \\dots, n $$ 首先，考虑一个样本每个类的预测分数做一个softmax，转换成每类预测的概率形式。\n$$ a^{[L]} = \\text{softmax}(z^{[L]}) $$$$ \\hat{y} = a^{[L]}\\quad $$然后，利用样本标签，结合极大似然估计的损失函数如下。 $$ L(\\hat{y}, y) = - \\sum_{i=1}^{n} y_i \\log(\\hat{y}_i) $$由于需要做反向传播，我们想求 $\\frac{\\partial L}{\\partial z^{[L]}}$，也就是做完softmax的前的偏导数。\n假设 $y$ 的分类为 $1$，则 $y_1 = 1$，其余 $y_j = 0\\ (j\\neq 1)$，$y=[1,0,.....,0]$ 则有， $$ L(\\hat{y}, y) = -\\log(\\hat{y}_1) $$$$ L(\\hat{y}, y) = - \\ln \\left( \\frac{e^{z_1^{[L]}}}{e^{z_1^{[L]}} + e^{z_2^{[L]}} + \\cdots + e^{z_n^{[L]}}} \\right), \\quad S = e^{z_1^{[L]}} + e^{z_2^{[L]}} + \\cdots + e^{z_n^{[L]}} $$接下来求 $Z^{[L]}$ 的偏导， $$ \\frac{\\partial L}{\\partial z^{[L]}_1} = -\\frac{S}{e^{z^{[L]}_1}} \\cdot \\frac{e^{z^{[L]}_1} \\cdot S - \\big(e^{z^{[L]}_1}\\big)^2}{S^2} = \\frac{e^{z^{[L]}_1}}{S} - 1 $$$$ \\frac{\\partial L}{\\partial z^{[L]}_j} = - \\frac{S}{e^{z^{[L]}_1}} \\cdot \\frac{-e^{z^{[L]}_1} \\cdot e^{z^{[L]}_j}}{S^2} = \\frac{e^{z^{[L]}_j}}{S}, \\quad j \\neq 1 $$因为， $$ a_j^{[L]} = \\frac{e^{z_j^{[L]}}}{S}, $$ 所以， $$ \\frac{\\partial L}{\\partial z^{[L]}_1} = a_1^{[L]} - 1 $$$$ \\frac{\\partial L}{\\partial z^{[L]}_j} = a_j^{[L]}, \\quad (j \\neq 1) $$由于不同分类标签的对称性，从而得到最终化简结果， $$ \\frac{\\partial L}{\\partial z^{[L]}} = \\hat{y} - y $$ 对于多样本，每个样本间独立，则有， $$ \\frac{\\partial L}{\\partial Z^{[L]}} = \\hat{Y} - Y $$","permalink":"http://localhost:1313/posts/softmax%E7%9A%84%E5%AF%BC%E6%95%B0%E6%8E%A8%E5%AF%BC/","summary":"\u003cp\u003esoftmax是一个经典的多分类概率分布的公式，有n个类，softmax公式如下，\n\u003c/p\u003e\n$$\n\\text{softmax}(z)_j = \\frac{e^{z_j}}{\\sum_{i=1}^n  e^{z_i}}, \\quad j = 1, 2, \\dots, n\n$$\u003cp\u003e\n首先，考虑一个样本每个类的预测分数做一个softmax，转换成每类预测的概率形式。\u003c/p\u003e\n$$\na^{[L]} = \\text{softmax}(z^{[L]})\n$$$$\n\\hat{y} = a^{[L]}\\quad\n$$\u003cp\u003e然后，利用样本标签，结合极大似然估计的损失函数如下。\n\u003c/p\u003e\n$$\nL(\\hat{y}, y) = - \\sum_{i=1}^{n} y_i \\log(\\hat{y}_i)\n$$\u003cp\u003e由于需要做反向传播，我们想求 $\\frac{\\partial L}{\\partial z^{[L]}}$，也就是做完softmax的前的偏导数。\u003c/p\u003e\n\u003cp\u003e假设 $y$ 的分类为 $1$，则 $y_1 = 1$，其余 $y_j = 0\\ (j\\neq 1)$，$y=[1,0,.....,0]$\n则有，\n\u003c/p\u003e\n$$\nL(\\hat{y}, y) = -\\log(\\hat{y}_1)\n$$$$\nL(\\hat{y}, y) = - \\ln \\left( \\frac{e^{z_1^{[L]}}}{e^{z_1^{[L]}} + e^{z_2^{[L]}} + \\cdots + e^{z_n^{[L]}}} \\right),\n\\quad S = e^{z_1^{[L]}} + e^{z_2^{[L]}} + \\cdots + e^{z_n^{[L]}}\n$$\u003cp\u003e接下来求 $Z^{[L]}$ 的偏导，\n\u003c/p\u003e","title":"Softmax的反向传播推导"},{"content":"\n最近在重新回顾深度学习相关基础，之前大概过了一遍李沐的动手学深度学习，但很多内容还一知半解， 感觉网上课程难度曲线还是不太平滑。\n无意间看到 Coursera平台，在淘宝上花了80买了个半年号，仿佛打开新世界了，第一次看到了原来真的有课程能把深度学习的学习曲线 弄的这么平滑的，爱了，有点像算法竞赛的acwing、牛客。感觉b站确实不错，但是反馈和互动肯定远远比不上Coursera的。\n现在刚学完第一门课程，并手动设计并实现了多层卷积神经网络（只用到numpy），在这里记录一下forward/back propagation的数学知识（主要是线性代数）。\n正向传播 非常简单易懂，就是矩阵乘法。\n反向传播 引理一 搞懂这个引理反向传播就差不多弄懂了，求哪个偏导，固定某行/列值算贡献 就好求了（A固定行，B固定列），因为矩阵乘法是B的列与A的行做点积。\n以上就是神经网络里的线性代数的一些知识，其实不需要太多基础弄得矩阵乘法，和求导链式法则即可手写神经网络。\n","permalink":"http://localhost:1313/posts/%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC/","summary":"\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC/2.png\"\u003e\u003c/p\u003e\n\u003cp\u003e最近在重新回顾深度学习相关基础，之前大概过了一遍李沐的动手学深度学习，但很多内容还一知半解，\n感觉网上课程难度曲线还是不太平滑。\u003c/p\u003e\n\u003cp\u003e无意间看到 \u003ca href=\"https://www.coursera.org/\"\u003eCoursera平台\u003c/a\u003e，在淘宝上花了80买了个半年号，仿佛打开新世界了，第一次看到了原来真的有课程能把深度学习的学习曲线\n弄的这么平滑的，爱了，有点像算法竞赛的acwing、牛客。感觉b站确实不错，但是反馈和互动肯定远远比不上Coursera的。\u003c/p\u003e\n\u003cp\u003e现在刚学完第一门课程，并手动设计并实现了多层卷积神经网络（只用到numpy），在这里记录一下forward/back propagation的数学知识（主要是线性代数）。\u003c/p\u003e\n\u003ch4 id=\"正向传播\"\u003e正向传播\u003c/h4\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC/%281%29.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003e非常简单易懂，就是矩阵乘法。\u003c/p\u003e\n\u003ch4 id=\"反向传播\"\u003e反向传播\u003c/h4\u003e\n\u003ch5 id=\"引理一\"\u003e引理一\u003c/h5\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC/%282%29.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC/%283%29.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003e搞懂这个引理反向传播就差不多弄懂了，求哪个偏导，固定某行/列值算贡献 就好求了（A固定行，B固定列），因为矩阵乘法是B的列与A的行做点积。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC/%284%29.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003e以上就是神经网络里的线性代数的一些知识，其实不需要太多基础弄得矩阵乘法，和求导链式法则即可手写神经网络。\u003c/p\u003e","title":"神经网络反向传播 数学推导"},{"content":"工具介绍 Hugo 简介：Hugo 是一个用 Go 语言编写的静态网站生成器。它以极快的生成速度著称，可以在几秒内构建上千页面。\n特点：\n不依赖数据库，所有页面都是静态文件，部署简单且性能高。 支持 Markdown 写作，适合博客和文档站点。 拥有强大的模板系统和主题生态。 跨平台运行（Windows、Linux、macOS）。 PaperMod 简介：PaperMod 是 Hugo 社区里非常流行的一个 简洁、现代的主题，灵感来自 Google Material Design。\n特点：\n设计简洁清爽，注重阅读体验。 自带夜间模式、搜索、标签分类等功能。 对 SEO 和性能友好，开箱即用。 支持高度自定义，比如文章目录、社交链接、评论系统等。 👉 总结：Hugo 是建站工具，PaperMod 是在 Hugo 上常用的主题之一。\nStep 1 按照下面视频安装hugo+papermod，搭建demo\n【雷】Hugo + Github免费搭建博客，并实现自动化部署\nStep 2 配置papermod主题，结合大语言模型，想要什么功能直接询问即可，并修改配置文件，主题大部分都是配有相关功能的。\n","permalink":"http://localhost:1313/posts/hugo+paermod%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%95%99%E7%A8%8B/","summary":"\u003ch3 id=\"工具介绍\"\u003e工具介绍\u003c/h3\u003e\n\u003ch4 id=\"hugo\"\u003eHugo\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e简介\u003c/strong\u003e：Hugo 是一个用 Go 语言编写的\u003cstrong\u003e静态网站生成器\u003c/strong\u003e。它以极快的生成速度著称，可以在几秒内构建上千页面。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e特点\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e不依赖数据库，所有页面都是静态文件，部署简单且性能高。\u003c/li\u003e\n\u003cli\u003e支持 Markdown 写作，适合博客和文档站点。\u003c/li\u003e\n\u003cli\u003e拥有强大的模板系统和主题生态。\u003c/li\u003e\n\u003cli\u003e跨平台运行（Windows、Linux、macOS）。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"papermod\"\u003ePaperMod\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e简介\u003c/strong\u003e：PaperMod 是 Hugo 社区里非常流行的一个 \u003cstrong\u003e简洁、现代的主题\u003c/strong\u003e，灵感来自 Google Material Design。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e特点\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e设计简洁清爽，注重阅读体验。\u003c/li\u003e\n\u003cli\u003e自带夜间模式、搜索、标签分类等功能。\u003c/li\u003e\n\u003cli\u003e对 SEO 和性能友好，开箱即用。\u003c/li\u003e\n\u003cli\u003e支持高度自定义，比如文章目录、社交链接、评论系统等。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e👉 总结：\u003cstrong\u003eHugo\u003c/strong\u003e 是建站工具，\u003cstrong\u003ePaperMod\u003c/strong\u003e 是在 Hugo 上常用的主题之一。\u003c/p\u003e\n\u003ch3 id=\"step-1\"\u003eStep 1\u003c/h3\u003e\n\u003cp\u003e按照下面视频安装hugo+papermod，搭建demo\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://www.bilibili.com/video/BV1bovfeaEtQ?vd_source=89574dec834a4f547f86ccea8df6514e\"\u003e【雷】Hugo + Github免费搭建博客，并实现自动化部署\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id=\"step-2\"\u003eStep 2\u003c/h3\u003e\n\u003cp\u003e配置papermod主题，结合大语言模型，想要什么功能直接询问即可，并修改配置文件，主题大部分都是配有相关功能的。\u003c/p\u003e","title":"hugo+papermod博客搭建教程"},{"content":"你好，我是 wanghai673，一名正在攻读 计算机科学与技术 的研究生（研 0），本科毕业于东华大学，目前就读于华东师范大学。\n💻 编程语言：C++、Python、Java\n🔍 研究兴趣：深度学习、大语言模型、智能体\n🏆 竞赛经历：\nICPC 亚洲区域赛 金奖（第 49 届） 蓝桥杯全国总决赛 一等奖（全国第 6 名） 百度之星全国总决赛 金奖 多次 ICPC/CCPC 银奖 上海市大学生程序设计竞赛 一等奖 我正在不断学习和提升自己，期待将所学应用于实际问题。如果有相关的 实习机会 或者 研究合作，非常欢迎联系我。\n📫 联系方式：微信、邮件\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e你好，我是 \u003cstrong\u003ewanghai673\u003c/strong\u003e，一名正在攻读 \u003cstrong\u003e计算机科学与技术\u003c/strong\u003e 的研究生（研 0），本科毕业于东华大学，目前就读于华东师范大学。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e💻 编程语言：C++、Python、Java\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e🔍 研究兴趣：深度学习、大语言模型、智能体\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e🏆 竞赛经历：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eICPC 亚洲区域赛 \u003cstrong\u003e金奖（第 49 届）\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e蓝桥杯全国总决赛 \u003cstrong\u003e一等奖（全国第 6 名）\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e百度之星全国总决赛 \u003cstrong\u003e金奖\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e多次 ICPC/CCPC \u003cstrong\u003e银奖\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e上海市大学生程序设计竞赛 \u003cstrong\u003e一等奖\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e我正在不断学习和提升自己，期待将所学应用于实际问题。如果有相关的 \u003cstrong\u003e实习机会\u003c/strong\u003e 或者 \u003cstrong\u003e研究合作\u003c/strong\u003e，非常欢迎联系我。\u003c/p\u003e\n\u003cp\u003e📫 联系方式：\u003ca href=\"wechat.jpg\"\u003e微信\u003c/a\u003e、\u003ca href=\"https://mail.qq.com/cgi-bin/qm_share?t=qm_mailme\u0026amp;email=1154103986@qq.com\"\u003e邮件\u003c/a\u003e\u003c/p\u003e","title":"关于"},{"content":"EduAgent: Generative Student Agents in Learning 总结\n本文是针对线上教育领域的学生模仿相关的研究，之前的模型多利用庞大的数据对学生学习行为进行预测，随着LLM的问世，LLM提供的前置知识能很好的针对不同场景不同内容线上教育的学生行为预测。\n学生行为预测受到多方面的影响，如性格、学生储备知识等，本文提供了一个数据集（350个sample），针对一段5分钟的幻灯片讲解，提供学生个人信息和每个小时间段的学生注意窗口、行为、认知状态信息等。\n作者结合LLM强大的推理功能，让LLM自主推理出不同信息间的关联，从而实现学生行为的预测和模仿，但这篇论文的实验没咋看懂\u0026hellip;\nLLM-mediated domain-specific voice agents: the case of TextileBot 总结\n粗粒度地看了下\u0026hellip;\n只看了摘要和引言和结论，讲的是如何原型化地设计一个垂直领域的对话agent，包含prompt模板，随后作者自己设计了一个宣传服装环保领域的一个agent（在购物的时候跟顾客交流的），并做了用户实验。\nWhy language models hallucinate 总结\nWhy language models hallucinate | OpenAI\nOpenAI 9月5号刚发布的文章，主要讲述了为什么大语言模型会产生幻觉。\n作者描述，LLM（大语言模型）之所以产生幻觉，是因为现在对模型后训练的奖励函数，往往将答错一道题和拒答一道题（承认不知道）的惩罚都是一致的，导致LLM更倾向于去猜题，这样还有概率猜对。\n那有人就会说了，让答错的惩罚提升一些不就行了。确实可以，但是作者回应到现如今大多数的benchmark，只有对/错两个选项，并没有考虑到幻觉的因素，从而导致大家更宁愿LLM猜题，增加一些benchmark的准确率，而不是拒答（大幅度降低幻觉，但准确率会略微降低）。\n作者呼吁所有benchmark的制作者们，将幻觉这个评价指标加入到benchmark的评测之中，从而抑制LLM的胡言乱语。但现在的benchmark对幻觉的评判往往是特定的一类，大多数benmark没有考虑幻觉因素。\n上面都是通过后训练降低LLM幻觉的途径，那能不能在预训练的时候降低大语言模型的幻觉呢？作者回答，现在的数据都是无监督的，导致LLM并没有办法对每段数据的真实性做判断，更好的办法还是在后训练的时候减少大模型的幻觉。\n下图是原文的提出的LLM幻觉的一些误解与澄清：\n","permalink":"http://localhost:1313/posts/9.6_%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/","summary":"\u003ch3 id=\"eduagent-generative-student-agents-in-learning\"\u003eEduAgent: Generative Student Agents in Learning\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e总结\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e本文是针对线上教育领域的学生模仿相关的研究，之前的模型多利用庞大的数据对学生学习行为进行预测，随着LLM的问世，LLM提供的前置知识能很好的针对不同场景不同内容线上教育的学生行为预测。\u003c/p\u003e\n\u003cp\u003e学生行为预测受到多方面的影响，如性格、学生储备知识等，本文提供了一个数据集（350个sample），针对一段5分钟的幻灯片讲解，提供学生个人信息和每个小时间段的学生注意窗口、行为、认知状态信息等。\u003c/p\u003e\n\u003cp\u003e作者结合LLM强大的推理功能，让LLM自主推理出不同信息间的关联，从而实现学生行为的预测和模仿，但这篇论文的实验没咋看懂\u0026hellip;\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"llm-mediated-domain-specific-voice-agents-the-case-of-textilebot\"\u003eLLM-mediated domain-specific voice agents: the case of TextileBot\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e总结\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e粗粒度地看了下\u0026hellip;\u003c/p\u003e\n\u003cp\u003e只看了摘要和引言和结论，讲的是如何原型化地设计一个垂直领域的对话agent，包含prompt模板，随后作者自己设计了一个宣传服装环保领域的一个agent（在购物的时候跟顾客交流的），并做了用户实验。\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"why-language-models-hallucinate\"\u003eWhy language models hallucinate\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e总结\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://openai.com/index/why-language-models-hallucinate/\"\u003eWhy language models hallucinate | OpenAI\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eOpenAI 9月5号刚发布的文章，主要讲述了为什么大语言模型会产生幻觉。\u003c/p\u003e\n\u003cp\u003e作者描述，LLM（大语言模型）之所以产生幻觉，是因为现在对模型后训练的奖励函数，往往将答错一道题和拒答一道题（承认不知道）的惩罚都是一致的，导致LLM更倾向于去猜题，这样还有概率猜对。\u003c/p\u003e\n\u003cp\u003e那有人就会说了，让答错的惩罚提升一些不就行了。确实可以，但是作者回应到现如今大多数的benchmark，只有对/错两个选项，并没有考虑到幻觉的因素，从而导致大家更宁愿LLM猜题，增加一些benchmark的准确率，而不是拒答（大幅度降低幻觉，但准确率会略微降低）。\u003c/p\u003e\n\u003cp\u003e作者呼吁所有benchmark的制作者们，将幻觉这个评价指标加入到benchmark的评测之中，从而抑制LLM的胡言乱语。但现在的benchmark对幻觉的评判往往是特定的一类，大多数benmark没有考虑幻觉因素。\u003c/p\u003e\n\u003cp\u003e上面都是通过后训练降低LLM幻觉的途径，那能不能在预训练的时候降低大语言模型的幻觉呢？作者回答，现在的数据都是无监督的，导致LLM并没有办法对每段数据的真实性做判断，更好的办法还是在后训练的时候减少大模型的幻觉。\u003c/p\u003e\n\u003cp\u003e下图是原文的提出的LLM幻觉的一些误解与澄清：\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250906164329093\" loading=\"lazy\" src=\"/posts/9.6_%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/image-20250906164329093.png\"\u003e\u003c/p\u003e","title":"9.6 论文阅读"},{"content":"LLM Agents for Education: Advances and Applications 总结\n这是一篇综述论文，讲述了现在LLM agents在领域的各种运用。作者将教育agent分为 教学agent 和 垂直领域agent。\n教学agent又分为面向学生和面向教师的，垂直领域的分为很多不同学科类的agent，不同学科agent也有不同的功能的agent，整体分类思维导图见下图。\n然后作者讲述了，现有教育agent所面临的困难，如道德、偏见方面的，也有幻觉、可靠性方面的。现有的agent大多数不具备结构化的形式（更多是对话类型），无法直接在现实教育场景中插入。\n最后整理介绍了现有测评教育agent各种benchmark，以供后来研究者使用。\nMATHAGENT: Leveraging a Mixture-of-Math-Agent Framework for Real-World Multimodal Mathematical Error Detection 背景\n大语言模型在数学问题求解中已经非常厉害了，但是在数学错误发现上还很少涉足。传统的数学老师批改，耗时耗力，并且不具备可扩展性，如无法为学生指明学生具体错误（人工成本高），多模态大模型可以识别图片，并且为学生提供错误位置和错误分类，但是MLLM还在存在较多错误，对于有细微错误的地方无法很好识别。并且现在研究多聚焦纯文本数学题改错，对于带有图片信息的不能很好应对。\n方法\n数据集合为下图，有文本问题描述，图片类信息，正确答案，学生的不正确答案，解题步骤。 任务分为 1：找到第一个错误步骤，2：错误分类，指标都是准确率。\n作者引入了个多智能体框架，分为三个部分，流程如下图。\n文本-图像一致性检测：判断图片和文字是否高度一致，避免使用图片识别功能，从而增强题目解读能力 公式-表格识别：用专门model将各种公式、表格等识别为文本形式 融合找错：将文本和转文本的图片信息融合为一个完整题目，并且让LLM完成上面具体两个任务 实验结果\n将该方法运用到多个多模态大模型，大部分都能提升准确率，但相较于人工还有很大的差距。 论文写的浅显易懂，结构也很清晰，可惜本论文并未公布数据集。。。\n","permalink":"http://localhost:1313/posts/9%E6%9C%885%E6%97%A5%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/","summary":"\u003ch3 id=\"llm-agents-for-education-advances-and-applications\"\u003eLLM Agents for Education: Advances and Applications\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e总结\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e这是一篇综述论文，讲述了现在LLM agents在领域的各种运用。作者将教育agent分为 教学agent 和 垂直领域agent。\u003c/p\u003e\n\u003cp\u003e教学agent又分为面向学生和面向教师的，垂直领域的分为很多不同学科类的agent，不同学科agent也有不同的功能的agent，整体分类思维导图见下图。\u003c/p\u003e\n\u003cp\u003e然后作者讲述了，现有教育agent所面临的困难，如道德、偏见方面的，也有幻觉、可靠性方面的。现有的agent大多数不具备结构化的形式（更多是对话类型），无法直接在现实教育场景中插入。\u003c/p\u003e\n\u003cp\u003e最后整理介绍了现有测评教育agent各种benchmark，以供后来研究者使用。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"image-20250905134524279\" loading=\"lazy\" src=\"/posts/9%E6%9C%885%E6%97%A5%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/image-20250905134524279.png\"\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"mathagent-leveraging-a-mixture-of-math-agent-framework-for-real-world-multimodal-mathematical-error-detection\"\u003eMATHAGENT: Leveraging a Mixture-of-Math-Agent Framework for Real-World Multimodal Mathematical Error Detection\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e背景\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e大语言模型在数学问题求解中已经非常厉害了，但是在数学错误发现上还很少涉足。传统的数学老师批改，耗时耗力，并且不具备可扩展性，如无法为学生指明学生具体错误（人工成本高），多模态大模型可以识别图片，并且为学生提供错误位置和错误分类，但是MLLM还在存在较多错误，对于有细微错误的地方无法很好识别。并且现在研究多聚焦纯文本数学题改错，对于带有图片信息的不能很好应对。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e方法\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e数据集合为下图，有文本问题描述，图片类信息，正确答案，学生的不正确答案，解题步骤。\n任务分为  1：找到第一个错误步骤，2：错误分类，指标都是准确率。\u003c/p\u003e\n\u003cimg src=\"image-20250905153558820.png\" alt=\"image-20250905153558820\" style=\"zoom:67%;\" /\u003e\n\u003cp\u003e作者引入了个多智能体框架，分为三个部分，流程如下图。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e文本-图像一致性检测：判断图片和文字是否高度一致，避免使用图片识别功能，从而增强题目解读能力\u003c/li\u003e\n\u003cli\u003e公式-表格识别：用专门model将各种公式、表格等识别为文本形式\u003c/li\u003e\n\u003cli\u003e融合找错：将文本和转文本的图片信息融合为一个完整题目，并且让LLM完成上面具体两个任务\u003cimg src=\"image-20250905153953903.png\" alt=\"image-20250905153953903\" style=\"zoom:67%;\" /\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e实验结果\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e将该方法运用到多个多模态大模型，大部分都能提升准确率，但相较于人工还有很大的差距。\n\u003cimg alt=\"image-20250905154103167\" loading=\"lazy\" src=\"/posts/9%E6%9C%885%E6%97%A5%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/image-20250905154103167.png\"\u003e\u003c/p\u003e\n\u003cp\u003e论文写的浅显易懂，结构也很清晰，可惜本论文并未公布数据集。。。\u003c/p\u003e","title":"9.5 论文阅读"},{"content":"最近闲着无聊随便做了一个windows的语音唤醒助手，主要是闲平常要出门，或者不方便的时候（比如运动、躺床上的时候），可以叫一声电脑就做我想让他做的内容（可以连接LLM/GUI agent/MCP等等）。\n再加上现在GUIAgent发展的很快，网上还没有语音唤醒形式的链接，也就自己搭了一个出来。\n下面是这个项目的readme。\nWinAssistant – Windows 本地语音唤醒与自动化执行 一个在 Windows 上运行的本地语音助手：\n说出唤醒词 → 识别你的语音 → 自动执行自定义动作（脚本、GUI Agent、MCP 等）。 全离线（唤醒+识别均可离线），即插即用，优先使用耳机麦克风。 演示视频 https://github.com/user-attachments/assets/a48b8e94-8b95-46eb-9aa5-a4085c2341c4\n✨ 核心特性 多唤醒词可选 / 可自定义 内置多种常见唤醒词，也可替换为你训练的 .ppn 文件。\n本地唤醒：Picovoice Porcupine 轻量、低延迟、可靠，离线运行。\n语音识别：fast-whisper 内置去噪、VAD 端点检测，自动判断“用户是否说完”，可按需调节模型大小（速度/准确度权衡）。\n自动音频设备选择 自动选择可用的输入/输出设备，优先耳机。\n可插拔“处理态” 识别到文本后进入你的“处理态”（可自定义），例如：\n调用 MCP / 工具调用 触发 GUI Agent 执行脚本、打开应用、查询信息等 🧠 工作流 / 状态机 stateDiagram-v2 [*] --\u0026gt; 空闲态 空闲态 --\u0026gt; 唤醒态: 语音唤醒 唤醒态 --\u0026gt; 处理态: 用户语音结束 处理态 --\u0026gt; 空闲态 唤醒态 --\u0026gt; 空闲态: 用户长时间无应答 空闲态 --\u0026gt; 空闲态: （持续监听） 说明：唤醒后进入实时听写；若检测到长时间静音则回退到空闲态。\n📦 目录结构 WINASSISTANT/ ├─ model/ │ ├─ 小智.ppn # 自定义/内置唤醒词（Porcupine） │ └─ porcupine_params_zh.pv # 中文参数 ├─ music/ # 系统提示音 │ ├─ ok.wav │ ├─ sorry.wav │ └─ zai.wav ├─ utils/ │ ├─ player.py # 播放器：播放提示音/反馈 │ ├─ reader.py # 识别器：fast-whisper + VAD │ ├─ rouser.py # 唤醒：Porcupine 推理 │ └─ UIoperator.py # 处理态模板（可自定义） ├─ .env # 环境变量（见下） ├─ main.py # 入口：python main.py └─ requirements.txt # 依赖 🚀 快速开始 1) 环境准备 Windows 10/11 Python 3.9+（建议 64-bit） 麦克风 \u0026amp; 扬声器/耳机 git clone https://github.com/wanghai673/WinAssistant cd WINASSISTANT # 建议：创建虚拟环境 python -m venv .venv .\\.venv\\Scripts\\activate pip install -r requirements.txt 2) 申请 Picovoice Access Key 前往 https://picovoice.ai/ 免费获取 ACCESS_KEY。\n3) 配置 .env 在项目根目录创建或修改 .env：\nACCESS_KEY=你的AccessKey # 唤醒词（可选：小智, hey google, grasshopper, computer, americano, # bumblebee, hey barista, ok google, pico clock, porcupine, # picovoice, jarvis, terminator, grapefruit, blueberry, alexa, hey siri） ROUSE_WORD=小智 想用自定义唤醒词？把训练好的 .ppn 文件放到 model/ 并在代码/ENV 中指向它即可。\n4) 运行 python main.py 说出唤醒词（默认 “小智”）→ 说出命令 → 听到提示音并执行。\n🧩 自定义“处理态” 识别结果会进入你的“处理态”模块（示例：utils/UIoperator.py）。 你可以在这里：\n串接 MCP 工具调用 通过 GUI Agent 操作桌面 执行脚本 / 打开应用 / 系统自动化 回放 music/ok.wav / sorry.wav 作为反馈 建议将业务逻辑与语音管线解耦：保留 player / reader / rouser 作为通用能力层，处理态专注于“要做什么”。\n⚙️ 常用调优点 VAD/静音阈值：在 reader.py 中调整 MAX_SILENCE_SECS 等参数，影响“说完就停”的敏感度。 模型大小：根据机器性能切换 fast-whisper 模型（小模型更快，大模型更准）。 提示音屏蔽：通过 realtime_zh(..., beep_guard=0.5) 吞掉前 0.5s 系统“滴”声，避免影响识别。 音频设备：默认自动选择，优先耳机；如需固定设备，可在 player/reader 中指定设备索引。 🔐 隐私与本地化 唤醒与识别均可离线完成；音频不会上传到云端。 仅在你显式配置联网服务时才会产生外部调用。 🧪 简单示例（伪代码） # 极简示例：监听唤醒 → 识别 from utils.player import Player from utils.reader import Reader from utils.rouser import Rouser from pvrecorder import PvRecorder from dotenv import load_dotenv import os load_dotenv() ACCESS_KEY = os.getenv(\u0026#34;ACCESS_KEY\u0026#34;) ROUSE_WORD = os.getenv(\u0026#34;ROUSE_WORD\u0026#34;, \u0026#34;小智\u0026#34;) DEVICE_INDEX = -1 # 使用系统默认输入设备 rouser = Rouser(access_key=ACCESS_KEY, device_index=DEVICE_INDEX, keyword=ROUSE_WORD) player = Player() reader = Reader(device_index=DEVICE_INDEX) recorder = PvRecorder(device_index=DEVICE_INDEX, frame_length=rouser.porcupine.frame_length) recorder.start() print(f\u0026#34;正在监听唤醒词：『{ROUSE_WORD}』 (Ctrl+C 退出)\u0026#34;) while True: pcm = recorder.read() if rouser.process(pcm) \u0026gt;= 0: # 检测到唤醒 player.play_voice(block=True) # 提示音 text = reader.realtime_zh(rec_shared=recorder, beep_guard=0.0) if text: print(\u0026#34;识别文本：\u0026#34;, text) player.play_voice(block=True, type=\u0026#34;ok\u0026#34;) # 在这里根据 text 执行动作... else: player.play_voice(block=True, type=\u0026#34;sorry\u0026#34;) 🧯 故障排查 没有反应 / 设备占用：检查是否有其他应用占用麦克风；尝试在系统声音设置中启用设备。 识别慢：试用更小的 fast-whisper 模型或关闭其他高占用程序。 唤醒不灵敏：更换更清晰的唤醒词模型 .ppn，或在安静环境下测试。 提示音被识别进去：增大 beep_guard（如 0.7）。 🙌 致谢 Picovoice Porcupine（本地唤醒） fast-whisper（快速 ASR） ","permalink":"http://localhost:1313/posts/windows%E8%AF%AD%E9%9F%B3%E5%94%A4%E9%86%92%E5%8A%A9%E6%89%8B/","summary":"\u003cp\u003e最近闲着无聊随便做了一个\u003ca href=\"https://github.com/wanghai673/WinAssistant/\"\u003ewindows的语音唤醒助手\u003c/a\u003e，主要是闲平常要出门，或者不方便的时候（比如运动、躺床上的时候），可以叫一声电脑就做我想让他做的内容（可以连接LLM/GUI agent/MCP等等）。\u003c/p\u003e\n\u003cp\u003e再加上现在GUIAgent发展的很快，网上还没有语音唤醒形式的链接，也就自己搭了一个出来。\u003c/p\u003e\n\u003cp\u003e下面是这个项目的readme。\u003c/p\u003e\n\u003ch1 id=\"winassistant--windows-本地语音唤醒与自动化执行\"\u003eWinAssistant – Windows 本地语音唤醒与自动化执行\u003c/h1\u003e\n\u003cp\u003e一个在 \u003cstrong\u003eWindows\u003c/strong\u003e 上运行的本地语音助手：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e说出唤醒词 → 识别你的语音 → 自动执行自定义动作（脚本、GUI Agent、MCP 等）。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e全离线\u003c/strong\u003e（唤醒+识别均可离线），即插即用，优先使用耳机麦克风。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"演示视频\"\u003e演示视频\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/user-attachments/assets/a48b8e94-8b95-46eb-9aa5-a4085c2341c4\"\u003ehttps://github.com/user-attachments/assets/a48b8e94-8b95-46eb-9aa5-a4085c2341c4\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"-核心特性\"\u003e✨ 核心特性\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e多唤醒词可选 / 可自定义\u003c/strong\u003e\n内置多种常见唤醒词，也可替换为你训练的 \u003ccode\u003e.ppn\u003c/code\u003e 文件。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e本地唤醒：Picovoice Porcupine\u003c/strong\u003e\n轻量、低延迟、可靠，离线运行。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e语音识别：fast-whisper\u003c/strong\u003e\n内置\u003cstrong\u003e去噪\u003c/strong\u003e、\u003cstrong\u003eVAD 端点检测\u003c/strong\u003e，自动判断“用户是否说完”，可按需调节模型大小（速度/准确度权衡）。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e自动音频设备选择\u003c/strong\u003e\n自动选择可用的输入/输出设备，\u003cstrong\u003e优先耳机\u003c/strong\u003e。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e可插拔“处理态”\u003c/strong\u003e\n识别到文本后进入你的“处理态”（可自定义），例如：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e调用 MCP / 工具调用\u003c/li\u003e\n\u003cli\u003e触发 GUI Agent\u003c/li\u003e\n\u003cli\u003e执行脚本、打开应用、查询信息等\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"-工作流--状态机\"\u003e🧠 工作流 / 状态机\u003c/h2\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode class=\"language-mermaid\" data-lang=\"mermaid\"\u003estateDiagram-v2\n    [*] --\u0026gt; 空闲态\n    空闲态 --\u0026gt; 唤醒态: 语音唤醒\n    唤醒态 --\u0026gt; 处理态: 用户语音结束\n    处理态 --\u0026gt; 空闲态\n    唤醒态 --\u0026gt; 空闲态: 用户长时间无应答\n    空闲态 --\u0026gt; 空闲态: （持续监听）\n\u003c/code\u003e\u003c/pre\u003e\u003cblockquote\u003e\n\u003cp\u003e说明：唤醒后进入实时听写；若检测到\u003cstrong\u003e长时间静音\u003c/strong\u003e则回退到空闲态。\u003c/p\u003e","title":"Windows语音唤醒助手"},{"content":"之前看过很多成功学/心理学众所周知的道理，但是都是空头说话，没有任何数据证明，但这门课，能通过实验的方式展示结果，看到了让我更加信服（科学是最大的迷信hhh）。\n课程纠正了我非常多的偏见，让我对自己有了更清晰的认识，强烈推荐给大家！\n下面是The Science of Well-Being | Coursera的LLM的总结。\n1. 幸福的常见误解 1.1 “知道就够了”（G.I. Joe 谬误） 仅“知道道理”并不会自动改变行为；需要情境与练习把“知道”变“做到”。 1.2 找工作与被拒 被拒的痛苦通常没想的那样强与久，心理免疫系统会缓冲。 1.3 金钱与收入 年轻人的价值观更偏向“高收入为先”。 收入增长与主观幸福并非一一对应；整体幸福感在富足年代并未同步上扬。 超过某一阈值后，收入主要提升“生活评价”，对日常情绪的边际效用有限。 1.4 “酷东西”与物质主义 流行文化强化对豪车、名酒等的向往。 物质主义目标与更低的长期满意度相关。 1.5 真爱与婚姻 婚后幸福感常在几年内回落到基线（适应效应）。 1.6 完美身材/整形与完美成绩 减重或整形未必带来更好的长期心理健康或幸福。 人们普遍高估成绩变化带来的情绪涨落。 幸福并非被基因与环境“写死”，相当比例可由行为与思维方式塑造。 2. 我们为什么总是判断失准 2.1 误想（Miswanting） 对“未来会多喜欢/多讨厌”经常判断错误。 2.2 相对参照点 我们按比较而非绝对值评估自己：同侪收入、媒体/社交媒体的呈现、班级曲线、外貌对比等都会扭曲感受与选择。 2.3 适应力强 对“好事/坏事”都会逐渐习惯：收入提升、中彩票、婚姻等皆会回到常态。 2.4 忽视我们会适应 预测未来情绪时，容易“聚焦于单一事件”并忽略适应与其他生活面向，导致高估负面事件的持续影响。 3. 如何克服偏误（可操作策略） 3.1 重新定义“酷东西”：投资体验而非物质 把钱与精力优先投入能被分享与反复回味的体验（旅行、学习、共创）。 3.2 阻断/延缓适应 品味/回味（savoring）：刻意思考并记录正向时刻。 积极回忆 \u0026amp; 书写消化：写下负面事件并完成认知加工。 负向想象：设想“若没有这件好事会怎样”，提升珍惜度。 时间稀缺：把某些体验当作“最后一次”，增强投入。 感恩练习：数祝福、写感谢信、表达谢意。 重置参照点：有意切换比较标准，校准高/低参照引发的偏差。 打断消费：给愉悦体验加入“短暂停”，延长新鲜感。 4. 真正更有效的幸福来源 4.1 更好的“想要”（Part 1） 优势运用：识别并在工作中高频使用个人优势，提升满足与“天职感”。 心流（Flow）：挑战×能力匹配，带来深度专注与高质量体验。 成长型思维：相信能力可发展，更能从挫折中学习与精进。 4.2 更好的“想要”（Part 2 \u0026amp; 3） 善意与给予：随机善举、为他人花钱、助人使人更幸福（跨文化成立）。 社会连接：重视亲密与日常社交；与陌生人开启对话、共享体验。 时间富足：优先时间而非金钱；思考“我如何用时间与人相处？”。 冥想与正念：降低走神、提升幸福、工作记忆与社会连结感。 健康习惯：规律运动与高质量睡眠，稳定情绪与认知表现。 5. 把策略落地：从“知道”到“做到” 5.1 情境支持（让好行为“更顺手”） 把诱因放远、把好选择放近：远离随手零食，台面摆水果；为运动与阅读预先布置环境。 5.2 目标设定（从愿望到执行） 具体目标：定义清晰的量化标准与截止时间。 实施意图（If–Then）：为关键情境写下触发语句（例：“如果吃完午饭，就散步10分钟”）。 WOOP 技术：愿望（Wish）→成果（Outcome）→障碍（Obstacle）→计划（Plan）。 5.3 速查清单（一周可上手） 每周一次新方式运用你的前五优势；在岗尽量覆盖≥4个优势。 把钱优先用在体验/他人上；为娱乐安排小而频繁的享受并刻意中断。 每日感恩 3 件事＋每周一封感谢讯息。 正念/慈心冥想10–15 分钟，配合每周≥3次运动与固定就寝/起床。 社交优先：与同事/陌生人开启短聊，把体验与人分享。 为关键习惯写 3 条 If–Then，并用 WOOP 复盘障碍与应对。 6. 主要参考 6.1 认知与预测偏误 Santos \u0026amp; Gendler (2014). Knowing is half the battle? Edge. Gilbert \u0026amp; Wilson (2000). Miswanting: Some problems in the forecasting of future affective states. Levine et al. (2012). Accuracy and artifact: Reexamining the intensity bias in affective forecasting. Dunn et al. (2002). Location, location, location. Ayton et al. (2007). Affective forecasting: Why can\u0026rsquo;t people predict their emotions? Gilbert et al. (1998). Immune neglect… Gilbert (2007). Stumbling on Happiness. 6.2 金钱与价值观 Eagan et al. (2015). The American Freshman Survey. LinkedIn Survey (2014). What recent grads care the most about. Diener \u0026amp; Oishi (2000). Money and happiness… Myers (2000). The American Paradox. Lyubomirsky (2007). The How of Happiness. Kahneman \u0026amp; Deaton (2010). High income improves evaluation of life… New York Times. Economic diversity and student outcomes at Yale University. 6.3 参照点与社会比较 Medvec et al. (1995). Olympic medalists \u0026amp; counterfactuals. van Praag \u0026amp; Frijters (1999). Leyden approach. Clark \u0026amp; Oswald (1996). Satisfaction and comparison income. Solnick \u0026amp; Hemenway (1997). Positional concerns. Clark (2003). Unemployment as a social norm. O’Guinn \u0026amp; Shrum (1997). Television \u0026amp; consumer reality. Schor (1999). The Overspent American. Kuhn et al. (2011). Dutch Postcode Lottery. Kenrick et al. (1989; 1993). Attractiveness \u0026amp; comparison. Vogel et al. (2014). Social media \u0026amp; self-esteem. Burleigh \u0026amp; Meegan (2013). Keeping Up with the Joneses \u0026amp; justice. 6.4 适应与物质/体验 Brickman et al. (1978). Lottery winners \u0026amp; accident victims. Di Tella et al. (2010). Adaptation to income \u0026amp; status. Lucas et al. (2003). Adaptation to marriage. Boven \u0026amp; Gilovich (2003). To do or to have? Kumar et al. (2014). Anticipatory consumption of experiential purchases. Pchelin \u0026amp; Howell (2014). Hidden cost of value-seeking. Howell \u0026amp; Hill (2009). Mediators of experiential purchases. Nelson \u0026amp; Meyvis (2008). Interrupted consumption. Nelson et al. (2009). Commercial interruptions \u0026amp; TV. 6.5 优势/心流/心态与善意社交时间 Seligman (2004); Seligman et al. (2005). Signature strengths \u0026amp; interventions. Lavy \u0026amp; Littman-Ovadia (2017); Harzer \u0026amp; Ruch (2012). Strengths at work. Csikszentmihalyi (1992; 2008; 1999). Flow. Deci (1971); Dweck (2007); Grant \u0026amp; Dweck (2003); Blackwell et al. (2007); Mangels et al. (2006). Growth mindset。 Otake et al. (2006); Lyubomirsky (2005); Dunn (2014); Dunn et al. (2008); Aknin et al. (2013). Kindness \u0026amp; prosocial spending. Myers (2000); Diener \u0026amp; Seligman (2002); Epley (2014); Epley \u0026amp; Schroeder (2014); Boothby et al. (2014). Social connection. Whillans et al. (2016); Hershfield et al. (2016); Moligner (2010). Time over money. 6.6 正念、健康与执行 Killingsworth \u0026amp; Gilbert (2010); Mason et al. (2007); Brewer et al. (2011); Fredrickson et al. (2008); Hölzel et al. (2011); Mrazek et al. (2013); Hutcherson et al. (2008). Mind-wandering \u0026amp; meditation. Babyak et al. (2000); Hillman et al. (2008). Exercise \u0026amp; cognition. Dinges et al. (1997); Walker et al. (2002); Wagner et al. (2004); Huffington Post（睡眠图解）. Sleep \u0026amp; performance. Wansink et al. (2006; 2016). Situation support \u0026amp; default choices. Klein et al. (1990); Gollwitzer \u0026amp; Brandstätter (1997); Stadler \u0026amp; Oettingen (2010); Duckworth et al. (2013); Stadler et al. (2009). 目标与实施意图/WOOP。 ","permalink":"http://localhost:1313/posts/the_science_of_well-being_%E6%80%BB%E7%BB%93/","summary":"\u003cp\u003e之前看过很多成功学/心理学众所周知的道理，但是都是空头说话，没有任何数据证明，但这门课，能通过实验的方式展示结果，看到了让我更加信服（科学是最大的迷信hhh）。\u003c/p\u003e\n\u003cp\u003e课程纠正了我非常多的偏见，让我对自己有了更清晰的认识，强烈推荐给大家！\u003c/p\u003e\n\u003cp\u003e下面是\u003ca href=\"https://www.coursera.org/learn/the-science-of-well-being\"\u003eThe Science of Well-Being | Coursera\u003c/a\u003e的LLM的总结。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"1-幸福的常见误解\"\u003e1. 幸福的常见误解\u003c/h2\u003e\n\u003ch3 id=\"11-知道就够了gi-joe-谬误\"\u003e1.1 “知道就够了”（G.I. Joe 谬误）\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e仅“知道道理”并不会自动改变行为；需要情境与练习把“知道”变“做到”。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"12-找工作与被拒\"\u003e1.2 找工作与被拒\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e被拒的痛苦通常没想的那样强与久，心理免疫系统会缓冲。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"13-金钱与收入\"\u003e1.3 金钱与收入\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e年轻人的价值观更偏向“高收入为先”。\u003c/li\u003e\n\u003cli\u003e收入增长与主观幸福并非一一对应；整体幸福感在富足年代并未同步上扬。\u003c/li\u003e\n\u003cli\u003e超过某一阈值后，收入主要提升“生活评价”，对日常情绪的边际效用有限。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"14-酷东西与物质主义\"\u003e1.4 “酷东西”与物质主义\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e流行文化强化对豪车、名酒等的向往。\u003c/li\u003e\n\u003cli\u003e物质主义目标与更低的长期满意度相关。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"15-真爱与婚姻\"\u003e1.5 真爱与婚姻\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e婚后幸福感常在几年内回落到基线（适应效应）。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"16-完美身材整形与完美成绩\"\u003e1.6 完美身材/整形与完美成绩\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e减重或整形未必带来更好的长期心理健康或幸福。\u003c/li\u003e\n\u003cli\u003e人们普遍高估成绩变化带来的情绪涨落。\u003c/li\u003e\n\u003cli\u003e幸福并非被基因与环境“写死”，相当比例可由行为与思维方式塑造。\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"2-我们为什么总是判断失准\"\u003e2. 我们为什么总是判断失准\u003c/h2\u003e\n\u003ch3 id=\"21-误想miswanting\"\u003e2.1 误想（Miswanting）\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e对“未来会多喜欢/多讨厌”经常判断错误。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"22-相对参照点\"\u003e2.2 相对参照点\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e我们按比较而非绝对值评估自己：同侪收入、媒体/社交媒体的呈现、班级曲线、外貌对比等都会扭曲感受与选择。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"23-适应力强\"\u003e2.3 适应力强\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e对“好事/坏事”都会逐渐习惯：收入提升、中彩票、婚姻等皆会回到常态。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"24-忽视我们会适应\"\u003e2.4 忽视我们会适应\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e预测未来情绪时，容易“聚焦于单一事件”并忽略适应与其他生活面向，导致高估负面事件的持续影响。\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"3-如何克服偏误可操作策略\"\u003e3. 如何克服偏误（可操作策略）\u003c/h2\u003e\n\u003ch3 id=\"31-重新定义酷东西投资体验而非物质\"\u003e3.1 重新定义“酷东西”：投资体验而非物质\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e把钱与精力优先投入能被分享与反复回味的体验（旅行、学习、共创）。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"32-阻断延缓适应\"\u003e3.2 阻断/延缓适应\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e品味/回味（savoring）\u003c/strong\u003e：刻意思考并记录正向时刻。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e积极回忆 \u0026amp; 书写消化\u003c/strong\u003e：写下负面事件并完成认知加工。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e负向想象\u003c/strong\u003e：设想“若没有这件好事会怎样”，提升珍惜度。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e时间稀缺\u003c/strong\u003e：把某些体验当作“最后一次”，增强投入。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e感恩练习\u003c/strong\u003e：数祝福、写感谢信、表达谢意。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e重置参照点\u003c/strong\u003e：有意切换比较标准，校准高/低参照引发的偏差。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e打断消费\u003c/strong\u003e：给愉悦体验加入“短暂停”，延长新鲜感。\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"4-真正更有效的幸福来源\"\u003e4. 真正更有效的幸福来源\u003c/h2\u003e\n\u003ch3 id=\"41-更好的想要part-1\"\u003e4.1 更好的“想要”（Part 1）\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e优势运用\u003c/strong\u003e：识别并在工作中高频使用个人优势，提升满足与“天职感”。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e心流（Flow）\u003c/strong\u003e：挑战×能力匹配，带来深度专注与高质量体验。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e成长型思维\u003c/strong\u003e：相信能力可发展，更能从挫折中学习与精进。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"42-更好的想要part-2--3\"\u003e4.2 更好的“想要”（Part 2 \u0026amp; 3）\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e善意与给予\u003c/strong\u003e：随机善举、为他人花钱、助人使人更幸福（跨文化成立）。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e社会连接\u003c/strong\u003e：重视亲密与日常社交；与陌生人开启对话、共享体验。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e时间富足\u003c/strong\u003e：优先时间而非金钱；思考“我如何用时间与人相处？”。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e冥想与正念\u003c/strong\u003e：降低走神、提升幸福、工作记忆与社会连结感。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e健康习惯\u003c/strong\u003e：规律运动与高质量睡眠，稳定情绪与认知表现。\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"5-把策略落地从知道到做到\"\u003e5. 把策略落地：从“知道”到“做到”\u003c/h2\u003e\n\u003ch3 id=\"51-情境支持让好行为更顺手\"\u003e5.1 情境支持（让好行为“更顺手”）\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e把诱因放远、把好选择放近：远离随手零食，台面摆水果；为运动与阅读预先布置环境。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"52-目标设定从愿望到执行\"\u003e5.2 目标设定（从愿望到执行）\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e具体目标\u003c/strong\u003e：定义清晰的量化标准与截止时间。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e实施意图（If–Then）\u003c/strong\u003e：为关键情境写下触发语句（例：“如果吃完午饭，就散步10分钟”）。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eWOOP 技术\u003c/strong\u003e：愿望（Wish）→成果（Outcome）→障碍（Obstacle）→计划（Plan）。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"53-速查清单一周可上手\"\u003e5.3 速查清单（一周可上手）\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e每周\u003cstrong\u003e一次新方式\u003c/strong\u003e运用你的\u003cstrong\u003e前五优势\u003c/strong\u003e；在岗尽量覆盖≥4个优势。\u003c/li\u003e\n\u003cli\u003e把\u003cstrong\u003e钱\u003c/strong\u003e优先用在\u003cstrong\u003e体验/他人\u003c/strong\u003e上；为娱乐安排\u003cstrong\u003e小而频繁\u003c/strong\u003e的享受并\u003cstrong\u003e刻意中断\u003c/strong\u003e。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e每日感恩 3 件事\u003c/strong\u003e＋\u003cstrong\u003e每周一封感谢讯息\u003c/strong\u003e。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e正念/慈心冥想\u003c/strong\u003e10–15 分钟，配合\u003cstrong\u003e每周≥3次运动\u003c/strong\u003e与\u003cstrong\u003e固定就寝/起床\u003c/strong\u003e。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e社交优先\u003c/strong\u003e：与同事/陌生人开启短聊，把体验与人分享。\u003c/li\u003e\n\u003cli\u003e为关键习惯写 3 条 \u003cstrong\u003eIf–Then\u003c/strong\u003e，并用 \u003cstrong\u003eWOOP\u003c/strong\u003e 复盘障碍与应对。\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"6-主要参考\"\u003e6. 主要参考\u003c/h2\u003e\n\u003ch3 id=\"61-认知与预测偏误\"\u003e6.1 认知与预测偏误\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eSantos \u0026amp; Gendler (2014). Knowing is half the battle? Edge.\u003c/li\u003e\n\u003cli\u003eGilbert \u0026amp; Wilson (2000). Miswanting: Some problems in the forecasting of future affective states.\u003c/li\u003e\n\u003cli\u003eLevine et al. (2012). Accuracy and artifact: Reexamining the intensity bias in affective forecasting.\u003c/li\u003e\n\u003cli\u003eDunn et al. (2002). Location, location, location.\u003c/li\u003e\n\u003cli\u003eAyton et al. (2007). Affective forecasting: Why can\u0026rsquo;t people predict their emotions?\u003c/li\u003e\n\u003cli\u003eGilbert et al. (1998). Immune neglect…\u003c/li\u003e\n\u003cli\u003eGilbert (2007). \u003cem\u003eStumbling on Happiness\u003c/em\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"62-金钱与价值观\"\u003e6.2 金钱与价值观\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eEagan et al. (2015). \u003cem\u003eThe American Freshman Survey\u003c/em\u003e.\u003c/li\u003e\n\u003cli\u003eLinkedIn Survey (2014). What recent grads care the most about.\u003c/li\u003e\n\u003cli\u003eDiener \u0026amp; Oishi (2000). Money and happiness…\u003c/li\u003e\n\u003cli\u003eMyers (2000). \u003cem\u003eThe American Paradox\u003c/em\u003e.\u003c/li\u003e\n\u003cli\u003eLyubomirsky (2007). \u003cem\u003eThe How of Happiness\u003c/em\u003e.\u003c/li\u003e\n\u003cli\u003eKahneman \u0026amp; Deaton (2010). High income improves evaluation of life…\u003c/li\u003e\n\u003cli\u003eNew York Times. Economic diversity and student outcomes at Yale University.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"63-参照点与社会比较\"\u003e6.3 参照点与社会比较\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eMedvec et al. (1995). Olympic medalists \u0026amp; counterfactuals.\u003c/li\u003e\n\u003cli\u003evan Praag \u0026amp; Frijters (1999). Leyden approach.\u003c/li\u003e\n\u003cli\u003eClark \u0026amp; Oswald (1996). Satisfaction and comparison income.\u003c/li\u003e\n\u003cli\u003eSolnick \u0026amp; Hemenway (1997). Positional concerns.\u003c/li\u003e\n\u003cli\u003eClark (2003). Unemployment as a social norm.\u003c/li\u003e\n\u003cli\u003eO’Guinn \u0026amp; Shrum (1997). Television \u0026amp; consumer reality.\u003c/li\u003e\n\u003cli\u003eSchor (1999). \u003cem\u003eThe Overspent American\u003c/em\u003e.\u003c/li\u003e\n\u003cli\u003eKuhn et al. (2011). Dutch Postcode Lottery.\u003c/li\u003e\n\u003cli\u003eKenrick et al. (1989; 1993). Attractiveness \u0026amp; comparison.\u003c/li\u003e\n\u003cli\u003eVogel et al. (2014). Social media \u0026amp; self-esteem.\u003c/li\u003e\n\u003cli\u003eBurleigh \u0026amp; Meegan (2013). Keeping Up with the Joneses \u0026amp; justice.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"64-适应与物质体验\"\u003e6.4 适应与物质/体验\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eBrickman et al. (1978). Lottery winners \u0026amp; accident victims.\u003c/li\u003e\n\u003cli\u003eDi Tella et al. (2010). Adaptation to income \u0026amp; status.\u003c/li\u003e\n\u003cli\u003eLucas et al. (2003). Adaptation to marriage.\u003c/li\u003e\n\u003cli\u003eBoven \u0026amp; Gilovich (2003). To do or to have?\u003c/li\u003e\n\u003cli\u003eKumar et al. (2014). Anticipatory consumption of experiential purchases.\u003c/li\u003e\n\u003cli\u003ePchelin \u0026amp; Howell (2014). Hidden cost of value-seeking.\u003c/li\u003e\n\u003cli\u003eHowell \u0026amp; Hill (2009). Mediators of experiential purchases.\u003c/li\u003e\n\u003cli\u003eNelson \u0026amp; Meyvis (2008). Interrupted consumption.\u003c/li\u003e\n\u003cli\u003eNelson et al. (2009). Commercial interruptions \u0026amp; TV.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"65-优势心流心态与善意社交时间\"\u003e6.5 优势/心流/心态与善意社交时间\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eSeligman (2004); Seligman et al. (2005). Signature strengths \u0026amp; interventions.\u003c/li\u003e\n\u003cli\u003eLavy \u0026amp; Littman-Ovadia (2017); Harzer \u0026amp; Ruch (2012). Strengths at work.\u003c/li\u003e\n\u003cli\u003eCsikszentmihalyi (1992; 2008; 1999). Flow.\u003c/li\u003e\n\u003cli\u003eDeci (1971); Dweck (2007); Grant \u0026amp; Dweck (2003); Blackwell et al. (2007); Mangels et al. (2006). Growth mindset。\u003c/li\u003e\n\u003cli\u003eOtake et al. (2006); Lyubomirsky (2005); Dunn (2014); Dunn et al. (2008); Aknin et al. (2013). Kindness \u0026amp; prosocial spending.\u003c/li\u003e\n\u003cli\u003eMyers (2000); Diener \u0026amp; Seligman (2002); Epley (2014); Epley \u0026amp; Schroeder (2014); Boothby et al. (2014). Social connection.\u003c/li\u003e\n\u003cli\u003eWhillans et al. (2016); Hershfield et al. (2016); Moligner (2010). Time over money.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"66-正念健康与执行\"\u003e6.6 正念、健康与执行\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eKillingsworth \u0026amp; Gilbert (2010); Mason et al. (2007); Brewer et al. (2011); Fredrickson et al. (2008); Hölzel et al. (2011); Mrazek et al. (2013); Hutcherson et al. (2008). Mind-wandering \u0026amp; meditation.\u003c/li\u003e\n\u003cli\u003eBabyak et al. (2000); Hillman et al. (2008). Exercise \u0026amp; cognition.\u003c/li\u003e\n\u003cli\u003eDinges et al. (1997); Walker et al. (2002); Wagner et al. (2004); \u003cem\u003eHuffington Post\u003c/em\u003e（睡眠图解）. Sleep \u0026amp; performance.\u003c/li\u003e\n\u003cli\u003eWansink et al. (2006; 2016). Situation support \u0026amp; default choices.\u003c/li\u003e\n\u003cli\u003eKlein et al. (1990); Gollwitzer \u0026amp; Brandstätter (1997); Stadler \u0026amp; Oettingen (2010); Duckworth et al. (2013); Stadler et al. (2009). 目标与实施意图/WOOP。\u003c/li\u003e\n\u003c/ul\u003e","title":"耶鲁大学幸福科学课程总结"},{"content":"最近都在广泛学习一些有趣的内容，主要是通过coursera平台。在家呆了2个多月了，也不知道未来啥方向，目前也是有些迷茫的状态，还是学些东西充实下自己吧，搜寻一下感兴趣的东东。\ncoursera平台类似于国外的mooc，国内外还有好多这样的平台，如中国大学mooc、bilibili大学、网易云课等等。coursera需要付费会员才能观看课程，而且只能通过国外信用卡付款（无）。于是，我在淘宝一搜，这么多卖号，而且很便宜，86半年，立马充值了一波。\n有了平台，我立马重新在coursera里，拾起深度学习的基础知识，吴恩达的课程。之前只听过，在coursera认真地观看，还是感觉受益匪浅，毕竟有作业有互动，感觉b站还是差点味道。\n现在主要看了深度学习专项课程的前3个：\n其实就相当于复习了一下之前在李沐动手学深度学习的内容。\n然后光看深度学习也有些乏味，我在网上搜索coursera有没有其他好课程，打开了一个课程排名，类似于垃圾小网站的那种：\n然后最近在看幸福科学，才刚开始看，讲的是如何变得幸福，通过科学的方式，感觉讲的还挺好的，在实验的加持下，科学成为人们可以坚持最大的迷信，hhh，但是还是要有反驳精神，感觉很多科学实验严谨性还是有些欠缺。\n之后的日子，想了解一下金融相关的知识，挺感兴趣的。马上要开学了，5555，希望能保持学习一些课外内容的习惯。还有，运动也要保持，在家和爸妈打了一个暑假的乒乓球，每日锻炼~\n","permalink":"http://localhost:1313/posts/%E6%9C%80%E8%BF%91%E5%9C%A8%E5%81%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E4%BA%8B/","summary":"\u003cp\u003e最近都在广泛学习一些有趣的内容，主要是通过coursera平台。在家呆了2个多月了，也不知道未来啥方向，目前也是有些迷茫的状态，还是学些东西充实下自己吧，搜寻一下感兴趣的东东。\u003c/p\u003e\n\u003cp\u003ecoursera平台类似于国外的mooc，国内外还有好多这样的平台，如中国大学mooc、bilibili大学、网易云课等等。coursera需要付费会员才能观看课程，而且只能通过国外信用卡付款（无）。于是，我在淘宝一搜，这么多卖号，而且很便宜，86半年，立马充值了一波。\u003c/p\u003e\n\u003cp\u003e有了平台，我立马重新在coursera里，拾起深度学习的基础知识，吴恩达的课程。之前只听过，在coursera认真地观看，还是感觉受益匪浅，毕竟有作业有互动，感觉b站还是差点味道。\u003c/p\u003e\n\u003cp\u003e现在主要看了深度学习专项课程的前3个：\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"233\" loading=\"lazy\" src=\"/posts/%E6%9C%80%E8%BF%91%E5%9C%A8%E5%81%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E4%BA%8B/image-20250825155253827.png\"\u003e\u003c/p\u003e\n\u003cp\u003e其实就相当于复习了一下之前在李沐动手学深度学习的内容。\u003c/p\u003e\n\u003cp\u003e然后光看深度学习也有些乏味，我在网上搜索coursera有没有其他好课程，打开了一个课程排名，类似于垃圾小网站的那种：\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"2333\" loading=\"lazy\" src=\"/posts/%E6%9C%80%E8%BF%91%E5%9C%A8%E5%81%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E4%BA%8B/image-20250825155452140.png\"\u003e\u003c/p\u003e\n\u003cp\u003e然后最近在看幸福科学，才刚开始看，讲的是如何变得幸福，通过科学的方式，感觉讲的还挺好的，在实验的加持下，科学成为人们可以坚持最大的迷信，hhh，但是还是要有反驳精神，感觉很多科学实验严谨性还是有些欠缺。\u003c/p\u003e\n\u003cp\u003e之后的日子，想了解一下金融相关的知识，挺感兴趣的。马上要开学了，5555，希望能保持学习一些课外内容的习惯。还有，运动也要保持，在家和爸妈打了一个暑假的乒乓球，每日锻炼~\u003c/p\u003e","title":"最近在做的一些事"},{"content":"softmax是一个经典的多分类概率分布的公式，有n个类，softmax公式如下， $$ \\text{softmax}(z)_j = \\frac{e^{z_j}}{\\sum_{i=1}^n e^{z_i}}, \\quad j = 1, 2, \\dots, n $$ 首先，考虑一个样本每个类的预测分数做一个softmax，转换成每类预测的概率形式。\n$$ a^{[L]} = \\text{softmax}(z^{[L]}) $$$$ \\hat{y} = a^{[L]}\\quad $$然后，利用样本标签，结合极大似然估计的损失函数如下。 $$ L(\\hat{y}, y) = - \\sum_{i=1}^{n} y_i \\log(\\hat{y}_i) $$由于需要做反向传播，我们想求 $\\frac{\\partial L}{\\partial z^{[L]}}$，也就是做完softmax的前的偏导数。\n假设 $y$ 的分类为 $1$，则 $y_1 = 1$，其余 $y_j = 0\\ (j\\neq 1)$，$y=[1,0,.....,0]$ 则有， $$ L(\\hat{y}, y) = -\\log(\\hat{y}_1) $$$$ L(\\hat{y}, y) = - \\ln \\left( \\frac{e^{z_1^{[L]}}}{e^{z_1^{[L]}} + e^{z_2^{[L]}} + \\cdots + e^{z_n^{[L]}}} \\right), \\quad S = e^{z_1^{[L]}} + e^{z_2^{[L]}} + \\cdots + e^{z_n^{[L]}} $$接下来求 $Z^{[L]}$ 的偏导， $$ \\frac{\\partial L}{\\partial z^{[L]}_1} = -\\frac{S}{e^{z^{[L]}_1}} \\cdot \\frac{e^{z^{[L]}_1} \\cdot S - \\big(e^{z^{[L]}_1}\\big)^2}{S^2} = \\frac{e^{z^{[L]}_1}}{S} - 1 $$$$ \\frac{\\partial L}{\\partial z^{[L]}_j} = - \\frac{S}{e^{z^{[L]}_1}} \\cdot \\frac{-e^{z^{[L]}_1} \\cdot e^{z^{[L]}_j}}{S^2} = \\frac{e^{z^{[L]}_j}}{S}, \\quad j \\neq 1 $$因为， $$ a_j^{[L]} = \\frac{e^{z_j^{[L]}}}{S}, $$ 所以， $$ \\frac{\\partial L}{\\partial z^{[L]}_1} = a_1^{[L]} - 1 $$$$ \\frac{\\partial L}{\\partial z^{[L]}_j} = a_j^{[L]}, \\quad (j \\neq 1) $$由于不同分类标签的对称性，从而得到最终化简结果， $$ \\frac{\\partial L}{\\partial z^{[L]}} = \\hat{y} - y $$ 对于多样本，每个样本间独立，则有， $$ \\frac{\\partial L}{\\partial Z^{[L]}} = \\hat{Y} - Y $$","permalink":"http://localhost:1313/posts/softmax%E7%9A%84%E5%AF%BC%E6%95%B0%E6%8E%A8%E5%AF%BC/","summary":"\u003cp\u003esoftmax是一个经典的多分类概率分布的公式，有n个类，softmax公式如下，\n\u003c/p\u003e\n$$\n\\text{softmax}(z)_j = \\frac{e^{z_j}}{\\sum_{i=1}^n  e^{z_i}}, \\quad j = 1, 2, \\dots, n\n$$\u003cp\u003e\n首先，考虑一个样本每个类的预测分数做一个softmax，转换成每类预测的概率形式。\u003c/p\u003e\n$$\na^{[L]} = \\text{softmax}(z^{[L]})\n$$$$\n\\hat{y} = a^{[L]}\\quad\n$$\u003cp\u003e然后，利用样本标签，结合极大似然估计的损失函数如下。\n\u003c/p\u003e\n$$\nL(\\hat{y}, y) = - \\sum_{i=1}^{n} y_i \\log(\\hat{y}_i)\n$$\u003cp\u003e由于需要做反向传播，我们想求 $\\frac{\\partial L}{\\partial z^{[L]}}$，也就是做完softmax的前的偏导数。\u003c/p\u003e\n\u003cp\u003e假设 $y$ 的分类为 $1$，则 $y_1 = 1$，其余 $y_j = 0\\ (j\\neq 1)$，$y=[1,0,.....,0]$\n则有，\n\u003c/p\u003e\n$$\nL(\\hat{y}, y) = -\\log(\\hat{y}_1)\n$$$$\nL(\\hat{y}, y) = - \\ln \\left( \\frac{e^{z_1^{[L]}}}{e^{z_1^{[L]}} + e^{z_2^{[L]}} + \\cdots + e^{z_n^{[L]}}} \\right),\n\\quad S = e^{z_1^{[L]}} + e^{z_2^{[L]}} + \\cdots + e^{z_n^{[L]}}\n$$\u003cp\u003e接下来求 $Z^{[L]}$ 的偏导，\n\u003c/p\u003e","title":"Softmax的反向传播推导"},{"content":"\n最近在重新回顾深度学习相关基础，之前大概过了一遍李沐的动手学深度学习，但很多内容还一知半解， 感觉网上课程难度曲线还是不太平滑。\n无意间看到 Coursera平台，在淘宝上花了80买了个半年号，仿佛打开新世界了，第一次看到了原来真的有课程能把深度学习的学习曲线 弄的这么平滑的，爱了，有点像算法竞赛的acwing、牛客。感觉b站确实不错，但是反馈和互动肯定远远比不上Coursera的。\n现在刚学完第一门课程，并手动设计并实现了多层卷积神经网络（只用到numpy），在这里记录一下forward/back propagation的数学知识（主要是线性代数）。\n正向传播 非常简单易懂，就是矩阵乘法。\n反向传播 引理一 搞懂这个引理反向传播就差不多弄懂了，求哪个偏导，固定某行/列值算贡献 就好求了（A固定行，B固定列），因为矩阵乘法是B的列与A的行做点积。\n以上就是神经网络里的线性代数的一些知识，其实不需要太多基础弄得矩阵乘法，和求导链式法则即可手写神经网络。\n","permalink":"http://localhost:1313/posts/%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC/","summary":"\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC/2.png\"\u003e\u003c/p\u003e\n\u003cp\u003e最近在重新回顾深度学习相关基础，之前大概过了一遍李沐的动手学深度学习，但很多内容还一知半解，\n感觉网上课程难度曲线还是不太平滑。\u003c/p\u003e\n\u003cp\u003e无意间看到 \u003ca href=\"https://www.coursera.org/\"\u003eCoursera平台\u003c/a\u003e，在淘宝上花了80买了个半年号，仿佛打开新世界了，第一次看到了原来真的有课程能把深度学习的学习曲线\n弄的这么平滑的，爱了，有点像算法竞赛的acwing、牛客。感觉b站确实不错，但是反馈和互动肯定远远比不上Coursera的。\u003c/p\u003e\n\u003cp\u003e现在刚学完第一门课程，并手动设计并实现了多层卷积神经网络（只用到numpy），在这里记录一下forward/back propagation的数学知识（主要是线性代数）。\u003c/p\u003e\n\u003ch4 id=\"正向传播\"\u003e正向传播\u003c/h4\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC/%281%29.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003e非常简单易懂，就是矩阵乘法。\u003c/p\u003e\n\u003ch4 id=\"反向传播\"\u003e反向传播\u003c/h4\u003e\n\u003ch5 id=\"引理一\"\u003e引理一\u003c/h5\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC/%282%29.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC/%283%29.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003e搞懂这个引理反向传播就差不多弄懂了，求哪个偏导，固定某行/列值算贡献 就好求了（A固定行，B固定列），因为矩阵乘法是B的列与A的行做点积。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC/%284%29.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003e以上就是神经网络里的线性代数的一些知识，其实不需要太多基础弄得矩阵乘法，和求导链式法则即可手写神经网络。\u003c/p\u003e","title":"神经网络反向传播 数学推导"},{"content":"工具介绍 Hugo 简介：Hugo 是一个用 Go 语言编写的静态网站生成器。它以极快的生成速度著称，可以在几秒内构建上千页面。\n特点：\n不依赖数据库，所有页面都是静态文件，部署简单且性能高。 支持 Markdown 写作，适合博客和文档站点。 拥有强大的模板系统和主题生态。 跨平台运行（Windows、Linux、macOS）。 PaperMod 简介：PaperMod 是 Hugo 社区里非常流行的一个 简洁、现代的主题，灵感来自 Google Material Design。\n特点：\n设计简洁清爽，注重阅读体验。 自带夜间模式、搜索、标签分类等功能。 对 SEO 和性能友好，开箱即用。 支持高度自定义，比如文章目录、社交链接、评论系统等。 👉 总结：Hugo 是建站工具，PaperMod 是在 Hugo 上常用的主题之一。\nStep 1 按照下面视频安装hugo+papermod，搭建demo\n【雷】Hugo + Github免费搭建博客，并实现自动化部署\nStep 2 配置papermod主题，结合大语言模型，想要什么功能直接询问即可，并修改配置文件，主题大部分都是配有相关功能的。\n","permalink":"http://localhost:1313/posts/hugo+paermod%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%95%99%E7%A8%8B/","summary":"\u003ch3 id=\"工具介绍\"\u003e工具介绍\u003c/h3\u003e\n\u003ch4 id=\"hugo\"\u003eHugo\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e简介\u003c/strong\u003e：Hugo 是一个用 Go 语言编写的\u003cstrong\u003e静态网站生成器\u003c/strong\u003e。它以极快的生成速度著称，可以在几秒内构建上千页面。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e特点\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e不依赖数据库，所有页面都是静态文件，部署简单且性能高。\u003c/li\u003e\n\u003cli\u003e支持 Markdown 写作，适合博客和文档站点。\u003c/li\u003e\n\u003cli\u003e拥有强大的模板系统和主题生态。\u003c/li\u003e\n\u003cli\u003e跨平台运行（Windows、Linux、macOS）。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"papermod\"\u003ePaperMod\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e简介\u003c/strong\u003e：PaperMod 是 Hugo 社区里非常流行的一个 \u003cstrong\u003e简洁、现代的主题\u003c/strong\u003e，灵感来自 Google Material Design。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e特点\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e设计简洁清爽，注重阅读体验。\u003c/li\u003e\n\u003cli\u003e自带夜间模式、搜索、标签分类等功能。\u003c/li\u003e\n\u003cli\u003e对 SEO 和性能友好，开箱即用。\u003c/li\u003e\n\u003cli\u003e支持高度自定义，比如文章目录、社交链接、评论系统等。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e👉 总结：\u003cstrong\u003eHugo\u003c/strong\u003e 是建站工具，\u003cstrong\u003ePaperMod\u003c/strong\u003e 是在 Hugo 上常用的主题之一。\u003c/p\u003e\n\u003ch3 id=\"step-1\"\u003eStep 1\u003c/h3\u003e\n\u003cp\u003e按照下面视频安装hugo+papermod，搭建demo\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://www.bilibili.com/video/BV1bovfeaEtQ?vd_source=89574dec834a4f547f86ccea8df6514e\"\u003e【雷】Hugo + Github免费搭建博客，并实现自动化部署\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id=\"step-2\"\u003eStep 2\u003c/h3\u003e\n\u003cp\u003e配置papermod主题，结合大语言模型，想要什么功能直接询问即可，并修改配置文件，主题大部分都是配有相关功能的。\u003c/p\u003e","title":"hugo+papermod博客搭建教程"},{"content":"你好，我是 wanghai673，一名正在攻读 计算机科学与技术 的研究生（研 0），本科毕业于东华大学，目前就读于华东师范大学。\n💻 编程语言：C++、Python、Java\n🔍 研究兴趣：深度学习、大语言模型、智能体\n🏆 竞赛经历：\nICPC 亚洲区域赛 金奖（第 49 届） 蓝桥杯全国总决赛 一等奖（全国第 6 名） 百度之星全国总决赛 金奖 多次 ICPC/CCPC 银奖 上海市大学生程序设计竞赛 一等奖 我正在不断学习和提升自己，期待将所学应用于实际问题。如果有相关的 实习机会 或者 研究合作，非常欢迎联系我。\n📫 联系方式：微信、邮件\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e你好，我是 \u003cstrong\u003ewanghai673\u003c/strong\u003e，一名正在攻读 \u003cstrong\u003e计算机科学与技术\u003c/strong\u003e 的研究生（研 0），本科毕业于东华大学，目前就读于华东师范大学。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e💻 编程语言：C++、Python、Java\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e🔍 研究兴趣：深度学习、大语言模型、智能体\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e🏆 竞赛经历：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eICPC 亚洲区域赛 \u003cstrong\u003e金奖（第 49 届）\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e蓝桥杯全国总决赛 \u003cstrong\u003e一等奖（全国第 6 名）\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e百度之星全国总决赛 \u003cstrong\u003e金奖\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e多次 ICPC/CCPC \u003cstrong\u003e银奖\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e上海市大学生程序设计竞赛 \u003cstrong\u003e一等奖\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e我正在不断学习和提升自己，期待将所学应用于实际问题。如果有相关的 \u003cstrong\u003e实习机会\u003c/strong\u003e 或者 \u003cstrong\u003e研究合作\u003c/strong\u003e，非常欢迎联系我。\u003c/p\u003e\n\u003cp\u003e📫 联系方式：\u003ca href=\"wechat.jpg\"\u003e微信\u003c/a\u003e、\u003ca href=\"https://mail.qq.com/cgi-bin/qm_share?t=qm_mailme\u0026amp;email=1154103986@qq.com\"\u003e邮件\u003c/a\u003e\u003c/p\u003e","title":"关于"}]