[{"content":"最近都在广泛学习一些有趣的内容，主要是通过coursera平台。在家呆了2个多月了，也不知道未来啥方向，目前也是有些迷茫的状态，还是学些东西充实下自己吧，搜寻一下感兴趣的东东。\ncoursera平台类似于国外的mooc，国内外还有好多这样的平台，如中国大学mooc、bilibili大学、网易云课等等。coursera需要付费会员才能观看课程，而且只能通过国外信用卡付款（无）。于是，我在淘宝一搜，这么多卖号，而且很便宜，86半年，立马充值了一波。\n有了平台，我立马重新在coursera里，拾起深度学习的基础知识，吴恩达的课程。之前只听过，在coursera认真地观看，还是感觉受益匪浅，毕竟有作业有互动，感觉b站还是差点味道。\n现在主要看了深度学习专项课程的前3个：\n其实就相当于复习了一下之前在李沐动手学深度学习的内容。\n然后光看深度学习也有些乏味，我在网上搜索coursera有没有其他好课程，打开了一个课程排名，类似于垃圾小网站的那种：\n然后最近在看幸福科学，才刚开始看，讲的是如何变得幸福，通过科学的方式，感觉讲的还挺好的，在实验的加持下，科学成为人们可以坚持最大的迷信，hhh，但是还是要有反驳精神，感觉很多科学实验严谨性还是有些欠缺。\n之后的日子，想了解一下金融相关的知识，挺感兴趣的。马上要开学了，5555，希望能保持学习一些课外内容的习惯。还有，运动也要保持，在家和爸妈打了一个暑假的乒乓球，每日锻炼~\n","permalink":"http://localhost:52364/posts/%E6%9C%80%E8%BF%91%E5%9C%A8%E5%81%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E4%BA%8B/","summary":"\u003cp\u003e最近都在广泛学习一些有趣的内容，主要是通过coursera平台。在家呆了2个多月了，也不知道未来啥方向，目前也是有些迷茫的状态，还是学些东西充实下自己吧，搜寻一下感兴趣的东东。\u003c/p\u003e\n\u003cp\u003ecoursera平台类似于国外的mooc，国内外还有好多这样的平台，如中国大学mooc、bilibili大学、网易云课等等。coursera需要付费会员才能观看课程，而且只能通过国外信用卡付款（无）。于是，我在淘宝一搜，这么多卖号，而且很便宜，86半年，立马充值了一波。\u003c/p\u003e\n\u003cp\u003e有了平台，我立马重新在coursera里，拾起深度学习的基础知识，吴恩达的课程。之前只听过，在coursera认真地观看，还是感觉受益匪浅，毕竟有作业有互动，感觉b站还是差点味道。\u003c/p\u003e\n\u003cp\u003e现在主要看了深度学习专项课程的前3个：\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"233\" loading=\"lazy\" src=\"/posts/%E6%9C%80%E8%BF%91%E5%9C%A8%E5%81%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E4%BA%8B/image-20250825155253827.png\"\u003e\u003c/p\u003e\n\u003cp\u003e其实就相当于复习了一下之前在李沐动手学深度学习的内容。\u003c/p\u003e\n\u003cp\u003e然后光看深度学习也有些乏味，我在网上搜索coursera有没有其他好课程，打开了一个课程排名，类似于垃圾小网站的那种：\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"2333\" loading=\"lazy\" src=\"/posts/%E6%9C%80%E8%BF%91%E5%9C%A8%E5%81%9A%E7%9A%84%E4%B8%80%E4%BA%9B%E4%BA%8B/image-20250825155452140.png\"\u003e\u003c/p\u003e\n\u003cp\u003e然后最近在看幸福科学，才刚开始看，讲的是如何变得幸福，通过科学的方式，感觉讲的还挺好的，在实验的加持下，科学成为人们可以坚持最大的迷信，hhh，但是还是要有反驳精神，感觉很多科学实验严谨性还是有些欠缺。\u003c/p\u003e\n\u003cp\u003e之后的日子，想了解一下金融相关的知识，挺感兴趣的。马上要开学了，5555，希望能保持学习一些课外内容的习惯。还有，运动也要保持，在家和爸妈打了一个暑假的乒乓球，每日锻炼~\u003c/p\u003e","title":"最近在做的一些事"},{"content":"softmax是一个经典的多分类概率分布的公式，有n个类，softmax公式如下， $$ \\text{softmax}(z)_j = \\frac{e^{z_j}}{\\sum_{i=1}^n e^{z_i}}, \\quad j = 1, 2, \\dots, n $$ 首先，考虑一个样本每个类的预测分数做一个softmax，转换成每类预测的概率形式。\n$$ a^{[L]} = \\text{softmax}(z^{[L]}) $$$$ \\hat{y} = a^{[L]}\\quad $$然后，利用样本标签，结合极大似然估计的损失函数如下。 $$ L(\\hat{y}, y) = - \\sum_{i=1}^{n} y_i \\log(\\hat{y}_i) $$由于需要做反向传播，我们想求 $\\frac{\\partial L}{\\partial z^{[L]}}$，也就是做完softmax的前的偏导数。\n假设 $y$ 的分类为 $1$，则 $y_1 = 1$，其余 $y_j = 0\\ (j\\neq 1)$，$y=[1,0,.....,0]$ 则有， $$ L(\\hat{y}, y) = -\\log(\\hat{y}_1) $$$$ L(\\hat{y}, y) = - \\ln \\left( \\frac{e^{z_1^{[L]}}}{e^{z_1^{[L]}} + e^{z_2^{[L]}} + \\cdots + e^{z_n^{[L]}}} \\right), \\quad S = e^{z_1^{[L]}} + e^{z_2^{[L]}} + \\cdots + e^{z_n^{[L]}} $$接下来求 $Z^{[L]}$ 的偏导， $$ \\frac{\\partial L}{\\partial z^{[L]}_1} = -\\frac{S}{e^{z^{[L]}_1}} \\cdot \\frac{e^{z^{[L]}_1} \\cdot S - \\big(e^{z^{[L]}_1}\\big)^2}{S^2} = \\frac{e^{z^{[L]}_1}}{S} - 1 $$$$ \\frac{\\partial L}{\\partial z^{[L]}_j} = - \\frac{S}{e^{z^{[L]}_1}} \\cdot \\frac{-e^{z^{[L]}_1} \\cdot e^{z^{[L]}_j}}{S^2} = \\frac{e^{z^{[L]}_j}}{S}, \\quad j \\neq 1 $$因为， $$ a_j^{[L]} = \\frac{e^{z_j^{[L]}}}{S}, $$ 所以， $$ \\frac{\\partial L}{\\partial z^{[L]}_1} = a_1^{[L]} - 1 $$$$ \\frac{\\partial L}{\\partial z^{[L]}_j} = a_j^{[L]}, \\quad (j \\neq 1) $$由于不同分类标签的对称性，从而得到最终化简结果， $$ \\frac{\\partial L}{\\partial z^{[L]}} = \\hat{y} - y $$ 对于多样本，每个样本间独立，则有， $$ \\frac{\\partial L}{\\partial Z^{[L]}} = \\hat{Y} - Y $$","permalink":"http://localhost:52364/posts/softmax%E7%9A%84%E5%AF%BC%E6%95%B0%E6%8E%A8%E5%AF%BC/","summary":"\u003cp\u003esoftmax是一个经典的多分类概率分布的公式，有n个类，softmax公式如下，\n\u003c/p\u003e\n$$\n\\text{softmax}(z)_j = \\frac{e^{z_j}}{\\sum_{i=1}^n  e^{z_i}}, \\quad j = 1, 2, \\dots, n\n$$\u003cp\u003e\n首先，考虑一个样本每个类的预测分数做一个softmax，转换成每类预测的概率形式。\u003c/p\u003e\n$$\na^{[L]} = \\text{softmax}(z^{[L]})\n$$$$\n\\hat{y} = a^{[L]}\\quad\n$$\u003cp\u003e然后，利用样本标签，结合极大似然估计的损失函数如下。\n\u003c/p\u003e\n$$\nL(\\hat{y}, y) = - \\sum_{i=1}^{n} y_i \\log(\\hat{y}_i)\n$$\u003cp\u003e由于需要做反向传播，我们想求 $\\frac{\\partial L}{\\partial z^{[L]}}$，也就是做完softmax的前的偏导数。\u003c/p\u003e\n\u003cp\u003e假设 $y$ 的分类为 $1$，则 $y_1 = 1$，其余 $y_j = 0\\ (j\\neq 1)$，$y=[1,0,.....,0]$\n则有，\n\u003c/p\u003e\n$$\nL(\\hat{y}, y) = -\\log(\\hat{y}_1)\n$$$$\nL(\\hat{y}, y) = - \\ln \\left( \\frac{e^{z_1^{[L]}}}{e^{z_1^{[L]}} + e^{z_2^{[L]}} + \\cdots + e^{z_n^{[L]}}} \\right),\n\\quad S = e^{z_1^{[L]}} + e^{z_2^{[L]}} + \\cdots + e^{z_n^{[L]}}\n$$\u003cp\u003e接下来求 $Z^{[L]}$ 的偏导，\n\u003c/p\u003e","title":"Softmax的反向传播推导"},{"content":"\n最近在重新回顾深度学习相关基础，之前大概过了一遍李沐的动手学深度学习，但很多内容还一知半解， 感觉网上课程难度曲线还是不太平滑。\n无意间看到 Coursera平台，在淘宝上花了80买了个半年号，仿佛打开新世界了，第一次看到了原来真的有课程能把深度学习的学习曲线 弄的这么平滑的，爱了，有点像算法竞赛的acwing、牛客。感觉b站确实不错，但是反馈和互动肯定远远比不上Coursera的。\n现在刚学完第一门课程，并手动设计并实现了多层卷积神经网络（只用到numpy），在这里记录一下forward/back propagation的数学知识（主要是线性代数）。\n正向传播 非常简单易懂，就是矩阵乘法。\n反向传播 引理一 搞懂这个引理反向传播就差不多弄懂了，求哪个偏导，固定某行/列值算贡献 就好求了（A固定行，B固定列），因为矩阵乘法是B的列与A的行做点积。\n以上就是神经网络里的线性代数的一些知识，其实不需要太多基础弄得矩阵乘法，和求导链式法则即可手写神经网络。\n","permalink":"http://localhost:52364/posts/%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC/","summary":"\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC/2.png\"\u003e\u003c/p\u003e\n\u003cp\u003e最近在重新回顾深度学习相关基础，之前大概过了一遍李沐的动手学深度学习，但很多内容还一知半解，\n感觉网上课程难度曲线还是不太平滑。\u003c/p\u003e\n\u003cp\u003e无意间看到 \u003ca href=\"https://www.coursera.org/\"\u003eCoursera平台\u003c/a\u003e，在淘宝上花了80买了个半年号，仿佛打开新世界了，第一次看到了原来真的有课程能把深度学习的学习曲线\n弄的这么平滑的，爱了，有点像算法竞赛的acwing、牛客。感觉b站确实不错，但是反馈和互动肯定远远比不上Coursera的。\u003c/p\u003e\n\u003cp\u003e现在刚学完第一门课程，并手动设计并实现了多层卷积神经网络（只用到numpy），在这里记录一下forward/back propagation的数学知识（主要是线性代数）。\u003c/p\u003e\n\u003ch4 id=\"正向传播\"\u003e正向传播\u003c/h4\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC/%281%29.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003e非常简单易懂，就是矩阵乘法。\u003c/p\u003e\n\u003ch4 id=\"反向传播\"\u003e反向传播\u003c/h4\u003e\n\u003ch5 id=\"引理一\"\u003e引理一\u003c/h5\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC/%282%29.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC/%283%29.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003e搞懂这个引理反向传播就差不多弄懂了，求哪个偏导，固定某行/列值算贡献 就好求了（A固定行，B固定列），因为矩阵乘法是B的列与A的行做点积。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC/%284%29.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003e以上就是神经网络里的线性代数的一些知识，其实不需要太多基础弄得矩阵乘法，和求导链式法则即可手写神经网络。\u003c/p\u003e","title":"神经网络反向传播 数学推导"},{"content":"工具介绍 Hugo 简介：Hugo 是一个用 Go 语言编写的静态网站生成器。它以极快的生成速度著称，可以在几秒内构建上千页面。\n特点：\n不依赖数据库，所有页面都是静态文件，部署简单且性能高。 支持 Markdown 写作，适合博客和文档站点。 拥有强大的模板系统和主题生态。 跨平台运行（Windows、Linux、macOS）。 PaperMod 简介：PaperMod 是 Hugo 社区里非常流行的一个 简洁、现代的主题，灵感来自 Google Material Design。\n特点：\n设计简洁清爽，注重阅读体验。 自带夜间模式、搜索、标签分类等功能。 对 SEO 和性能友好，开箱即用。 支持高度自定义，比如文章目录、社交链接、评论系统等。 👉 总结：Hugo 是建站工具，PaperMod 是在 Hugo 上常用的主题之一。\nStep 1 按照下面视频安装hugo+papermod，搭建demo\n【雷】Hugo + Github免费搭建博客，并实现自动化部署\nStep 2 配置papermod主题，结合大语言模型，想要什么功能直接询问即可，并修改配置文件，主题大部分都是配有相关功能的。\n","permalink":"http://localhost:52364/posts/hugo+paermod%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%95%99%E7%A8%8B/","summary":"\u003ch3 id=\"工具介绍\"\u003e工具介绍\u003c/h3\u003e\n\u003ch4 id=\"hugo\"\u003eHugo\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e简介\u003c/strong\u003e：Hugo 是一个用 Go 语言编写的\u003cstrong\u003e静态网站生成器\u003c/strong\u003e。它以极快的生成速度著称，可以在几秒内构建上千页面。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e特点\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e不依赖数据库，所有页面都是静态文件，部署简单且性能高。\u003c/li\u003e\n\u003cli\u003e支持 Markdown 写作，适合博客和文档站点。\u003c/li\u003e\n\u003cli\u003e拥有强大的模板系统和主题生态。\u003c/li\u003e\n\u003cli\u003e跨平台运行（Windows、Linux、macOS）。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"papermod\"\u003ePaperMod\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e简介\u003c/strong\u003e：PaperMod 是 Hugo 社区里非常流行的一个 \u003cstrong\u003e简洁、现代的主题\u003c/strong\u003e，灵感来自 Google Material Design。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e特点\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e设计简洁清爽，注重阅读体验。\u003c/li\u003e\n\u003cli\u003e自带夜间模式、搜索、标签分类等功能。\u003c/li\u003e\n\u003cli\u003e对 SEO 和性能友好，开箱即用。\u003c/li\u003e\n\u003cli\u003e支持高度自定义，比如文章目录、社交链接、评论系统等。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e👉 总结：\u003cstrong\u003eHugo\u003c/strong\u003e 是建站工具，\u003cstrong\u003ePaperMod\u003c/strong\u003e 是在 Hugo 上常用的主题之一。\u003c/p\u003e\n\u003ch3 id=\"step-1\"\u003eStep 1\u003c/h3\u003e\n\u003cp\u003e按照下面视频安装hugo+papermod，搭建demo\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://www.bilibili.com/video/BV1bovfeaEtQ?vd_source=89574dec834a4f547f86ccea8df6514e\"\u003e【雷】Hugo + Github免费搭建博客，并实现自动化部署\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id=\"step-2\"\u003eStep 2\u003c/h3\u003e\n\u003cp\u003e配置papermod主题，结合大语言模型，想要什么功能直接询问即可，并修改配置文件，主题大部分都是配有相关功能的。\u003c/p\u003e","title":"hugo+papermod博客搭建教程"},{"content":"你好，我是 wanghai673，一名正在攻读 计算机科学与技术 的研究生（研 0），本科毕业于东华大学，目前就读于华东师范大学。\n💻 编程语言：C++、Python、Java\n🔍 研究兴趣：深度学习、大语言模型、智能体\n🏆 竞赛经历：\nICPC 亚洲区域赛 金奖（第 49 届） 蓝桥杯全国总决赛 一等奖（全国第 6 名） 百度之星全国总决赛 金奖 多次 ICPC/CCPC 银奖 上海市大学生程序设计竞赛 一等奖 我正在不断学习和提升自己，期待将所学应用于实际问题。如果有相关的 实习机会 或者 研究合作，非常欢迎联系我。\n📫 联系方式：微信、邮件\n","permalink":"http://localhost:52364/about/","summary":"\u003cp\u003e你好，我是 \u003cstrong\u003ewanghai673\u003c/strong\u003e，一名正在攻读 \u003cstrong\u003e计算机科学与技术\u003c/strong\u003e 的研究生（研 0），本科毕业于东华大学，目前就读于华东师范大学。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e💻 编程语言：C++、Python、Java\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e🔍 研究兴趣：深度学习、大语言模型、智能体\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e🏆 竞赛经历：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eICPC 亚洲区域赛 \u003cstrong\u003e金奖（第 49 届）\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e蓝桥杯全国总决赛 \u003cstrong\u003e一等奖（全国第 6 名）\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e百度之星全国总决赛 \u003cstrong\u003e金奖\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e多次 ICPC/CCPC \u003cstrong\u003e银奖\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e上海市大学生程序设计竞赛 \u003cstrong\u003e一等奖\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e我正在不断学习和提升自己，期待将所学应用于实际问题。如果有相关的 \u003cstrong\u003e实习机会\u003c/strong\u003e 或者 \u003cstrong\u003e研究合作\u003c/strong\u003e，非常欢迎联系我。\u003c/p\u003e\n\u003cp\u003e📫 联系方式：\u003ca href=\"wechat.jpg\"\u003e微信\u003c/a\u003e、\u003ca href=\"https://mail.qq.com/cgi-bin/qm_share?t=qm_mailme\u0026amp;email=1154103986@qq.com\"\u003e邮件\u003c/a\u003e\u003c/p\u003e","title":"关于"}]